{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efde7a7",
   "metadata": {},
   "source": [
    "## Converting pdf to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fc61896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1: PDF TO CSV CONVERSION\n",
      "================================================================================\n",
      "\n",
      "üìÑ Reading PDF: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_statement_john.pdf\n",
      "üîê Using password: ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Feb 17, 2026 1:18:53 AM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'ArialMT' for 'DejaVuSans'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Extracted 148 tables from PDF\n",
      "‚úì Combined into 2869 rows and 14 columns\n",
      "\n",
      "‚úÖ CSV saved successfully: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\n",
      "\n",
      "================================================================================\n",
      "PREVIEW - First 5 rows:\n",
      "================================================================================\n",
      "   Unnamed: 0  Unnamed: 1           TRANSACTION TYPE       PAID IN  \\\n",
      "0         NaN         NaN                SEND MONEY:          0.00   \n",
      "1         NaN         NaN            RECEIVED MONEY:    581,070.00   \n",
      "2         NaN         NaN             AGENT DEPOSIT:  2,028,550.00   \n",
      "3         NaN         NaN          AGENT WITHDRAWAL:          0.00   \n",
      "4         NaN         NaN  LIPA NA M-PESA (PAYBILL):          0.00   \n",
      "\n",
      "       PAID OUT Receipt No. Completion Time Details Transaction Status  \\\n",
      "0    781,669.00         NaN             NaN     NaN                NaN   \n",
      "1          0.00         NaN             NaN     NaN                NaN   \n",
      "2          0.00         NaN             NaN     NaN                NaN   \n",
      "3    146,179.00         NaN             NaN     NaN                NaN   \n",
      "4  1,994,874.00         NaN             NaN     NaN                NaN   \n",
      "\n",
      "  Paid In Withdrawn Balance Statement Verification Code  \\\n",
      "0     NaN       NaN     NaN                         NaN   \n",
      "1     NaN       NaN     NaN                         NaN   \n",
      "2     NaN       NaN     NaN                         NaN   \n",
      "3     NaN       NaN     NaN                         NaN   \n",
      "4     NaN       NaN     NaN                         NaN   \n",
      "\n",
      "   To verify the validity of this M-PESA statement dial *334#, select My account and follow the\\rprompts to enter the code.  \n",
      "0                                                NaN                                                                         \n",
      "1                                                NaN                                                                         \n",
      "2                                                NaN                                                                         \n",
      "3                                                NaN                                                                         \n",
      "4                                                NaN                                                                         \n",
      "\n",
      "================================================================================\n",
      "PREVIEW - Last 5 rows:\n",
      "================================================================================\n",
      "      Unnamed: 0  Unnamed: 1 TRANSACTION TYPE PAID IN PAID OUT Receipt No.  \\\n",
      "2864         NaN         NaN              NaN     NaN      NaN         NaN   \n",
      "2865         NaN         NaN              NaN     NaN      NaN         NaN   \n",
      "2866         NaN         NaN              NaN     NaN      NaN  SBH9E59WPT   \n",
      "2867         NaN         NaN              NaN     NaN      NaN         NaN   \n",
      "2868         NaN         NaN              NaN     NaN      NaN         NaN   \n",
      "\n",
      "          Completion Time           Details Transaction Status Paid In  \\\n",
      "2864                  NaN               NaN                NaN     NaN   \n",
      "2865                  NaN               NaN                NaN     NaN   \n",
      "2866  2024-02-17 18:31:52  Airtime Purchase          Completed     NaN   \n",
      "2867                  NaN               NaN                NaN     NaN   \n",
      "2868                  NaN               NaN                NaN     NaN   \n",
      "\n",
      "     Withdrawn Balance Statement Verification Code  \\\n",
      "2864       NaN     NaN                         NaN   \n",
      "2865       NaN     NaN                    W3JDL74Z   \n",
      "2866     -30.0   95.15                         NaN   \n",
      "2867       NaN     NaN                         NaN   \n",
      "2868       NaN     NaN                    W3JDL74Z   \n",
      "\n",
      "      To verify the validity of this M-PESA statement dial *334#, select My account and follow the\\rprompts to enter the code.  \n",
      "2864                                                NaN                                                                         \n",
      "2865                                                NaN                                                                         \n",
      "2866                                                NaN                                                                         \n",
      "2867                                                NaN                                                                         \n",
      "2868                                                NaN                                                                         \n",
      "\n",
      "Total rows: 2,869\n",
      "Total columns: 14\n",
      "\n",
      "‚úÖ STAGE 1 COMPLETE!\n",
      "Output: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 1: PDF TO CSV CONVERSION\n",
    "Extracts M-Pesa statement from PDF and saves as CSV\n",
    "\"\"\"\n",
    "\n",
    "import tabula\n",
    "import pandas as pd\n",
    "\n",
    "def convert_mpesa_pdf_to_csv(pdf_path: str, password: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Convert M-Pesa PDF statement to CSV\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to M-Pesa PDF statement\n",
    "        password: PDF password\n",
    "        output_csv: Output CSV file path\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 1: PDF TO CSV CONVERSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    print(f\"üìÑ Reading PDF: {pdf_path}\")\n",
    "    print(f\"üîê Using password: {'*' * len(password)}\")\n",
    "    print()\n",
    "    \n",
    "    # Extract ALL tables from ALL pages with 'latin-1' encoding\n",
    "    tables = tabula.read_pdf(\n",
    "        pdf_path, \n",
    "        password=password,\n",
    "        encoding='latin-1',\n",
    "        pages='all',  # Extract from all pages\n",
    "        multiple_tables=True  # Get all tables on each page\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Extracted {len(tables)} tables from PDF\")\n",
    "    \n",
    "    # Combine all tables\n",
    "    df = pd.concat(tables, ignore_index=True)\n",
    "    \n",
    "    print(f\"‚úì Combined into {len(df)} rows and {len(df.columns)} columns\")\n",
    "    print()\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"‚úÖ CSV saved successfully: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    # Show preview\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREVIEW - First 5 rows:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.head())\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREVIEW - Last 5 rows:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.tail())\n",
    "    print()\n",
    "    \n",
    "    print(f\"Total rows: {len(df):,}\")\n",
    "    print(f\"Total columns: {len(df.columns)}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # CONFIGURE THESE PATHS\n",
    "    PDF_FILE = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_statement_john.pdf\"\n",
    "    PDF_PASSWORD = \"335419\"  # Your PDF password\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\"\n",
    "    \n",
    "    # Run conversion\n",
    "    df = convert_mpesa_pdf_to_csv(PDF_FILE, PDF_PASSWORD, OUTPUT_CSV)\n",
    "    \n",
    "    print(\"‚úÖ STAGE 1 COMPLETE!\")\n",
    "    print(f\"Output: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b603cc",
   "metadata": {},
   "source": [
    "## Key Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b999a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 2: TRANSACTION TYPE IDENTIFICATION (COMPLETE FIX)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ OverDraft of Credit Party ‚Üí Fuliza (LOAN)\n",
      "‚úÖ Fuliza payments ‚Üí Categorized by what was paid (Airtime, Till, etc.)\n",
      "‚úÖ Loan Repayment separate category\n",
      "‚úÖ LOOP B2C ‚Üí Income\n",
      "‚úÖ Data Bundles (4093441) ‚â† Airtime (826915)\n",
      "‚úÖ Direct Pay ‚Üí Airtime\n",
      "‚úÖ Deposit/Withdrawal at Agent ‚Üí separate\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\n",
      "‚úì Loaded 2715 transactions\n",
      "\n",
      "üîç Identifying transaction types...\n",
      "üìã Extracting details...\n",
      "‚úì Identified 13 transaction types\n",
      "\n",
      "================================================================================\n",
      "TRANSACTION TYPE BREAKDOWN\n",
      "================================================================================\n",
      "M-Pesa Fee               :   779 ( 28.7%)\n",
      "Send Money               :   625 ( 23.0%)\n",
      "PayBill                  :   404 ( 14.9%)\n",
      "Cash Deposit             :   297 ( 10.9%)\n",
      "Received Money           :   241 (  8.9%)\n",
      "Pochi la Biashara        :   139 (  5.1%)\n",
      "M-Shwari                 :    85 (  3.1%)\n",
      "Till Payment             :    81 (  3.0%)\n",
      "Airtime                  :    32 (  1.2%)\n",
      "Cash Withdrawal          :    21 (  0.8%)\n",
      "Other                    :     5 (  0.2%)\n",
      "Reversal                 :     4 (  0.1%)\n",
      "Data Bundles             :     2 (  0.1%)\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION - KEY TYPES\n",
      "================================================================================\n",
      "\n",
      "Data Bundles (2 transactions):\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "\n",
      "Airtime (32 transactions):\n",
      "  Airtime Purchase\n",
      "  Pay Bill Online to 4093275 - Direct Pay Limited 1 Acc. ATL1595883595\n",
      "\n",
      "Cash Deposit (297 transactions):\n",
      "  Deposit of Funds at Agent Till 158065 - Washindi Shop Dajos HotelBuild\n",
      "  Deposit of Funds at Agent Till 420487 - Kilwa Agencies LTDNyayo Stadiu\n",
      "\n",
      "Cash Withdrawal (21 transactions):\n",
      "  Customer Withdrawal At Agent Till 354039 - Enlight Comm Shanniz Enterp\n",
      "  Customer Withdrawal At Agent Till 171129 - Tosubeto Ent geneuine conn \n",
      "\n",
      "================================================================================\n",
      "FULIZA-POWERED TRANSACTIONS: 0 total\n",
      "================================================================================\n",
      "\n",
      "‚úì Fuliza LOAN (OverDraft) vs Fuliza PAYMENTS properly separated!\n",
      "\n",
      "‚úÖ Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\n",
      "\n",
      "‚úÖ Ready for Stage 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 2: TRANSACTION TYPE IDENTIFICATION (COMPLETE FIX)\n",
    "‚úÖ Separates Fuliza LOAN (OverDraft of Credit Party) from Fuliza PAYMENTS\n",
    "‚úÖ Loan Repayment as separate category\n",
    "‚úÖ All other fixes included\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class TransactionTypeIdentifier:\n",
    "    \"\"\"Enhanced transaction type identification with all fixes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Define patterns in strict priority order\"\"\"\n",
    "        # Format: (type_name, [patterns], priority)\n",
    "        self.type_patterns = [\n",
    "            # PRIORITY 1: Fees (check first - often confused with other types)\n",
    "            ('M-Pesa Fee', [\n",
    "                r'transfer\\s+of\\s+funds\\s+charge',\n",
    "                r'pay\\s+bill\\s+charge',\n",
    "                r'pay\\s+merchant\\s+charge',\n",
    "                r'withdraw(al)?\\s+charge',\n",
    "                r'\\bcharge\\b$',\n",
    "            ], 1),\n",
    "            \n",
    "            # PRIORITY 2: Fuliza/Overdraft LOAN (the credit itself - OverDraft of Credit Party)\n",
    "            ('Fuliza', [\n",
    "                r'overdraft\\s+of\\s+credit\\s+party',  # This is the LOAN\n",
    "            ], 2),\n",
    "            \n",
    "            # PRIORITY 3: Loan Repayment (paying back loans, including Fuliza payments)\n",
    "            ('Loan Repayment', [\n",
    "                r'od\\s+loan\\s+repayment',\n",
    "                r'loan\\s+repayment',\n",
    "                r'fuliza\\s+repayment',\n",
    "                r'overdraw',\n",
    "            ], 3),\n",
    "            \n",
    "            # PRIORITY 4: LOOP Payment (Income from LOOP)\n",
    "            ('LOOP Payment', [\n",
    "                r'promotion\\s+payment\\s+from.*loop\\s+b2c',\n",
    "                r'loop\\s+b2c',\n",
    "            ], 4),\n",
    "            \n",
    "            # PRIORITY 5: Received Money (Income)\n",
    "            ('Received Money', [\n",
    "                r'funds\\s+received\\s+from',\n",
    "                r'business\\s+payment\\s+from',\n",
    "                r'received\\s+from',\n",
    "            ], 5),\n",
    "            \n",
    "            # PRIORITY 6: Cash Deposit (at agent)\n",
    "            ('Cash Deposit', [\n",
    "                r'deposit\\s+of\\s+funds\\s+at\\s+agent',\n",
    "            ], 6),\n",
    "            \n",
    "            # PRIORITY 7: Cash Withdrawal (at agent)\n",
    "            ('Cash Withdrawal', [\n",
    "                r'customer\\s+withdrawal\\s+at\\s+agent',\n",
    "                r'withdrawal\\s+at\\s+agent',\n",
    "            ], 7),\n",
    "            \n",
    "            # PRIORITY 8: Data Bundles (separated from Airtime)\n",
    "            # Including Fuliza-powered data bundles\n",
    "            ('Data Bundles', [\n",
    "                r'safaricom\\s+data',\n",
    "                r'safaricom\\s+data\\s+bundles',\n",
    "                r'customer\\s+bundle\\s+purchase\\s+with\\s+fuliza.*4093441',\n",
    "                r'(?i)buy\\s+bundle',\n",
    "                r'(?i)customer\\s+bundle\\s+purchase',\n",
    "                 r'customer\\s+bundle\\s+purchase\\s+with\\s+fuliza',\n",
    "            \n",
    "            ], 8),\n",
    "            \n",
    "            # PRIORITY 9: Airtime (separated from Data, includes Direct Pay)\n",
    "            # Including Fuliza-powered airtime\n",
    "            ('Airtime', [\n",
    "                r'(?i)safaricom\\s+offers',  # Safaricom Offers = Airtime\n",
    "                r'airtime\\s+purchase',\n",
    "                r'pay\\s+bill.*direct\\s+pay.*atl\\d+',  # Direct Pay airtime\n",
    "                r'4187661.*direct\\s+pay',  # Direct Pay paybill\n",
    "                r'4093275.*direct\\s+pay',  # Another Direct Pay paybill\n",
    "                r'recharge\\s+for\\s+customer',\n",
    "            ], 9),\n",
    "            \n",
    "            # PRIORITY 10: Send Money (including Fuliza-powered transfers)\n",
    "            ('Send Money', [\n",
    "                r'(?i)customer\\s+transfer\\s+to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "                r'customer\\s+transfer\\s+to\\s+-\\s+',\n",
    "                r'(?i)customer\\stransfer',\n",
    "                r'customer\\s+send\\s+money.*fuliza.*to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "                r'(?i)customer\\s+transfer\\s+fuliza\\s+mpesa\\s*to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "            ], 10),\n",
    "            \n",
    "            # PRIORITY 11: Pochi la Biashara\n",
    "            ('Pochi la Biashara', [\n",
    "                r'customer\\s+payment\\s+to\\s+small\\s+business',\n",
    "            ], 11),\n",
    "            \n",
    "            # PRIORITY 12: Till Payment (including Fuliza-powered)\n",
    "            ('Till Payment', [\n",
    "                r'merchant\\s+payment\\s+(online\\s+)?to\\s+\\d+',\n",
    "                r'merchant\\s+payment\\s+fuliza\\s+m-?pesa\\s*to\\s+\\d+',\n",
    "                r'till\\s+\\d+',\n",
    "            ], 12),\n",
    "            \n",
    "            # PRIORITY 13: PayBill (including Fuliza-powered)\n",
    "            ('PayBill', [\n",
    "                r'pay\\s+bill\\s+(online\\s+)?to\\s+\\d+',\n",
    "                r'pay\\s+bill\\s+fuliza\\s+m-?pesa\\s+to\\s+\\d+',\n",
    "                r'pay\\s+bill\\s+online\\s+fuliza\\s+m-pesa\\s+to\\s+(\\d+)\\s+-\\s+([\\w\\s]+?)\\s+acc\\.?\\s+([\\w\\s]+)',\n",
    "            ], 13),\n",
    "            \n",
    "            # PRIORITY 14: M-Shwari\n",
    "            ('M-Shwari', [\n",
    "                r'm-?\\s*shwari',\n",
    "            ], 14),\n",
    "            \n",
    "            # PRIORITY 15: Unit Trust\n",
    "            ('Unit Trust', [\n",
    "                r'unit\\s+trust',\n",
    "                r'ziidi',\n",
    "            ], 15),\n",
    "            \n",
    "            # PRIORITY 16: Reversal\n",
    "            ('Reversal', [\n",
    "                r'reversal',\n",
    "                r'reversed',\n",
    "            ], 16),\n",
    "        ]\n",
    "    \n",
    "    def identify_type(self, description: str) -> str:\n",
    "        \"\"\"Identify transaction type\"\"\"\n",
    "        if pd.isna(description) or description == '':\n",
    "            return 'Other'\n",
    "        \n",
    "        desc_lower = str(description).lower().strip()\n",
    "        \n",
    "        # Check in priority order\n",
    "        for trans_type, patterns, _ in self.type_patterns:\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, desc_lower, re.IGNORECASE):\n",
    "                    return trans_type\n",
    "        \n",
    "        return 'Other'\n",
    "    \n",
    "    def extract_fields(self, description: str, txn_type: str) -> Dict:\n",
    "        \"\"\"Extract key fields from description\"\"\"\n",
    "        if pd.isna(description):\n",
    "            return {}\n",
    "        \n",
    "        fields = {}\n",
    "        desc = str(description)\n",
    "        \n",
    "        if txn_type == \"Send Money\":\n",
    "            # Regular transfer\n",
    "            match = re.search(\n",
    "                r'(?i)customer\\s+transfer\\s+(?:fuliza\\s+mpesa\\s*)?to\\s+-\\s+((2547|07|01)[\\d\\*]+)\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"recipient_number\"] = match.group(1)\n",
    "                fields[\"recipient_name\"] = match.group(3).strip()\n",
    "        \n",
    "        elif txn_type == \"Pochi la Biashara\":\n",
    "            match = re.search(\n",
    "                r'(?i)small\\s+business\\s+to\\s+-\\s+((2547|07|01)[\\d\\*]+)\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"recipient_number\"] = match.group(1)\n",
    "                fields[\"recipient_name\"] = match.group(3).strip()\n",
    "        \n",
    "        elif txn_type == \"Till Payment\":\n",
    "            # Regular or Fuliza merchant payment\n",
    "            match = re.search(\n",
    "                r'(?i)merchant\\s+payment\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+-\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"till_number\"] = match.group(1)\n",
    "                raw_merchant = match.group(2).strip()\n",
    "                raw_merchant = re.sub(\n",
    "                    r'(?i)\\s+via\\s+(coop|equity|kcb|ncba|family)\\s+bank\\.?$',\n",
    "                    '', raw_merchant\n",
    "                ).strip()\n",
    "                fields[\"merchant_name\"] = raw_merchant\n",
    "        \n",
    "        elif txn_type == \"PayBill\":\n",
    "            # Regular or Fuliza paybill\n",
    "            match = re.search(\n",
    "                r'(?i)pay\\s+bill\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+[-‚Äì]\\s+([\\w\\s]+?)\\s+[Aa]cc\\.?\\s+([\\w#]+)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"paybill_number\"] = match.group(1)\n",
    "                fields[\"merchant_name\"] = match.group(2).strip()\n",
    "                fields[\"account_number\"] = match.group(3).strip()\n",
    "            else:\n",
    "                match2 = re.search(\n",
    "                    r'(?i)pay\\s+bill\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+[-‚Äì]?\\s+(.*)',\n",
    "                    desc\n",
    "                )\n",
    "                if match2:\n",
    "                    fields[\"paybill_number\"] = match2.group(1)\n",
    "                    fields[\"merchant_name\"] = match2.group(2).strip()\n",
    "        \n",
    "        elif txn_type in [\"Cash Withdrawal\", \"Cash Deposit\"]:\n",
    "            match = re.search(\n",
    "                r'(?i)agent\\s+till\\s+(\\d+)\\s+[-‚Äì]\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"agent_till\"] = match.group(1)\n",
    "                fields[\"agent_name\"] = match.group(2).strip()\n",
    "        \n",
    "        elif txn_type in [\"Received Money\", \"LOOP Payment\"]:\n",
    "            match = re.search(\n",
    "                r'(?i)(?:funds\\s+received|payment)\\s+from\\s+[-‚Äì]?\\s+(\\d+)\\s+[-‚Äì]\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"sender_number\"] = match.group(1)\n",
    "                fields[\"sender_name\"] = match.group(2).strip()\n",
    "        \n",
    "        return fields\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add transaction_type and extracted_fields\"\"\"\n",
    "        print(\"üîç Identifying transaction types...\")\n",
    "        \n",
    "        # Clean description\n",
    "        df['description_clean'] = df['Details'].apply(self._clean_text)\n",
    "        \n",
    "        # Identify types\n",
    "        df['transaction_type'] = df['description_clean'].apply(self.identify_type)\n",
    "        \n",
    "        # Extract fields\n",
    "        print(\"üìã Extracting details...\")\n",
    "        df['extracted_fields'] = df.apply(\n",
    "            lambda row: self.extract_fields(row['description_clean'], row['transaction_type']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Identified {df['transaction_type'].nunique()} transaction types\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean multiline PDF text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        text = str(text).replace('\\\\r', ' ').replace('\\\\n', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "def run_stage2(input_csv: str, output_csv: str):\n",
    "    \"\"\"Run Stage 2\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 2: TRANSACTION TYPE IDENTIFICATION (COMPLETE FIX)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"‚úÖ OverDraft of Credit Party ‚Üí Fuliza (LOAN)\")\n",
    "    print(\"‚úÖ Fuliza payments ‚Üí Categorized by what was paid (Airtime, Till, etc.)\")\n",
    "    print(\"‚úÖ Loan Repayment separate category\")\n",
    "    print(\"‚úÖ LOOP B2C ‚Üí Income\")\n",
    "    print(\"‚úÖ Data Bundles (4093441) ‚â† Airtime (826915)\")\n",
    "    print(\"‚úÖ Direct Pay ‚Üí Airtime\")\n",
    "    print(\"‚úÖ Deposit/Withdrawal at Agent ‚Üí separate\")\n",
    "    print()\n",
    "    \n",
    "    # Load\n",
    "    print(f\"üìÇ Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    \n",
    "    # Filter to transactions\n",
    "    mask = df['Receipt No.'].notna() & (df['Receipt No.'] != '')\n",
    "    df = df[mask].copy()\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(df)} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Process\n",
    "    identifier = TransactionTypeIdentifier()\n",
    "    df = identifier.process_dataframe(df)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TRANSACTION TYPE BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    for trans_type, count in df['transaction_type'].value_counts().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{trans_type:25s}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERIFICATION - KEY TYPES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Verify critical fixes\n",
    "    key_types = ['Fuliza', 'Loan Repayment', 'LOOP Payment', 'Data Bundles', \n",
    "                 'Airtime', 'Cash Deposit', 'Cash Withdrawal']\n",
    "    \n",
    "    for trans_type in key_types:\n",
    "        type_df = df[df['transaction_type'] == trans_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{trans_type} ({len(type_df)} transactions):\")\n",
    "            for _, row in type_df.head(2).iterrows():\n",
    "                print(f\"  {row['description_clean'][:70]}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Show Fuliza-powered transactions\n",
    "    fuliza_powered = df[df['description_clean'].str.contains('fuliza', case=False, na=False)]\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"FULIZA-POWERED TRANSACTIONS: {len(fuliza_powered)} total\")\n",
    "    print(\"=\" * 80)\n",
    "    fuliza_breakdown = fuliza_powered['transaction_type'].value_counts()\n",
    "    for txn_type, count in fuliza_breakdown.items():\n",
    "        print(f\"  {txn_type:25s}: {count:5d}\")\n",
    "    print()\n",
    "    print(\"‚úì Fuliza LOAN (OverDraft) vs Fuliza PAYMENTS properly separated!\")\n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df['extracted_fields_str'] = df['extracted_fields'].apply(str)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\"\n",
    "    OUTPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\"\n",
    "    \n",
    "    df = run_stage2(INPUT, OUTPUT)\n",
    "    print(\"‚úÖ Ready for Stage 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b71c0",
   "metadata": {},
   "source": [
    "## Transansaction Type Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "113d8774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 3: KEYWORD-BASED CATEGORIZATION (COMPLETE FIX)\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Removed 'online' from Online Shopping\n",
      "‚úÖ Removed 'fuliza' from Loans\n",
      "‚úÖ Fuliza ‚Üí Loans (via transaction type)\n",
      "‚úÖ LOOP Payment ‚Üí Income\n",
      "‚úÖ Data Bundles & Airtime separate\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\n",
      "‚úì Loaded 2715 transactions\n",
      "\n",
      "üè∑Ô∏è  Categorizing...\n",
      "‚úì Categorized into 16 categories\n",
      "\n",
      "================================================================================\n",
      "CATEGORY BREAKDOWN\n",
      "================================================================================\n",
      "M-Pesa Fees                   :   779 ( 28.7%)\n",
      "Uncategorized                 :   626 ( 23.1%)\n",
      "Merchant                      :   420 ( 15.5%)\n",
      "Cash Deposit                  :   297 ( 10.9%)\n",
      "Income                        :   241 (  8.9%)\n",
      "Bills                         :   104 (  3.8%)\n",
      "Bank Transfer                 :    87 (  3.2%)\n",
      "Cash Withdrawal               :    62 (  2.3%)\n",
      "Savings                       :    46 (  1.7%)\n",
      "Airtime                       :    32 (  1.2%)\n",
      "Shopping                      :     6 (  0.2%)\n",
      "Reversal                      :     4 (  0.1%)\n",
      "Other                         :     4 (  0.1%)\n",
      "Personal Care                 :     4 (  0.1%)\n",
      "Data Bundles                  :     2 (  0.1%)\n",
      "Health Care                   :     1 (  0.0%)\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION - KEY CATEGORIES\n",
      "================================================================================\n",
      "\n",
      "Data Bundles (2 transactions):\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "\n",
      "Airtime (32 transactions):\n",
      "  Airtime Purchase\n",
      "  Pay Bill Online to 4093275 - Direct Pay Limited 1 Acc. ATL1595883595\n",
      "\n",
      "Income (241 transactions):\n",
      "  Funds received from - 2547******113 NDEGE KAUSI\n",
      "  Funds received from - 2547******067 Timothy Macharia\n",
      "\n",
      "Cash Deposit (297 transactions):\n",
      "  Deposit of Funds at Agent Till 158065 - Washindi Shop Dajos HotelBuild\n",
      "  Deposit of Funds at Agent Till 420487 - Kilwa Agencies LTDNyayo Stadiu\n",
      "\n",
      "Cash Withdrawal (62 transactions):\n",
      "  M-Shwari Withdraw\n",
      "  M-Shwari Withdraw\n",
      "\n",
      "‚úÖ Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\n",
      "\n",
      "‚úÖ Ready for Stage 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 3: KEYWORD-BASED CATEGORIZATION (COMPLETE FIX)\n",
    "All issues addressed:\n",
    "‚úÖ Removed \"online\" and \"online purchase\" from Online Shopping\n",
    "‚úÖ Removed \"fuliza\" from Loans (handled in Stage 2)\n",
    "‚úÖ Fuliza ‚Üí Loans (via transaction type)\n",
    "‚úÖ LOOP Payment ‚Üí Income\n",
    "‚úÖ Data Bundles and Airtime now separate\n",
    "‚úÖ Direct Pay airtime not miscategorized as Online Shopping\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class KeywordCategorizer:\n",
    "    \"\"\"Enhanced keyword categorizer with all fixes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.category_keywords = {\n",
    "            # HIGH PRIORITY\n",
    "            'Health Care': {\n",
    "                'keywords': [\n",
    "                    'hospital', 'clinic', 'pharmacy', 'medical', 'nhif',\n",
    "                    'chemist', 'doctor', 'laboratory', 'lab', 'diagnostic',\n",
    "                    'aga khan', 'nairobi hospital', 'mater', 'kenyatta hospital',\n",
    "                    'mp shah', 'gertrudes', 'lancet', 'dental', 'optical',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Betting': {\n",
    "                'keywords': [\n",
    "                    'sportpesa', 'sportybet', 'betika', '1xbet', 'stake', \n",
    "                    'bangbet', '22bet', 'mozzart bet', 'betway', 'odibets',\n",
    "                    'kareco holdings', 'melbet', 'betin', 'betpawa', 'shabiki',\n",
    "                    'bet', 'betting', 'lotto', 'lottery', 'casino',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # Loans - REMOVED \"fuliza\" (now handled via transaction type)\n",
    "            'Loans': {\n",
    "                'keywords': [\n",
    "                    'm-shwari loan', 'kcb m-pesa loan', 'hustler fund',\n",
    "                    'okash', 'zenka', 'timiza', 'Overdraft',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "\n",
    "            'Loan Repayment': {\n",
    "                'keywords': ['repayment', 'overdraw'],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # Online Shopping - REMOVED \"online\" and \"online purchase\"\n",
    "            'Online Shopping': {\n",
    "                'keywords': [\n",
    "                    'jumia', 'kilimall', 'masoko', 'glovo', 'jiji',\n",
    "                    'aliexpress', 'amazon', 'alibaba', 'uber eats', 'bolt food',\n",
    "                    'sky garden', 'food delivery', 'home delivery',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Bills': {\n",
    "                'keywords': [\n",
    "                    'kplc', 'water', 'rent', 'insurance', 'gas refill',\n",
    "                    'internet', 'home wifi', 'land rates', 'security',\n",
    "                    'parking', 'electricity', 'prepaid', 'postpaid',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Subscriptions': {\n",
    "                'keywords': [\n",
    "                    'netflix', 'spotify', 'youtube', 'prime', 'hbo',\n",
    "                    'gotv', 'dstv', 'showmax', 'apple music', 'startimes',\n",
    "                    'zuku', 'subscription', 'microsoft 365', 'office 365',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Education': {\n",
    "                'keywords': [\n",
    "                    'university', 'school', 'college', 'helb', 'kuccps',\n",
    "                    'knec', 'tvet', 'kmtc', 'fees', 'tuition', 'catering',\n",
    "                    'kabarak', 'student', 'academy', 'exam fee', 'hostel',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Savings': {\n",
    "                'keywords': [\n",
    "                    'mshwari deposit', 'unit trust', 'mmf', 'fixed deposit',\n",
    "                    'investment', 'koala', 'ndovu', 'etica', 'chama',\n",
    "                    'ziidi', 'savings', 'sacco deposit', 'Sacco'\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # MEDIUM PRIORITY\n",
    "            'Shopping': {\n",
    "                'keywords': [\n",
    "                    'supermarket', 'naivas', 'quickmart', 'quick mart',\n",
    "                    'carrefour', 'chandarana', 'foodplus', 'cleanshelf',\n",
    "                    'eastmatt', 'tuskys', 'kabsmart', 'nakumatt', 'Store', \n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Fast Foods': {\n",
    "                'keywords': [\n",
    "                    'kfc', 'chicken inn', 'java house', 'artcaffe',\n",
    "                    'pizza', 'burger king', 'dominos', 'debonairs',\n",
    "                    'pizza hut', 'pizza inn', 'subway', 'steers','inn',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Food & Dining': {\n",
    "                'keywords': [\n",
    "                    'restaurant', 'hotel', 'cafe', 'eatery', 'food court',\n",
    "                    'dining', 'meat', 'vegetables', 'fruits', 'milk','food',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Personal Care': {\n",
    "                'keywords': [\n",
    "                    'beauty', 'cosmetics', 'skincare', 'makeup', 'barber',\n",
    "                    'salon', 'spa', 'kinyozi', 'grooming', 'hair', 'nails',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Transport': {\n",
    "                'keywords': [\n",
    "                    'uber', 'bolt', 'taxi', 'little cab', 'transport',\n",
    "                    'fuel', 'petrol', 'diesel', 'shell', 'total', 'parking',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Entertainment': {\n",
    "                'keywords': [\n",
    "                    'liquor', 'bar', 'wine', 'beer', 'club', 'lounge',\n",
    "                    'pub', 'cinema', 'bowling', 'arcade', 'entertainment',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            # LOW PRIORITY\n",
    "            'Bank Transfer': {\n",
    "                'keywords': [\n",
    "                    'equity', 'kcb', 'family bank', 'co-op', 'ncba',\n",
    "                    'stanbic', 'absa', 'bank transfer',\n",
    "                ],\n",
    "                'priority': 3,\n",
    "            },\n",
    "        }\n",
    "    \n",
    "    def categorize(self, description: str, transaction_type: str, extracted_fields: Dict = None) -> str:\n",
    "        \"\"\"Categorize transaction\"\"\"\n",
    "        if pd.isna(description):\n",
    "            return 'Uncategorized'\n",
    "        \n",
    "        desc_lower = str(description).lower()\n",
    "        \n",
    "        # Build search text\n",
    "        search_text = desc_lower\n",
    "        if extracted_fields:\n",
    "            for key in ['merchant_name', 'recipient_name', 'sender_name', 'agent_name']:\n",
    "                if key in extracted_fields:\n",
    "                    search_text += ' ' + str(extracted_fields[key]).lower()\n",
    "        \n",
    "        # PRIORITY 1: Transaction type based (FIXED)\n",
    "        \n",
    "        # Income\n",
    "        if transaction_type in ['Received Money', 'LOOP Payment']:\n",
    "            return 'Income'\n",
    "        \n",
    "        # Cash operations\n",
    "        if transaction_type == 'Cash Deposit':\n",
    "            return 'Cash Deposit'\n",
    "        \n",
    "        if transaction_type == 'Cash Withdrawal':\n",
    "            return 'Cash Withdrawal'\n",
    "        \n",
    "        # Loans (including Fuliza/OverDraft from Stage 2)\n",
    "        if transaction_type == 'Overdraft':\n",
    "            return 'Loans'\n",
    "        \n",
    "        # Data vs Airtime (now separated in Stage 2)\n",
    "        if transaction_type == 'Data Bundles':\n",
    "            return 'Data Bundles'\n",
    "        \n",
    "        if transaction_type == 'Airtime':\n",
    "            return 'Airtime'\n",
    "        \n",
    "        # Fees\n",
    "        if transaction_type == 'M-Pesa Fee':\n",
    "            return 'M-Pesa Fees'\n",
    "        \n",
    "        # M-Shwari\n",
    "        if transaction_type == 'M-Shwari':\n",
    "            if 'withdraw' in desc_lower:\n",
    "                return 'Cash Withdrawal'\n",
    "            else:\n",
    "                return 'Savings'\n",
    "        \n",
    "        # Unit Trust\n",
    "        if transaction_type == 'Unit Trust':\n",
    "            return 'Savings'\n",
    "        \n",
    "        # Reversal\n",
    "        if transaction_type == 'Reversal':\n",
    "            return 'Reversal'\n",
    "        \n",
    "        # PRIORITY 2: Send Money - LEAVE UNCATEGORIZED for Stage 4\n",
    "        if transaction_type == 'Send Money':\n",
    "            return 'Uncategorized'\n",
    "        \n",
    "        # PRIORITY 3: Till/PayBill/Pochi - Try keywords, fallback to Merchant\n",
    "        if transaction_type in ['Till Payment', 'PayBill', 'Pochi la Biashara']:\n",
    "            matched = self._match_keywords(search_text)\n",
    "            return matched if matched else 'Merchant'\n",
    "        \n",
    "        # PRIORITY 4: Other - Try keywords\n",
    "        matched = self._match_keywords(search_text)\n",
    "        return matched if matched else 'Other'\n",
    "    \n",
    "    def _match_keywords(self, search_text: str) -> str:\n",
    "        \"\"\"Match keywords\"\"\"\n",
    "        sorted_categories = sorted(\n",
    "            self.category_keywords.items(),\n",
    "            key=lambda x: x[1].get('priority', 99)\n",
    "        )\n",
    "        \n",
    "        for category, rules in sorted_categories:\n",
    "            for keyword in rules.get('keywords', []):\n",
    "                pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "                if re.search(pattern, search_text, re.IGNORECASE):\n",
    "                    return category\n",
    "        \n",
    "        return ''\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add category column\"\"\"\n",
    "        print(\"üè∑Ô∏è  Categorizing...\")\n",
    "        \n",
    "        # Parse extracted_fields\n",
    "        if 'extracted_fields' in df.columns:\n",
    "            try:\n",
    "                import ast\n",
    "                df['extracted_fields_dict'] = df['extracted_fields'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.strip() else {}\n",
    "                )\n",
    "            except:\n",
    "                df['extracted_fields_dict'] = df['extracted_fields']\n",
    "        else:\n",
    "            df['extracted_fields_dict'] = [{}] * len(df)\n",
    "        \n",
    "        # Categorize\n",
    "        df['category'] = df.apply(\n",
    "            lambda row: self.categorize(\n",
    "                row['description_clean'], \n",
    "                row['transaction_type'],\n",
    "                row.get('extracted_fields_dict', {})\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Categorized into {df['category'].nunique()} categories\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def run_stage3(input_csv: str, output_csv: str):\n",
    "    \"\"\"Run Stage 3\"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 3: KEYWORD-BASED CATEGORIZATION (COMPLETE FIX)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"‚úÖ Removed 'online' from Online Shopping\")\n",
    "    print(\"‚úÖ Removed 'fuliza' from Loans\")\n",
    "    print(\"‚úÖ Fuliza ‚Üí Loans (via transaction type)\")\n",
    "    print(\"‚úÖ LOOP Payment ‚Üí Income\")\n",
    "    print(\"‚úÖ Data Bundles & Airtime separate\")\n",
    "    print()\n",
    "    \n",
    "    # Load\n",
    "    print(f\"üìÇ Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df)} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Categorize\n",
    "    categorizer = KeywordCategorizer()\n",
    "    df = categorizer.process_dataframe(df)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CATEGORY BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    for category, count in df['category'].value_counts().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{category:30s}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Verify key categories\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERIFICATION - KEY CATEGORIES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    key_cats = ['Loans', 'Data Bundles', 'Airtime', 'Income', \n",
    "                'Cash Deposit', 'Cash Withdrawal', 'Loan repayment',]\n",
    "    \n",
    "    for cat in key_cats:\n",
    "        cat_df = df[df['category'] == cat]\n",
    "        if len(cat_df) > 0:\n",
    "            print(f\"\\n{cat} ({len(cat_df)} transactions):\")\n",
    "            for _, row in cat_df.head(2).iterrows():\n",
    "                print(f\"  {row['description_clean'][:70]}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\"\n",
    "    OUTPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\"\n",
    "    \n",
    "    df = run_stage3(INPUT, OUTPUT)\n",
    "    print(\"‚úÖ Ready for Stage 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e614c2",
   "metadata": {},
   "source": [
    "## Smart Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 4: SEND MONEY CATEGORIZATION\n",
      "================================================================================\n",
      "\n",
      "Preserving all Stage 2 & 3 improvements:\n",
      "  ‚úÖ Fuliza (LOAN) vs Fuliza payments\n",
      "  ‚úÖ Loan Repayment separate\n",
      "  ‚úÖ LOOP Payment ‚Üí Income\n",
      "  ‚úÖ Data Bundles ‚â† Airtime\n",
      "  ‚úÖ Cash Deposit ‚â† Cash Withdrawal\n",
      "\n",
      "RULES:\n",
      "  1. Recurring (‚â•2) + Amount > 500.0 ‚Üí Friends & Family\n",
      "  2. Recurring (‚â•2) + Amount ‚â§ 500.0 ‚Üí Merchant\n",
      "  3. Non-recurring (any amount) ‚Üí Merchant\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\n",
      "‚úì Loaded 2,715 transactions\n",
      "\n",
      "Current categorization:\n",
      "  M-Pesa Fees              :   779 ( 28.7%)\n",
      "  Uncategorized            :   626 ( 23.1%)\n",
      "  Merchant                 :   420 ( 15.5%)\n",
      "  Cash Deposit             :   297 ( 10.9%)\n",
      "  Income                   :   241 (  8.9%)\n",
      "  Bills                    :   104 (  3.8%)\n",
      "  Bank Transfer            :    87 (  3.2%)\n",
      "  Cash Withdrawal          :    62 (  2.3%)\n",
      "  Savings                  :    46 (  1.7%)\n",
      "  Airtime                  :    32 (  1.2%)\n",
      "\n",
      "  Send Money (Uncategorized): 625\n",
      "\n",
      "ü§ñ Categorizing Send Money transactions...\n",
      "\n",
      "üîç Detecting recurring recipients in Send Money transactions...\n",
      "‚úì Found 198 unique recipients\n",
      "‚úì 72 recurring recipients (‚â•2 transactions)\n",
      "\n",
      "Top 15 recurring recipients:\n",
      "  2547******463                                : 196 times\n",
      "  2547******402                                :  20 times\n",
      "  07******162                                  :  14 times\n",
      "  2547******857                                :  13 times\n",
      "  2547******633                                :  11 times\n",
      "  2547******831                                :  10 times\n",
      "  01******309                                  :   9 times\n",
      "  2547******317                                :   9 times\n",
      "  07******312                                  :   8 times\n",
      "  2547******795                                :   8 times\n",
      "  2547******488                                :   8 times\n",
      "  2547******743                                :   8 times\n",
      "  2547******638                                :   8 times\n",
      "  07******121                                  :   8 times\n",
      "  2547******596                                :   7 times\n",
      "\n",
      "================================================================================\n",
      "SEND MONEY CATEGORIZATION RESULTS\n",
      "================================================================================\n",
      "Processed: 625 Send Money transactions\n",
      "  ‚Üí Friends & Family: 50\n",
      "  ‚Üí Merchant: 575\n",
      "  ‚Üí Still Uncategorized: 0\n",
      "\n",
      "================================================================================\n",
      "FINAL CATEGORY BREAKDOWN\n",
      "================================================================================\n",
      "Merchant                      :    995 ( 36.6%)\n",
      "M-Pesa Fees                   :    779 ( 28.7%)\n",
      "Cash Deposit                  :    297 ( 10.9%)\n",
      "Income                        :    241 (  8.9%)\n",
      "Bills                         :    104 (  3.8%)\n",
      "Bank Transfer                 :     87 (  3.2%)\n",
      "Cash Withdrawal               :     62 (  2.3%)\n",
      "Friends & Family              :     50 (  1.8%)\n",
      "Savings                       :     46 (  1.7%)\n",
      "Airtime                       :     32 (  1.2%)\n",
      "Shopping                      :      6 (  0.2%)\n",
      "Reversal                      :      4 (  0.1%)\n",
      "Personal Care                 :      4 (  0.1%)\n",
      "Other                         :      4 (  0.1%)\n",
      "Data Bundles                  :      2 (  0.1%)\n",
      "Health Care                   :      1 (  0.0%)\n",
      "Uncategorized                 :      1 (  0.0%)\n",
      "\n",
      "================================================================================\n",
      "CATEGORIZATION SUCCESS RATE\n",
      "================================================================================\n",
      "Total transactions: 2,715\n",
      "Categorized: 2,714 (100.0%)\n",
      "Uncategorized: 1 (0.0%)\n",
      "\n",
      "================================================================================\n",
      "SAMPLE CATEGORIZATIONS\n",
      "================================================================================\n",
      "\n",
      "--- FRIENDS & FAMILY (50 transactions) ---\n",
      "  KES     -629 | Customer Transfer to - 2547******488 FRANCISCA KISINGA\n",
      "  KES     -929 | Customer Transfer to - 2547******488 FRANCISCA KISINGA\n",
      "  KES     -929 | Customer Transfer to - 2547******488 FRANCISCA KISINGA\n",
      "  KES     -929 | Customer Transfer to - 2547******488 FRANCISCA KISINGA\n",
      "  KES     -629 | Customer Transfer to - 07******897 George kamau\n",
      "\n",
      "--- MERCHANT - from Send Money (575 transactions) ---\n",
      "  KES     -200 | Customer Transfer to - 2547******586 WELLINGTON MIRARA\n",
      "  KES        0 | Customer Transfer to - 2547******828 JAMES NDUNGU\n",
      "  KES        0 | Customer Transfer to - 2547******831 JANE NJATHAINI\n",
      "  KES      -50 | Customer Transfer to - 2547******105 Paul kariuki\n",
      "  KES        0 | Customer Transfer to - 2547******831 JANE NJATHAINI\n",
      "\n",
      "================================================================================\n",
      "SPENDING SUMMARY BY CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Category                           Total (KES)    Count    Avg (KES)\n",
      "--------------------------------------------------------------------------------\n",
      "Uncategorized                           -50.00        1       -50.00\n",
      "Health Care                             -90.00        1       -90.00\n",
      "Data Bundles                           -100.00        2       -50.00\n",
      "Personal Care                          -350.00        4       -87.50\n",
      "Savings                              -1,771.00        4      -442.75\n",
      "Shopping                             -2,010.00        6      -335.00\n",
      "Cash Withdrawal                      -3,150.00        6      -525.00\n",
      "Airtime                              -3,170.00       27      -117.41\n",
      "Bank Transfer                        -7,440.00       21      -354.29\n",
      "Bills                               -21,031.00       45      -467.36\n",
      "M-Pesa Fees                         -21,475.00      779       -27.57\n",
      "Friends & Family                    -31,402.00       50      -628.04\n",
      "Merchant                            -94,666.00      626      -151.22\n",
      "--------------------------------------------------------------------------------\n",
      "TOTAL SPENDING                     -186,705.00\n",
      "\n",
      "‚úÖ Saved final categorized data: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\n",
      "\n",
      "================================================================================\n",
      "STAGE 4 COMPLETE! üéâ\n",
      "================================================================================\n",
      "\n",
      "Your M-Pesa data is now fully categorized!\n",
      "Categorization rate: 100.0%\n",
      "Total spending: KES -186,705.00\n",
      "\n",
      "Next steps:\n",
      "  ‚Ä¢ Clean the CSV (remove empty/duplicate columns)\n",
      "  ‚Ä¢ Analyze spending patterns\n",
      "  ‚Ä¢ Create visualizations\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 4: SEND MONEY CATEGORIZATION\n",
    "Categorizes uncategorized Send Money transactions based on amount and recurring patterns\n",
    "\n",
    "RULES:\n",
    "1. Send Money + Recurring (‚â•2 times) + Amount > 500 ‚Üí Friends & Family\n",
    "2. Send Money + Recurring (‚â•2 times) + Amount ‚â§ 500 ‚Üí Merchant\n",
    "3. Send Money + Non-recurring (any amount) ‚Üí Merchant\n",
    "\n",
    "All other categories from Stage 3 remain unchanged.\n",
    "All improvements from Stage 2 & 3 are preserved:\n",
    "‚úÖ Fuliza (LOAN) vs Fuliza payments separated\n",
    "‚úÖ Loan Repayment as separate category\n",
    "‚úÖ LOOP Payment ‚Üí Income\n",
    "‚úÖ Data Bundles ‚â† Airtime\n",
    "‚úÖ Cash Deposit ‚â† Cash Withdrawal\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Dict\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class SendMoneyCategorizer:\n",
    "    \"\"\"Categorize Send Money transactions using recurring detection and amount thresholds\"\"\"\n",
    "    \n",
    "    def __init__(self, amount_threshold: float = 500.0, recurring_threshold: int = 2):\n",
    "        \"\"\"\n",
    "        Initialize with thresholds\n",
    "        \n",
    "        Args:\n",
    "            amount_threshold: Amount threshold (default 500 KES)\n",
    "            recurring_threshold: Minimum occurrences to be recurring (default 2)\n",
    "        \"\"\"\n",
    "        self.amount_threshold = amount_threshold\n",
    "        self.recurring_threshold = recurring_threshold\n",
    "    \n",
    "    def extract_recipient_id(self, extracted_fields_str: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract recipient identifier from extracted_fields string\n",
    "        \n",
    "        Args:\n",
    "            extracted_fields_str: String representation of extracted fields\n",
    "            \n",
    "        Returns:\n",
    "            Recipient identifier (phone number or name)\n",
    "        \"\"\"\n",
    "        if pd.isna(extracted_fields_str) or extracted_fields_str == '':\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            import ast\n",
    "            fields = ast.literal_eval(extracted_fields_str)\n",
    "            \n",
    "            # Use phone number as primary identifier\n",
    "            if 'recipient_number' in fields:\n",
    "                return fields['recipient_number']\n",
    "            elif 'recipient_name' in fields:\n",
    "                return fields['recipient_name']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def detect_recurring_recipients(self, df: pd.DataFrame) -> Dict[str, int]:\n",
    "        \"\"\"\n",
    "        Detect recurring recipients in Send Money transactions\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with Send Money transactions\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping recipient IDs to occurrence count\n",
    "        \"\"\"\n",
    "        print(\"üîç Detecting recurring recipients in Send Money transactions...\")\n",
    "        \n",
    "        # Filter to uncategorized Send Money only\n",
    "        send_money_df = df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Uncategorized')\n",
    "        ].copy()\n",
    "        \n",
    "        if len(send_money_df) == 0:\n",
    "            print(\"  No uncategorized Send Money transactions found\")\n",
    "            return {}\n",
    "        \n",
    "        # Extract recipient IDs\n",
    "        send_money_df['recipient_id'] = send_money_df['extracted_fields_str'].apply(\n",
    "            self.extract_recipient_id\n",
    "        )\n",
    "        \n",
    "        # Count occurrences\n",
    "        recipient_counts = send_money_df['recipient_id'].value_counts().to_dict()\n",
    "        \n",
    "        # Remove None\n",
    "        recipient_counts = {k: v for k, v in recipient_counts.items() if k is not None}\n",
    "        \n",
    "        # Filter to recurring only\n",
    "        recurring_recipients = {\n",
    "            k: v for k, v in recipient_counts.items() \n",
    "            if v >= self.recurring_threshold\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Found {len(recipient_counts)} unique recipients\")\n",
    "        print(f\"‚úì {len(recurring_recipients)} recurring recipients (‚â•{self.recurring_threshold} transactions)\")\n",
    "        \n",
    "        return recurring_recipients\n",
    "    \n",
    "    def categorize_send_money(self, row: pd.Series, recurring_recipients: Dict) -> str:\n",
    "        \"\"\"\n",
    "        Categorize a single Send Money transaction\n",
    "        \n",
    "        Args:\n",
    "            row: DataFrame row\n",
    "            recurring_recipients: Dict of recurring recipient IDs\n",
    "            \n",
    "        Returns:\n",
    "            Category (Friends & Family or Merchant)\n",
    "        \"\"\"\n",
    "        # Extract recipient ID\n",
    "        recipient_id = self.extract_recipient_id(row['extracted_fields_str'])\n",
    "        \n",
    "        # Check if recurring\n",
    "        is_recurring = recipient_id in recurring_recipients if recipient_id else False\n",
    "        \n",
    "        # Get amount from Withdrawn column\n",
    "        amount = 0\n",
    "        if pd.notna(row['Withdrawn']):\n",
    "            try:\n",
    "                amount = abs(float(row['Withdrawn']))\n",
    "            except:\n",
    "                amount = 0\n",
    "        \n",
    "        # Apply rules\n",
    "        if is_recurring:\n",
    "            if amount > self.amount_threshold:\n",
    "                # RULE 1: Recurring + >500 ‚Üí Friends & Family\n",
    "                return 'Friends & Family'\n",
    "            else:\n",
    "                # RULE 2: Recurring + ‚â§500 ‚Üí Merchant\n",
    "                return 'Merchant'\n",
    "        else:\n",
    "            # RULE 3: Non-recurring (any amount) ‚Üí Merchant\n",
    "            return 'Merchant'\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process entire dataframe - categorize Send Money transactions only\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with category column\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with updated categories\n",
    "        \"\"\"\n",
    "        print(\"ü§ñ Categorizing Send Money transactions...\")\n",
    "        print()\n",
    "        \n",
    "        # Detect recurring recipients\n",
    "        recurring_recipients = self.detect_recurring_recipients(df)\n",
    "        \n",
    "        if recurring_recipients:\n",
    "            print()\n",
    "            print(\"Top 15 recurring recipients:\")\n",
    "            sorted_recipients = sorted(\n",
    "                recurring_recipients.items(), \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True\n",
    "            )[:15]\n",
    "            for recipient, count in sorted_recipients:\n",
    "                print(f\"  {recipient[:45]:45s}: {count:3d} times\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Count before\n",
    "        before_uncat = len(df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Uncategorized')\n",
    "        ])\n",
    "        \n",
    "        # Apply categorization only to uncategorized Send Money\n",
    "        mask = (df['transaction_type'] == 'Send Money') & (df['category'] == 'Uncategorized')\n",
    "        \n",
    "        df.loc[mask, 'category'] = df[mask].apply(\n",
    "            lambda row: self.categorize_send_money(row, recurring_recipients),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Count after\n",
    "        after_uncat = len(df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Uncategorized')\n",
    "        ])\n",
    "        family_friends = len(df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Friends & Family')\n",
    "        ])\n",
    "        merchant = len(df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Merchant')\n",
    "        ])\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        print(\"SEND MONEY CATEGORIZATION RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Processed: {before_uncat:,} Send Money transactions\")\n",
    "        print(f\"  ‚Üí Friends & Family: {family_friends:,}\")\n",
    "        print(f\"  ‚Üí Merchant: {merchant:,}\")\n",
    "        print(f\"  ‚Üí Still Uncategorized: {after_uncat:,}\")\n",
    "        print()\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def run_stage4(input_csv: str, output_csv: str, \n",
    "               amount_threshold: float >= 500.0,  \n",
    "               recurring_threshold: int = 5):\n",
    "    \"\"\"\n",
    "    Run Stage 4: Send Money Categorization\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to Stage 3 output CSV\n",
    "        output_csv: Path to save final categorized CSV\n",
    "        amount_threshold: Amount threshold in KES (default 500)\n",
    "        recurring_threshold: Min occurrences for recurring (default 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 4: SEND MONEY CATEGORIZATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Preserving all Stage 2 & 3 improvements:\")\n",
    "    print(\"   Fuliza (LOAN) vs Fuliza payments\")\n",
    "    print(\"   Loan Repayment separate\")\n",
    "    print(\"   LOOP Payment ‚Üí Income\")\n",
    "    print(\"   Data Bundles ‚â† Airtime\")\n",
    "    print(\"   Cash Deposit ‚â† Cash Withdrawal\")\n",
    "    print()\n",
    "    print(\"RULES:\")\n",
    "    print(f\"  1. Recurring (‚â•{recurring_threshold}) + Amount > {amount_threshold} ‚Üí Friends & Family\")\n",
    "    print(f\"  2. Recurring (‚â•{recurring_threshold}) + Amount ‚â§ {amount_threshold} ‚Üí Merchant\")\n",
    "    print(f\"  3. Non-recurring (any amount) ‚Üí Merchant\")\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\" Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Show current state\n",
    "    print(\"Current categorization:\")\n",
    "    category_counts = df['category'].value_counts()\n",
    "    for category in list(category_counts.head(10).index):\n",
    "        count = category_counts.get(category, 0)\n",
    "        pct = (count / len(df)) * 100 if len(df) > 0 else 0\n",
    "        print(f\"  {category:25s}: {count:5,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    send_money_uncat = len(df[\n",
    "        (df['transaction_type'] == 'Send Money') & \n",
    "        (df['category'] == 'Uncategorized')\n",
    "    ])\n",
    "    print(f\"\\n  Send Money (Uncategorized): {send_money_uncat:,}\")\n",
    "    print()\n",
    "    \n",
    "    # Process\n",
    "    categorizer = SendMoneyCategorizer(\n",
    "        amount_threshold=amount_threshold,\n",
    "        recurring_threshold=recurring_threshold\n",
    "    )\n",
    "    df = categorizer.process_dataframe(df)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL CATEGORY BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    category_counts = df['category'].value_counts().sort_values(ascending=False)\n",
    "    for category, count in category_counts.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{category:30s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Uncategorized check\n",
    "    final_uncat = len(df[df['category'] == 'Uncategorized'])\n",
    "    final_uncat_pct = (final_uncat / len(df)) * 100\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CATEGORIZATION SUCCESS RATE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total transactions: {len(df):,}\")\n",
    "    print(f\"Categorized: {len(df) - final_uncat:,} ({100 - final_uncat_pct:.1f}%)\")\n",
    "    print(f\"Uncategorized: {final_uncat:,} ({final_uncat_pct:.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Sample results\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SAMPLE CATEGORIZATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Friends & Family samples\n",
    "    ff_df = df[\n",
    "        (df['category'] == 'Friends & Family') & \n",
    "        (df['transaction_type'] == 'Send Money')\n",
    "    ]\n",
    "    if len(ff_df) > 0:\n",
    "        print(f\"\\n--- FRIENDS & FAMILY ({len(ff_df):,} transactions) ---\")\n",
    "        for _, row in ff_df.head(5).iterrows():\n",
    "            try:\n",
    "                amount = float(row['Withdrawn']) if pd.notna(row['Withdrawn']) else 0.0\n",
    "            except:\n",
    "                amount = 0.0\n",
    "            desc = row['description_clean'][:55] if pd.notna(row['description_clean']) else ''\n",
    "            print(f\"  KES {amount:>8,.0f} | {desc}\")\n",
    "    \n",
    "    # Merchant samples from Send Money\n",
    "    merchant_df = df[\n",
    "        (df['category'] == 'Merchant') & \n",
    "        (df['transaction_type'] == 'Send Money')\n",
    "    ]\n",
    "    if len(merchant_df) > 0:\n",
    "        print(f\"\\n--- MERCHANT - from Send Money ({len(merchant_df):,} transactions) ---\")\n",
    "        for _, row in merchant_df.head(5).iterrows():\n",
    "            try:\n",
    "                amount = float(row['Withdrawn']) if pd.notna(row['Withdrawn']) else 0.0\n",
    "            except:\n",
    "                amount = 0.0\n",
    "            desc = row['description_clean'][:55] if pd.notna(row['description_clean']) else ''\n",
    "            print(f\"  KES {amount:>8,.0f} | {desc}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Spending summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPENDING SUMMARY BY CATEGORY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    spending_categories = df[df['Withdrawn'].notna()].copy()\n",
    "    spending_categories['Withdrawn'] = pd.to_numeric(spending_categories['Withdrawn'], errors='coerce')\n",
    "    \n",
    "    cat_spending = spending_categories.groupby('category')['Withdrawn'].agg([\n",
    "        ('Total', 'sum'),\n",
    "        ('Count', 'count'),\n",
    "        ('Average', 'mean')\n",
    "    ]).sort_values('Total', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'Category':<30s} {'Total (KES)':>15s} {'Count':>8s} {'Avg (KES)':>12s}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    total_spent = 0\n",
    "    for category, row in cat_spending.head(15).iterrows():\n",
    "        if category not in ['Income', 'Reversal', 'Cash Deposit']:\n",
    "            total_spent += row['Total']\n",
    "            print(f\"{category:<30s} {row['Total']:>15,.2f} {int(row['Count']):>8,} {row['Average']:>12,.2f}\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'TOTAL SPENDING':<30s} {total_spent:>15,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\" Saved final categorized data: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 4 COMPLETE! üéâ\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"Your M-Pesa data is now fully categorized!\")\n",
    "    print(f\"Categorization rate: {100 - final_uncat_pct:.1f}%\")\n",
    "    print(f\"Total spending: KES {total_spent:,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\"\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\"\n",
    "    \n",
    "    # Thresholds\n",
    "    AMOUNT_THRESHOLD = 500.0  # KES\n",
    "    RECURRING_THRESHOLD = 2   # Minimum occurrences\n",
    "    \n",
    "    # Run\n",
    "    df = run_stage4(\n",
    "        INPUT_CSV, \n",
    "        OUTPUT_CSV,\n",
    "        amount_threshold=AMOUNT_THRESHOLD,\n",
    "        recurring_threshold=RECURRING_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    print(\"Next steps:\")\n",
    "    print(\"  ‚Ä¢ Clean the CSV (remove empty/duplicate columns)\")\n",
    "    print(\"  ‚Ä¢ Analyze spending patterns\")\n",
    "    print(\"  ‚Ä¢ Create visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6f2fcd",
   "metadata": {},
   "source": [
    "## Merchant Sub-categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815214d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MERCHANT SUBCATEGORY PREDICTION - TRAINING\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\Merchant sub-categories.csv\n",
      "‚úì Loaded 2,715 transactions\n",
      "\n",
      "üßπ Cleaning subcategory labels...\n",
      "‚úì Cleaned subcategories\n",
      "  Unique subcategories after cleaning: 23\n",
      "‚úì Filtered to 1,125 Merchant transactions\n",
      "‚úì Found 1,118 labeled Merchant transactions\n",
      "\n",
      "================================================================================\n",
      "SUBCATEGORY DISTRIBUTION\n",
      "================================================================================\n",
      "deposit                  :   283 ( 25.3%)\n",
      "food                     :   220 ( 19.7%)\n",
      "transport                :   160 ( 14.3%)\n",
      "family                   :    95 (  8.5%)\n",
      "construction             :    62 (  5.5%)\n",
      "groceries                :    49 (  4.4%)\n",
      "friend                   :    36 (  3.2%)\n",
      "shop                     :    32 (  2.9%)\n",
      "contribution             :    30 (  2.7%)\n",
      "business                 :    30 (  2.7%)\n",
      "kinyozi                  :    22 (  2.0%)\n",
      "labor                    :    21 (  1.9%)\n",
      "withdraw                 :    19 (  1.7%)\n",
      "saving                   :    17 (  1.5%)\n",
      "airtime                  :    15 (  1.3%)\n",
      "... and 7 more subcategories\n",
      "\n",
      "üîç Filtering subcategories with too few examples...\n",
      "  ‚ö†Ô∏è  Removed 1 transactions from rare subcategories (only 1 example)\n",
      "  ‚úì Training with 1,117 transactions\n",
      "  ‚úì Across 21 subcategories\n",
      "\n",
      "üìä Extracting features...\n",
      "‚úì Features extracted\n",
      "üî§ Creating TF-IDF text features...\n",
      "‚úì Created 301 features\n",
      "\n",
      "Training set: 893 samples\n",
      "Test set: 224 samples\n",
      "\n",
      "Training on 21 subcategories\n",
      "\n",
      "================================================================================\n",
      "TRAINING MODELS\n",
      "================================================================================\n",
      "\n",
      "ü§ñ Training Logistic Regression...\n",
      "  ‚úì Test Accuracy: 0.781\n",
      "  ‚úì CV Score: 0.738 (+/- 0.019)\n",
      "\n",
      "ü§ñ Training Random Forest...\n",
      "  ‚úì Test Accuracy: 0.795\n",
      "  ‚úì CV Score: 0.763 (+/- 0.030)\n",
      "\n",
      "================================================================================\n",
      "üèÜ BEST MODEL: Random Forest\n",
      "   Accuracy: 0.795\n",
      "================================================================================\n",
      "\n",
      "CLASSIFICATION REPORT (Top subcategories):\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      business       0.50      0.67      0.57         6\n",
      "      clothing       0.00      0.00      0.00         0\n",
      "  construction       0.40      0.31      0.35        13\n",
      "  contribution       0.00      0.00      0.00         6\n",
      "       deposit       1.00      1.00      1.00        57\n",
      "drinking water       0.00      0.00      0.00         0\n",
      "        family       1.00      0.74      0.85        19\n",
      "          food       1.00      0.98      0.99        44\n",
      "        friend       0.00      0.00      0.00         7\n",
      "          gotv       0.00      0.00      0.00         0\n",
      "     groceries       0.86      0.60      0.71        10\n",
      "        health       0.00      0.00      0.00         0\n",
      "         labor       0.00      0.00      0.00         0\n",
      "          shop       0.62      0.71      0.67         7\n",
      "     transport       0.90      0.81      0.85        32\n",
      "\n",
      "      accuracy                           0.79       201\n",
      "     macro avg       0.42      0.39      0.40       201\n",
      "  weighted avg       0.84      0.79      0.81       201\n",
      "\n",
      "\n",
      "üíæ Saving model to: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\merchant_subcategory_model.pkl\n",
      "‚úì Model saved successfully!\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE! üéâ\n",
      "================================================================================\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 79.5%\n",
      "Trained on: 1,117 examples\n",
      "Subcategories: 21\n",
      "\n",
      "Next step:\n",
      "  Run the prediction script to categorize unlabeled transactions!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MERCHANT SUBCATEGORY PREDICTION - TRAINING\n",
    "Customized for your mpesa_stage6_john.csv data\n",
    "\n",
    "Your data has:\n",
    "- 1,122 labeled merchant subcategories in 'merchant deepdive' column\n",
    "- 37 subcategories (deposit, food, transport, family, construction, etc.)\n",
    "- Ready to train a model!\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def clean_subcategories(df: pd.DataFrame, subcategory_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean up subcategory labels (fix typos, consolidate similar categories)\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame\n",
    "        subcategory_col: Name of subcategory column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with cleaned subcategories\n",
    "    \"\"\"\n",
    "    print(\"üßπ Cleaning subcategory labels...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df[subcategory_col] = df[subcategory_col].astype(str)\n",
    "    \n",
    "    # Fix typos and consolidate\n",
    "    replacements = {\n",
    "        'depoit': 'deposit',\n",
    "        'familly': 'family',\n",
    "        'family=500': 'family',\n",
    "        'family above500': 'family',\n",
    "        'aittime': 'airtime',\n",
    "        'labor,farm': 'labor',\n",
    "        'transport,delivery': 'transport',\n",
    "        'sacco,savings': 'saving',\n",
    "        'health,code': 'health',\n",
    "        'shopping,code': 'shop',\n",
    "        'food,code': 'food',\n",
    "        'gotv,code': 'gotv',\n",
    "        'saving, code': 'saving',\n",
    "        'healthcare': 'health',\n",
    "        'reversed': 'reversal'\n",
    "    }\n",
    "    \n",
    "    df[subcategory_col] = df[subcategory_col].replace(replacements)\n",
    "    \n",
    "    # Remove 'nan' strings\n",
    "    df.loc[df[subcategory_col] == 'nan', subcategory_col] = np.nan\n",
    "    \n",
    "    print(f\"‚úì Cleaned subcategories\")\n",
    "    print(f\"  Unique subcategories after cleaning: {df[subcategory_col].nunique()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract features from transactions\"\"\"\n",
    "    print(\" Extracting features...\")\n",
    "    \n",
    "    # Create combined text features\n",
    "    df['text_features'] = ''\n",
    "    \n",
    "    # Add description\n",
    "    if 'description' in df.columns:\n",
    "        df['text_features'] += df['description'].fillna('') + ' '\n",
    "    \n",
    "    # Add details\n",
    "    if 'details_original' in df.columns:\n",
    "        df['text_features'] += df['details_original'].fillna('') + ' '\n",
    "    \n",
    "    # Extract merchant name from extracted_fields\n",
    "    def extract_merchant_name(fields_str):\n",
    "        if pd.isna(fields_str) or fields_str == '' or fields_str == '{}':\n",
    "            return ''\n",
    "        try:\n",
    "            import ast\n",
    "            fields = ast.literal_eval(fields_str)\n",
    "            name = fields.get('merchant_name', '')\n",
    "            if not name:\n",
    "                name = fields.get('recipient_name', '')\n",
    "            return name\n",
    "        except:\n",
    "            return ''\n",
    "    \n",
    "    if 'extracted_fields' in df.columns:\n",
    "        df['merchant_name'] = df['extracted_fields'].apply(extract_merchant_name)\n",
    "        df['text_features'] += df['merchant_name'].fillna('')\n",
    "    \n",
    "    # Clean text\n",
    "    df['text_features'] = df['text_features'].str.lower()\n",
    "    df['text_features'] = df['text_features'].str.replace(r'[^a-z0-9\\s]', ' ', regex=True)\n",
    "    df['text_features'] = df['text_features'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    df['text_features'] = df['text_features'].str.strip()\n",
    "    \n",
    "    # Amount features\n",
    "    if 'withdrawn' in df.columns:\n",
    "        df['amount'] = pd.to_numeric(df['withdrawn'], errors='coerce').fillna(0).abs()\n",
    "    else:\n",
    "        df['amount'] = 0\n",
    "    \n",
    "    df['amount_log'] = np.log1p(df['amount'])\n",
    "    \n",
    "    print(f\"‚úì Features extracted\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def train_model(input_csv: str, subcategory_col: str, output_model_path: str):\n",
    "    \"\"\"\n",
    "    Train the merchant subcategory prediction model\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to your CSV file\n",
    "        subcategory_col: Name of subcategory column ('merchant deepdive')\n",
    "        output_model_path: Where to save the trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MERCHANT SUBCATEGORY PREDICTION - TRAINING\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"üìÇ Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Clean subcategories\n",
    "    df = clean_subcategories(df, subcategory_col)\n",
    "    \n",
    "    # Filter to MERCHANT category only\n",
    "    if 'category' in df.columns:\n",
    "        df = df[df['category'] == 'Merchant'].copy()\n",
    "        print(f\"‚úì Filtered to {len(df):,} Merchant transactions\")\n",
    "    \n",
    "    # Filter to labeled data only\n",
    "    df_labeled = df[df[subcategory_col].notna()].copy()\n",
    "    print(f\"‚úì Found {len(df_labeled):,} labeled Merchant transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Show distribution\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUBCATEGORY DISTRIBUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    subcategory_counts = df_labeled[subcategory_col].value_counts()\n",
    "    for subcat, count in subcategory_counts.head(15).items():\n",
    "        pct = (count / len(df_labeled)) * 100\n",
    "        print(f\"{subcat:25s}: {count:5,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    if len(subcategory_counts) > 15:\n",
    "        print(f\"... and {len(subcategory_counts) - 15} more subcategories\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Filter out subcategories with only 1 example (can't be split for training/testing)\n",
    "    print(\"üîç Filtering subcategories with too few examples...\")\n",
    "    min_examples = 2\n",
    "    valid_subcategories = subcategory_counts[subcategory_counts >= min_examples].index\n",
    "    \n",
    "    before_filter = len(df_labeled)\n",
    "    df_labeled = df_labeled[df_labeled[subcategory_col].isin(valid_subcategories)]\n",
    "    removed = before_filter - len(df_labeled)\n",
    "    \n",
    "    if removed > 0:\n",
    "        print(f\"  ‚ö†Ô∏è  Removed {removed} transactions from rare subcategories (only 1 example)\")\n",
    "        print(f\"  ‚úì Training with {len(df_labeled):,} transactions\")\n",
    "        print(f\"  ‚úì Across {len(valid_subcategories)} subcategories\")\n",
    "    else:\n",
    "        print(f\"  ‚úì All subcategories have enough examples\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Extract features\n",
    "    df_labeled = extract_features(df_labeled)\n",
    "    \n",
    "    # Create TF-IDF features\n",
    "    print(\"üî§ Creating TF-IDF text features...\")\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=300,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.9\n",
    "    )\n",
    "    \n",
    "    X_text = vectorizer.fit_transform(df_labeled['text_features'])\n",
    "    tfidf_df = pd.DataFrame(\n",
    "        X_text.toarray(),\n",
    "        columns=[f'tfidf_{i}' for i in range(X_text.shape[1])],\n",
    "        index=df_labeled.index\n",
    "    )\n",
    "    \n",
    "    # Add amount feature\n",
    "    amount_features = df_labeled[['amount_log']].copy()\n",
    "    \n",
    "    # Combine features\n",
    "    X = pd.concat([tfidf_df, amount_features], axis=1)\n",
    "    \n",
    "    # Target variable\n",
    "    y = df_labeled[subcategory_col]\n",
    "    \n",
    "    print(f\"‚úì Created {X.shape[1]} features\")\n",
    "    print()\n",
    "    \n",
    "    # Check if we can use stratification (need at least 2 examples per class)\n",
    "    class_counts = y.value_counts()\n",
    "    can_stratify = (class_counts >= 2).all()\n",
    "    \n",
    "    if not can_stratify:\n",
    "        print(\"‚ö†Ô∏è  Some subcategories have only 1 example - using random split instead of stratified\")\n",
    "    \n",
    "    # Split data\n",
    "    if can_stratify:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "    \n",
    "    \n",
    "    print(f\"Training set: {len(X_train):,} samples\")\n",
    "    print(f\"Test set: {len(X_test):,} samples\")\n",
    "    print()\n",
    "    \n",
    "    # Check if stratification was successful\n",
    "    print(f\"Training on {y_train.nunique()} subcategories\")\n",
    "    print()\n",
    "    \n",
    "    # Train models\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TRAINING MODELS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            C=1.0\n",
    "        ),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            random_state=42,\n",
    "            class_weight='balanced',\n",
    "            min_samples_split=5\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = ''\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"ü§ñ Training {model_name}...\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        \n",
    "        print(f\"  ‚úì Test Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"  ‚úì CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n",
    "        print()\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"   Accuracy: {best_accuracy:.3f}\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Classification report for best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(\"CLASSIFICATION REPORT (Top subcategories):\")\n",
    "    print()\n",
    "    \n",
    "    # Show report for top categories only (to avoid clutter)\n",
    "    top_categories = subcategory_counts.head(10).index.tolist()\n",
    "    \n",
    "    # Filter test data to top categories\n",
    "    mask = y_test.isin(top_categories)\n",
    "    if mask.sum() > 0:\n",
    "        print(classification_report(y_test[mask], y_pred[mask], zero_division=0))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save model\n",
    "    print(f\"üíæ Saving model to: {output_model_path}\")\n",
    "    \n",
    "    model_data = {\n",
    "        'vectorizer': vectorizer,\n",
    "        'model': best_model,\n",
    "        'subcategories': list(y.unique()),\n",
    "        'model_name': best_model_name,\n",
    "        'accuracy': best_accuracy\n",
    "    }\n",
    "    \n",
    "    joblib.dump(model_data, output_model_path)\n",
    "    print(\"‚úì Model saved successfully!\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"TRAINING COMPLETE! üéâ\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(f\"Model: {best_model_name}\")\n",
    "    print(f\"Accuracy: {best_accuracy:.1%}\")\n",
    "    print(f\"Trained on: {len(df_labeled):,} examples\")\n",
    "    print(f\"Subcategories: {len(y.unique())}\")\n",
    "    print()\n",
    "    print(\"Next step:\")\n",
    "    print(\"  Run the prediction script to categorize unlabeled transactions!\")\n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your file paths\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\Merchant sub-categories.csv\"\n",
    "    SUBCATEGORY_COL = \"merchant deepdive\"\n",
    "    OUTPUT_MODEL = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\merchant_subcategory_model.pkl\"\n",
    "    \n",
    "    # Train\n",
    "    train_model(INPUT_CSV, SUBCATEGORY_COL, OUTPUT_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc8f1a",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50228651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MERCHANT SUBCATEGORY PREDICTION - INFERENCE\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading model: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\merchant_subcategory_model.pkl\n",
      "‚úì Loaded Random Forest (Accuracy: 79.5%)\n",
      "‚úì Trained on 21 subcategories\n",
      "\n",
      "üìÇ Loading data: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\Merchant sub-categories.csv\n",
      "‚úì Loaded 2,715 transactions\n",
      "\n",
      "‚úì Found 1,125 Merchant transactions\n",
      "‚úì Found 7 unlabeled Merchant transactions\n",
      "\n",
      "Unlabeled Merchants to predict: 7\n",
      "\n",
      "üîÆ Making predictions...\n",
      "‚úì Predictions complete!\n",
      "\n",
      "================================================================================\n",
      "PREDICTION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Predicted subcategories:\n",
      "  deposit                  :     1 ( 14.3%) - Avg Conf: 1.00\n",
      "  food                     :     1 ( 14.3%) - Avg Conf: 0.95\n",
      "  contribution             :     1 ( 14.3%) - Avg Conf: 0.18\n",
      "  clothing                 :     1 ( 14.3%) - Avg Conf: 0.25\n",
      "  business                 :     1 ( 14.3%) - Avg Conf: 0.18\n",
      "  groceries                :     1 ( 14.3%) - Avg Conf: 0.26\n",
      "  airtime                  :     1 ( 14.3%) - Avg Conf: 0.93\n",
      "\n",
      "Confidence distribution:\n",
      "  High (‚â•0.7):         3 ( 42.9%)\n",
      "  Medium (0.4-0.7):     0 (  0.0%)\n",
      "  Low (<0.4):          4 ( 57.1%) ‚ö†Ô∏è  Review needed\n",
      "\n",
      "================================================================================\n",
      "SAMPLE PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "HIGH CONFIDENCE PREDICTIONS:\n",
      "  deposit              (1.00) | Deposit of Funds at Agent Till 265020 - Simnett Na\n",
      "  food                 (0.95) | Customer Transfer to - 2547******463 Peter Thuo\n",
      "  airtime              (0.93) | Pay Bill to 220220 - PesaPal Acc. AIRT0752061289\n",
      "\n",
      "LOW CONFIDENCE PREDICTIONS (REVIEW THESE):\n",
      "  contribution         (0.18) | Customer Transfer to - 2547******506 ISAAC MUIRURI\n",
      "  clothing             (0.25) | Customer Transfer to - 2547******167 VIRGINIA NGUG\n",
      "  business             (0.18) | Customer Transfer to - 2547******055 JOSEPH KARURI\n",
      "  groceries            (0.26) | Merchant Payment to 5084236 - MARGRET SEREKA\n",
      "\n",
      "üíæ Saving results to: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_with_all_subcategories.csv\n",
      "‚úì Saved!\n",
      "\n",
      "‚ö†Ô∏è  Saved 4 low-confidence predictions to:\n",
      "   C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_with_all_subcategories_needs_review.csv\n",
      "   Please review these manually!\n",
      "\n",
      "================================================================================\n",
      "PREDICTION COMPLETE! üéâ\n",
      "================================================================================\n",
      "\n",
      "Total labeled: 1,129\n",
      "  - Manual: 2,708\n",
      "  - Predicted: 7\n",
      "\n",
      "Final subcategory distribution:\n",
      "  deposit                  :   285 ( 10.5%)\n",
      "  food                     :   220 (  8.1%)\n",
      "  transport                :   159 (  5.9%)\n",
      "  family                   :    92 (  3.4%)\n",
      "  construction             :    62 (  2.3%)\n",
      "  groceries                :    50 (  1.8%)\n",
      "  friend                   :    36 (  1.3%)\n",
      "  shop                     :    32 (  1.2%)\n",
      "  contribution             :    31 (  1.1%)\n",
      "  business                 :    31 (  1.1%)\n",
      "\n",
      "‚úÖ All done! Check your output files.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MERCHANT SUBCATEGORY PREDICTION - INFERENCE\n",
    "Predicts subcategories for unlabeled transactions using trained model\n",
    "\n",
    "Your unlabeled data:\n",
    "- 1,593 transactions without subcategories\n",
    "- Mostly in: Transfers, Bills, Income, Savings, Online Shopping\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def extract_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Extract same features used in training\"\"\"\n",
    "    \n",
    "    # Create combined text features\n",
    "    df['text_features'] = ''\n",
    "    \n",
    "    if 'description' in df.columns:\n",
    "        df['text_features'] += df['description'].fillna('') + ' '\n",
    "    \n",
    "    if 'details_original' in df.columns:\n",
    "        df['text_features'] += df['details_original'].fillna('') + ' '\n",
    "    \n",
    "    # Extract merchant name\n",
    "    def extract_merchant_name(fields_str):\n",
    "        if pd.isna(fields_str) or fields_str == '' or fields_str == '{}':\n",
    "            return ''\n",
    "        try:\n",
    "            import ast\n",
    "            fields = ast.literal_eval(fields_str)\n",
    "            name = fields.get('merchant_name', '')\n",
    "            if not name:\n",
    "                name = fields.get('recipient_name', '')\n",
    "            return name\n",
    "        except:\n",
    "            return ''\n",
    "    \n",
    "    if 'extracted_fields' in df.columns:\n",
    "        df['merchant_name'] = df['extracted_fields'].apply(extract_merchant_name)\n",
    "        df['text_features'] += df['merchant_name'].fillna('')\n",
    "    \n",
    "    # Clean text\n",
    "    df['text_features'] = df['text_features'].str.lower()\n",
    "    df['text_features'] = df['text_features'].str.replace(r'[^a-z0-9\\s]', ' ', regex=True)\n",
    "    df['text_features'] = df['text_features'].str.replace(r'\\s+', ' ', regex=True)\n",
    "    df['text_features'] = df['text_features'].str.strip()\n",
    "    \n",
    "    # Amount features\n",
    "    if 'withdrawn' in df.columns:\n",
    "        df['amount'] = pd.to_numeric(df['withdrawn'], errors='coerce').fillna(0).abs()\n",
    "    else:\n",
    "        df['amount'] = 0\n",
    "    \n",
    "    df['amount_log'] = np.log1p(df['amount'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def predict_subcategories(input_csv: str, \n",
    "                         model_path: str, \n",
    "                         subcategory_col: str,\n",
    "                         output_csv: str,\n",
    "                         confidence_threshold: float = 0.4):\n",
    "    \"\"\"\n",
    "    Predict subcategories for unlabeled transactions\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Your data file\n",
    "        model_path: Trained model file\n",
    "        subcategory_col: Column name for subcategories\n",
    "        output_csv: Where to save results\n",
    "        confidence_threshold: Minimum confidence (0-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MERCHANT SUBCATEGORY PREDICTION - INFERENCE\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"üìÇ Loading model: {model_path}\")\n",
    "    model_data = joblib.load(model_path)\n",
    "    \n",
    "    vectorizer = model_data['vectorizer']\n",
    "    model = model_data['model']\n",
    "    model_name = model_data['model_name']\n",
    "    accuracy = model_data['accuracy']\n",
    "    \n",
    "    print(f\"‚úì Loaded {model_name} (Accuracy: {accuracy:.1%})\")\n",
    "    print(f\"‚úì Trained on {len(model_data['subcategories'])} subcategories\")\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"üìÇ Loading data: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Check if subcategory column exists, if not create it\n",
    "    if subcategory_col not in df.columns:\n",
    "        print(f\"‚ö†Ô∏è  Column '{subcategory_col}' not found - creating it\")\n",
    "        df[subcategory_col] = np.nan\n",
    "    \n",
    "    # Filter to MERCHANT category ONLY\n",
    "    if 'category' in df.columns:\n",
    "        merchant_mask = df['category'] == 'Merchant'\n",
    "        print(f\"‚úì Found {merchant_mask.sum():,} Merchant transactions\")\n",
    "        \n",
    "        # Find unlabeled merchants\n",
    "        df[subcategory_col] = df[subcategory_col].astype(str)\n",
    "        df.loc[df[subcategory_col] == 'nan', subcategory_col] = np.nan\n",
    "        \n",
    "        unlabeled_mask = merchant_mask & df[subcategory_col].isna()\n",
    "        df_unlabeled = df[unlabeled_mask].copy()\n",
    "        \n",
    "        print(f\"‚úì Found {len(df_unlabeled):,} unlabeled Merchant transactions\")\n",
    "        print()\n",
    "    else:\n",
    "        # Fallback if no category column\n",
    "        df[subcategory_col] = df[subcategory_col].astype(str)\n",
    "        df.loc[df[subcategory_col] == 'nan', subcategory_col] = np.nan\n",
    "        \n",
    "        unlabeled_mask = df[subcategory_col].isna()\n",
    "        df_unlabeled = df[unlabeled_mask].copy()\n",
    "        \n",
    "        print(f\"‚úì Found {len(df_unlabeled):,} unlabeled transactions\")\n",
    "        print()\n",
    "    \n",
    "    if len(df_unlabeled) == 0:\n",
    "        print(\"‚úÖ All Merchant transactions already labeled!\")\n",
    "        print()\n",
    "        print(\"Your data is complete:\")\n",
    "        print(f\"  Total transactions: {len(df):,}\")\n",
    "        print(f\"  Merchant (labeled): {merchant_mask.sum():,}\")\n",
    "        print(f\"  Other categories: {(~merchant_mask).sum():,}\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"Unlabeled Merchants to predict: {len(df_unlabeled):,}\")\n",
    "    print()\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"üîÆ Making predictions...\")\n",
    "    df_unlabeled = extract_features(df_unlabeled)\n",
    "    \n",
    "    # Transform text\n",
    "    X_text = vectorizer.transform(df_unlabeled['text_features'])\n",
    "    tfidf_df = pd.DataFrame(\n",
    "        X_text.toarray(),\n",
    "        columns=[f'tfidf_{i}' for i in range(X_text.shape[1])],\n",
    "        index=df_unlabeled.index\n",
    "    )\n",
    "    \n",
    "    # Add amount features\n",
    "    amount_features = df_unlabeled[['amount_log']].copy()\n",
    "    \n",
    "    # Combine\n",
    "    X = pd.concat([tfidf_df, amount_features], axis=1)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X)\n",
    "    probabilities = model.predict_proba(X)\n",
    "    max_probs = probabilities.max(axis=1)\n",
    "    \n",
    "    # Add predictions to unlabeled data\n",
    "    df_unlabeled['predicted_subcategory'] = predictions\n",
    "    df_unlabeled['prediction_confidence'] = max_probs\n",
    "    df_unlabeled['needs_review'] = max_probs < confidence_threshold\n",
    "    \n",
    "    print(f\"‚úì Predictions complete!\")\n",
    "    print()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREDICTION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    print(\"Predicted subcategories:\")\n",
    "    for subcat, count in df_unlabeled['predicted_subcategory'].value_counts().head(15).items():\n",
    "        pct = (count / len(df_unlabeled)) * 100\n",
    "        avg_conf = df_unlabeled[df_unlabeled['predicted_subcategory'] == subcat]['prediction_confidence'].mean()\n",
    "        print(f\"  {subcat:25s}: {count:5,} ({pct:5.1f}%) - Avg Conf: {avg_conf:.2f}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"Confidence distribution:\")\n",
    "    high = len(df_unlabeled[df_unlabeled['prediction_confidence'] >= 0.7])\n",
    "    med = len(df_unlabeled[(df_unlabeled['prediction_confidence'] >= 0.4) & \n",
    "                          (df_unlabeled['prediction_confidence'] < 0.7)])\n",
    "    low = len(df_unlabeled[df_unlabeled['prediction_confidence'] < 0.4])\n",
    "    \n",
    "    print(f\"  High (‚â•0.7):     {high:5,} ({high/len(df_unlabeled)*100:5.1f}%)\")\n",
    "    print(f\"  Medium (0.4-0.7): {med:5,} ({med/len(df_unlabeled)*100:5.1f}%)\")\n",
    "    print(f\"  Low (<0.4):      {low:5,} ({low/len(df_unlabeled)*100:5.1f}%) ‚ö†Ô∏è  Review needed\")\n",
    "    print()\n",
    "    \n",
    "    # Merge predictions back to original dataframe\n",
    "    # For unlabeled rows, use predictions; for labeled rows, keep original\n",
    "    df.loc[unlabeled_mask, subcategory_col] = df_unlabeled['predicted_subcategory'].values\n",
    "    \n",
    "    # Add prediction metadata columns if they don't exist\n",
    "    if 'prediction_confidence' not in df.columns:\n",
    "        df['prediction_confidence'] = np.nan\n",
    "    if 'needs_review' not in df.columns:\n",
    "        df['needs_review'] = False\n",
    "    if 'was_manually_labeled' not in df.columns:\n",
    "        df['was_manually_labeled'] = False\n",
    "    \n",
    "    df.loc[unlabeled_mask, 'prediction_confidence'] = df_unlabeled['prediction_confidence'].values\n",
    "    df.loc[unlabeled_mask, 'needs_review'] = df_unlabeled['needs_review'].values\n",
    "    \n",
    "    # Mark originally labeled rows (if any were labeled before)\n",
    "    df.loc[~unlabeled_mask & merchant_mask, 'was_manually_labeled'] = True\n",
    "    \n",
    "    # Sample predictions\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SAMPLE PREDICTIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # High confidence\n",
    "    high_conf = df_unlabeled[df_unlabeled['prediction_confidence'] >= 0.7]\n",
    "    if len(high_conf) > 0:\n",
    "        print(\"HIGH CONFIDENCE PREDICTIONS:\")\n",
    "        for _, row in high_conf.head(5).iterrows():\n",
    "            desc = row['description'][:50] if pd.notna(row['description']) else ''\n",
    "            subcat = row['predicted_subcategory']\n",
    "            conf = row['prediction_confidence']\n",
    "            print(f\"  {subcat:20s} ({conf:.2f}) | {desc}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Low confidence\n",
    "    low_conf = df_unlabeled[df_unlabeled['prediction_confidence'] < 0.4]\n",
    "    if len(low_conf) > 0:\n",
    "        print(\"LOW CONFIDENCE PREDICTIONS (REVIEW THESE):\")\n",
    "        for _, row in low_conf.head(5).iterrows():\n",
    "            desc = row['description'][:50] if pd.notna(row['description']) else ''\n",
    "            subcat = row['predicted_subcategory']\n",
    "            conf = row['prediction_confidence']\n",
    "            print(f\"  {subcat:20s} ({conf:.2f}) | {desc}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    print(f\"üíæ Saving results to: {output_csv}\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(\"‚úì Saved!\")\n",
    "    print()\n",
    "    \n",
    "    # Save low confidence for review\n",
    "    if low < len(df_unlabeled):\n",
    "        review_file = output_csv.replace('.csv', '_needs_review.csv')\n",
    "        df_review = df[df.get('needs_review', False) == True]\n",
    "        df_review.to_csv(review_file, index=False)\n",
    "        print(f\"‚ö†Ô∏è  Saved {len(df_review):,} low-confidence predictions to:\")\n",
    "        print(f\"   {review_file}\")\n",
    "        print(\"   Please review these manually!\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"PREDICTION COMPLETE! üéâ\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(f\"Total labeled: {len(df[df[subcategory_col].notna()]):,}\")\n",
    "    print(f\"  - Manual: {(~unlabeled_mask).sum():,}\")\n",
    "    print(f\"  - Predicted: {len(df_unlabeled):,}\")\n",
    "    print()\n",
    "    print(\"Final subcategory distribution:\")\n",
    "    for subcat, count in df[subcategory_col].value_counts().head(10).items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {subcat:25s}: {count:5,} ({pct:5.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Your file paths\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\Merchant sub-categories.csv\"\n",
    "    MODEL_PATH = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\merchant_subcategory_model.pkl\"\n",
    "    SUBCATEGORY_COL = \"merchant deepdive\"\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_with_all_subcategories.csv\"\n",
    "    \n",
    "    # Confidence threshold (lower = more predictions, but less confident)\n",
    "    CONFIDENCE_THRESHOLD = 0.4\n",
    "    \n",
    "    # Predict\n",
    "    df_final = predict_subcategories(\n",
    "        INPUT_CSV,\n",
    "        MODEL_PATH,\n",
    "        SUBCATEGORY_COL,\n",
    "        OUTPUT_CSV,\n",
    "        CONFIDENCE_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ All done! Check your output files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befad16b",
   "metadata": {},
   "source": [
    "## Final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9be259c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL CSV GENERATOR - MERCHANT SUBCATEGORY INTEGRATION\n",
      "================================================================================\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_with_all_subcategories.csv\n",
      "‚úì Loaded 2,715 transactions\n",
      "\n",
      "üîÑ Creating unified category column...\n",
      "‚úì Replaced 1,125 'Merchant' entries with specific subcategories\n",
      "\n",
      "================================================================================\n",
      "FINAL CATEGORY BREAKDOWN\n",
      "================================================================================\n",
      "\n",
      "MAIN CATEGORIES:\n",
      "  Income                        :    241 (  8.9%)\n",
      "  M-Pesa Fees                   :    779 ( 28.7%)\n",
      "  Transfers                     :    148 (  5.5%)\n",
      "  Bills                         :    104 (  3.8%)\n",
      "  Savings                       :     70 (  2.6%)\n",
      "  Online Shopping               :     72 (  2.7%)\n",
      "  Friends & Family              :     60 (  2.2%)\n",
      "  Cash Withdrawal               :     41 (  1.5%)\n",
      "  Airtime & Data                :     30 (  1.1%)\n",
      "  Shopping                      :     11 (  0.4%)\n",
      "  Education                     :     11 (  0.4%)\n",
      "  Personal Care                 :      7 (  0.3%)\n",
      "  Health Care                   :      5 (  0.2%)\n",
      "  Fast Foods                    :      1 (  0.0%)\n",
      "  Entertainment                 :      1 (  0.0%)\n",
      "  Reversal                      :      4 (  0.1%)\n",
      "  Other                         :      4 (  0.1%)\n",
      "\n",
      "MERCHANT SUBCATEGORIES:\n",
      "  Uncategorized                 :      1 (  0.0%)\n",
      "  airtime                       :     15 (  0.6%)\n",
      "  aittime                       :      1 (  0.0%)\n",
      "  business                      :     31 (  1.1%)\n",
      "  clothing                      :      6 (  0.2%)\n",
      "  construction                  :     62 (  2.3%)\n",
      "  contribution                  :     31 (  1.1%)\n",
      "  depoit                        :      1 (  0.0%)\n",
      "  deposit                       :    283 ( 10.4%)\n",
      "  drinking water                :      3 (  0.1%)\n",
      "  familly                       :      1 (  0.0%)\n",
      "  family                        :     92 (  3.4%)\n",
      "  family above500               :      1 (  0.0%)\n",
      "  family=500                    :      1 (  0.0%)\n",
      "  food                          :    220 (  8.1%)\n",
      "  food,code                     :      1 (  0.0%)\n",
      "  friend                        :     36 (  1.3%)\n",
      "  funeral home                  :      2 (  0.1%)\n",
      "  gotv                          :      1 (  0.0%)\n",
      "  gotv,code                     :      1 (  0.0%)\n",
      "  groceries                     :     50 (  1.8%)\n",
      "  health                        :      1 (  0.0%)\n",
      "  health,code                   :      1 (  0.0%)\n",
      "  healthcare                    :      1 (  0.0%)\n",
      "  investment                    :     11 (  0.4%)\n",
      "  kinyozi                       :     22 (  0.8%)\n",
      "  labor                         :      1 (  0.0%)\n",
      "  labor,farm                    :     20 (  0.7%)\n",
      "  reversed                      :      1 (  0.0%)\n",
      "  sacco,savings                 :      1 (  0.0%)\n",
      "  saving                        :     15 (  0.6%)\n",
      "  saving, code                  :      1 (  0.0%)\n",
      "  shop                          :     32 (  1.2%)\n",
      "  transport                     :    159 (  5.9%)\n",
      "  transport,delivery            :      1 (  0.0%)\n",
      "  withdraw                      :     19 (  0.7%)\n",
      "\n",
      "================================================================================\n",
      "CREATING CLEAN FINAL CSV\n",
      "================================================================================\n",
      "\n",
      "Final columns included:\n",
      "   1. receipt_no                -     0 nulls ( 0.0%)\n",
      "   2. completion_time           -     0 nulls ( 0.0%)\n",
      "   3. description               -     1 nulls ( 0.0%)\n",
      "   4. type                      -     0 nulls ( 0.0%)\n",
      "   5. withdrawn                 -   586 nulls (21.6%)\n",
      "   6. paid_in                   - 2,129 nulls (78.4%)\n",
      "   7. balance                   -     0 nulls ( 0.0%)\n",
      "   8. final_category            -     0 nulls ( 0.0%)\n",
      "   9. extracted_fields          -     0 nulls ( 0.0%)\n",
      "  10. prediction_confidence     - 2,708 nulls (99.7%)\n",
      "  11. was_manually_labeled      -     0 nulls ( 0.0%)\n",
      "\n",
      "üíæ Saving final CSV to: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_final_categorized.csv\n",
      "‚úì Saved successfully!\n",
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Total transactions: 2,715\n",
      "Total categories: 53\n",
      "Merchant subcategories: 36\n",
      "Main categories: 17\n",
      "\n",
      "================================================================================\n",
      "SPENDING BY CATEGORY (Top 15)\n",
      "================================================================================\n",
      "\n",
      "Category                           Total (KES)    Count    Avg (KES)\n",
      "--------------------------------------------------------------------------------\n",
      "Friends & Family                     38,151.00       60       635.85\n",
      "food                                 28,425.00      218       130.39\n",
      "M-Pesa Fees                          21,475.00      779        27.57\n",
      "Bills                                21,031.00       45       467.36\n",
      "transport                            11,820.00      157        75.29\n",
      "Transfers                             8,760.00       24       365.00\n",
      "family                                6,379.00       21       303.76\n",
      "shop                                  5,388.00       27       199.56\n",
      "friend                                5,250.00       15       350.00\n",
      "groceries                             4,609.00       49        94.06\n",
      "construction                          3,548.00       12       295.67\n",
      "business                              3,529.00       12       294.08\n",
      "Airtime & Data                        3,270.00       29       112.76\n",
      "withdraw                              3,150.00        6       525.00\n",
      "Savings                               2,817.00        8       352.12\n",
      "\n",
      "================================================================================\n",
      "SAMPLE TRANSACTIONS (Final Format)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "M-Pesa Fees (779 total):\n",
      "         -34 | Pay Bill Charge\n",
      "         -10 | Pay Bill Charge\n",
      "\n",
      "deposit (283 total):\n",
      "             | Deposit of Funds at Agent Till 158065 - Washindi S\n",
      "             | Deposit of Funds at Agent Till 420487 - Kilwa Agen\n",
      "\n",
      "Income (241 total):\n",
      "             | Funds received from - 2547******113 NDEGE KAUSI\n",
      "             | Funds received from - 2547******067 Timothy Machar\n",
      "\n",
      "food (220 total):\n",
      "        -500 | Merchant Payment to 7798896 - DAVID MUIRURI KAHUKI\n",
      "        -120 | Customer Transfer to - 2547******463 Peter Thuo\n",
      "\n",
      "transport (159 total):\n",
      "         -50 | Customer Payment to Small Business to - 07******27\n",
      "         -50 | Customer Transfer to - 2547******105 Paul kariuki\n",
      "\n",
      "================================================================================\n",
      "FINAL CSV GENERATION COMPLETE! üéâ\n",
      "================================================================================\n",
      "\n",
      "Output file: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_final_categorized.csv\n",
      "\n",
      "Your data is now ready for:\n",
      "  ‚Ä¢ Analysis and visualization\n",
      "  ‚Ä¢ Spending reports\n",
      "  ‚Ä¢ Budget tracking\n",
      "  ‚Ä¢ Financial insights\n",
      "\n",
      "‚úÖ All files generated successfully!\n",
      "\n",
      "Files created:\n",
      "  1. C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_final_categorized.csv - Your final clean data\n",
      "  2. C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\category_mapping_report.csv - Category mapping details\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FINAL CSV GENERATOR\n",
    "Creates a clean, final CSV with:\n",
    "- Original categories (Income, Bills, Transfers, etc.) remain as-is\n",
    "- Merchant category replaced with specific subcategories (food, transport, deposit, etc.)\n",
    "- Clean column names and structure\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_final_csv(input_csv: str, \n",
    "                      output_csv: str,\n",
    "                      subcategory_col: str = 'merchant deepdive',\n",
    "                      main_category_col: str = 'category'):\n",
    "    \"\"\"\n",
    "    Generate final CSV with merchant subcategories replacing the generic Merchant category\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to CSV with predictions (mpesa_with_all_subcategories.csv)\n",
    "        output_csv: Path to save final clean CSV\n",
    "        subcategory_col: Name of merchant subcategory column\n",
    "        main_category_col: Name of main category column\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL CSV GENERATOR - MERCHANT SUBCATEGORY INTEGRATION\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"üìÇ Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Create final category column\n",
    "    print(\"üîÑ Creating unified category column...\")\n",
    "    \n",
    "    # Start with main category\n",
    "    df['final_category'] = df[main_category_col].copy()\n",
    "    \n",
    "    # Replace \"Merchant\" with specific subcategories\n",
    "    if subcategory_col in df.columns:\n",
    "        merchant_mask = df[main_category_col] == 'Merchant'\n",
    "        has_subcategory = df[subcategory_col].notna()\n",
    "        \n",
    "        # For Merchant transactions with subcategories, use the subcategory\n",
    "        replace_mask = merchant_mask & has_subcategory\n",
    "        df.loc[replace_mask, 'final_category'] = df.loc[replace_mask, subcategory_col]\n",
    "        \n",
    "        replaced_count = replace_mask.sum()\n",
    "        print(f\"‚úì Replaced {replaced_count:,} 'Merchant' entries with specific subcategories\")\n",
    "        \n",
    "        # Check for any Merchants without subcategories\n",
    "        unclassified_merchants = merchant_mask & ~has_subcategory\n",
    "        if unclassified_merchants.sum() > 0:\n",
    "            print(f\"‚ö†Ô∏è  {unclassified_merchants.sum()} Merchant transactions still without subcategories\")\n",
    "            print(\"   These will remain as 'Merchant'\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Column '{subcategory_col}' not found - keeping all categories as-is\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Show category distribution\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL CATEGORY BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    category_counts = df['final_category'].value_counts()\n",
    "    \n",
    "    # Separate merchant subcategories from main categories\n",
    "    main_categories = ['Income', 'M-Pesa Fees', 'Transfers', 'Bills', 'Savings', \n",
    "                      'Online Shopping', 'Friends & Family', 'Cash Withdrawal',\n",
    "                      'Airtime & Data', 'Shopping', 'Education', 'Personal Care',\n",
    "                      'Health Care', 'Fast Foods', 'Entertainment', 'Transport',\n",
    "                      'Food & Dining', 'Reversal', 'Other', 'Merchant']\n",
    "    \n",
    "    # Show main categories first\n",
    "    print(\"MAIN CATEGORIES:\")\n",
    "    for cat in main_categories:\n",
    "        if cat in category_counts.index:\n",
    "            count = category_counts[cat]\n",
    "            pct = (count / len(df)) * 100\n",
    "            print(f\"  {cat:30s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    print(\"MERCHANT SUBCATEGORIES:\")\n",
    "    merchant_subcats = [cat for cat in category_counts.index if cat not in main_categories]\n",
    "    for cat in sorted(merchant_subcats):\n",
    "        count = category_counts[cat]\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"  {cat:30s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Select essential columns for final CSV\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CREATING CLEAN FINAL CSV\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Define columns to keep\n",
    "    essential_columns = [\n",
    "        'receipt_no',\n",
    "        'completion_time',\n",
    "        'description',\n",
    "        'type',\n",
    "        'withdrawn',\n",
    "        'paid_in',\n",
    "        'balance',\n",
    "        'final_category'\n",
    "    ]\n",
    "    \n",
    "    # Check which columns exist\n",
    "    available_columns = [col for col in essential_columns if col in df.columns]\n",
    "    \n",
    "    # Add optional useful columns if they exist\n",
    "    optional_columns = ['extracted_fields', 'prediction_confidence', 'was_manually_labeled']\n",
    "    for col in optional_columns:\n",
    "        if col in df.columns:\n",
    "            available_columns.append(col)\n",
    "    \n",
    "    df_final = df[available_columns].copy()\n",
    "    \n",
    "    print(\"Final columns included:\")\n",
    "    for i, col in enumerate(df_final.columns, 1):\n",
    "        null_count = df_final[col].isna().sum()\n",
    "        null_pct = (null_count / len(df_final)) * 100\n",
    "        print(f\"  {i:2d}. {col:25s} - {null_count:5,} nulls ({null_pct:4.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    print(f\"üíæ Saving final CSV to: {output_csv}\")\n",
    "    df_final.to_csv(output_csv, index=False)\n",
    "    print(\"‚úì Saved successfully!\")\n",
    "    print()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    total_categories = df_final['final_category'].nunique()\n",
    "    print(f\"Total transactions: {len(df_final):,}\")\n",
    "    print(f\"Total categories: {total_categories}\")\n",
    "    print(f\"Merchant subcategories: {len(merchant_subcats)}\")\n",
    "    print(f\"Main categories: {len([c for c in main_categories if c in category_counts.index])}\")\n",
    "    print()\n",
    "    \n",
    "    # Spending analysis (if withdrawn column exists)\n",
    "    if 'withdrawn' in df_final.columns:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"SPENDING BY CATEGORY (Top 15)\")\n",
    "        print(\"=\" * 80)\n",
    "        print()\n",
    "        \n",
    "        spending_df = df_final[df_final['withdrawn'].notna()].copy()\n",
    "        spending_df['withdrawn'] = pd.to_numeric(spending_df['withdrawn'], errors='coerce').abs()\n",
    "        \n",
    "        category_spending = spending_df.groupby('final_category')['withdrawn'].agg([\n",
    "            ('Total', 'sum'),\n",
    "            ('Count', 'count'),\n",
    "            ('Average', 'mean')\n",
    "        ]).sort_values('Total', ascending=False).head(15)\n",
    "        \n",
    "        print(f\"{'Category':<30s} {'Total (KES)':>15s} {'Count':>8s} {'Avg (KES)':>12s}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for category, row in category_spending.iterrows():\n",
    "            if category not in ['Income', 'Reversal']:\n",
    "                print(f\"{category:<30s} {row['Total']:>15,.2f} {int(row['Count']):>8,} {row['Average']:>12,.2f}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Sample transactions\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SAMPLE TRANSACTIONS (Final Format)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Show samples from different categories\n",
    "    sample_categories = df_final['final_category'].value_counts().head(5).index\n",
    "    for cat in sample_categories:\n",
    "        cat_df = df_final[df_final['final_category'] == cat]\n",
    "        print(f\"\\n{cat} ({len(cat_df):,} total):\")\n",
    "        for _, row in cat_df.head(2).iterrows():\n",
    "            desc = str(row['description'])[:50] if pd.notna(row['description']) else ''\n",
    "            amount = row['withdrawn'] if pd.notna(row.get('withdrawn', '')) else ''\n",
    "            print(f\"  {str(amount):>10s} | {desc}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL CSV GENERATION COMPLETE! üéâ\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(f\"Output file: {output_csv}\")\n",
    "    print()\n",
    "    print(\"Your data is now ready for:\")\n",
    "    print(\"  ‚Ä¢ Analysis and visualization\")\n",
    "    print(\"  ‚Ä¢ Spending reports\")\n",
    "    print(\"  ‚Ä¢ Budget tracking\")\n",
    "    print(\"  ‚Ä¢ Financial insights\")\n",
    "    print()\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "def create_category_mapping_report(df: pd.DataFrame, output_file: str):\n",
    "    \"\"\"\n",
    "    Create a report showing how categories were mapped\n",
    "    \n",
    "    Args:\n",
    "        df: Final dataframe with 'category' and 'final_category' columns\n",
    "        output_file: Path to save the mapping report\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'category' not in df.columns or 'final_category' not in df.columns:\n",
    "        print(\"‚ö†Ô∏è  Cannot create mapping report - missing required columns\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"CREATING CATEGORY MAPPING REPORT\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Create mapping\n",
    "    mapping_df = df.groupby(['category', 'final_category']).size().reset_index(name='count')\n",
    "    mapping_df = mapping_df.sort_values(['category', 'count'], ascending=[True, False])\n",
    "    \n",
    "    # Save\n",
    "    mapping_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"‚úì Category mapping saved to: {output_file}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Mapping summary:\")\n",
    "    print(f\"  Original categories: {df['category'].nunique()}\")\n",
    "    print(f\"  Final categories: {df['final_category'].nunique()}\")\n",
    "    print()\n",
    "    \n",
    "    # Show how Merchant was broken down\n",
    "    merchant_mapping = mapping_df[mapping_df['category'] == 'Merchant']\n",
    "    if len(merchant_mapping) > 0:\n",
    "        print(\"Merchant breakdown:\")\n",
    "        for _, row in merchant_mapping.head(10).iterrows():\n",
    "            print(f\"  Merchant ‚Üí {row['final_category']:25s}: {row['count']:5,}\")\n",
    "        if len(merchant_mapping) > 10:\n",
    "            print(f\"  ... and {len(merchant_mapping) - 10} more\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_with_all_subcategories.csv\" # Output from prediction script\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_final_categorized.csv\"      # Final clean CSV\n",
    "    MAPPING_REPORT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\category_mapping_report.csv\"  # How categories were mapped\n",
    "    \n",
    "    # Generate final CSV\n",
    "    df_final = generate_final_csv(\n",
    "        INPUT_CSV,\n",
    "        OUTPUT_CSV,\n",
    "        subcategory_col='merchant deepdive',\n",
    "        main_category_col='category'\n",
    "    )\n",
    "    \n",
    "    # Create mapping report\n",
    "    if 'category' in df_final.columns:\n",
    "        # Need to reload full data with both columns for mapping\n",
    "        df_full = pd.read_csv(INPUT_CSV, low_memory=False)\n",
    "        \n",
    "        # Add final_category to full dataframe\n",
    "        df_full['final_category'] = df_full['category'].copy()\n",
    "        merchant_mask = df_full['category'] == 'Merchant'\n",
    "        has_subcategory = df_full['merchant deepdive'].notna()\n",
    "        replace_mask = merchant_mask & has_subcategory\n",
    "        df_full.loc[replace_mask, 'final_category'] = df_full.loc[replace_mask, 'merchant deepdive']\n",
    "        \n",
    "        create_category_mapping_report(df_full, MAPPING_REPORT)\n",
    "    \n",
    "    print(\"‚úÖ All files generated successfully!\")\n",
    "    print()\n",
    "    print(\"Files created:\")\n",
    "    print(f\"  1. {OUTPUT_CSV} - Your final clean data\")\n",
    "    print(f\"  2. {MAPPING_REPORT} - Category mapping details\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
