{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  M-PESA DATA EXTRACTION PIPELINE\n",
    "## From PDF Upload to Analytics-Ready Data\n",
    "\n",
    "---\n",
    "\n",
    "###  Complete Workflow:\n",
    "\n",
    "```\n",
    "PDF UPLOAD ‚Üí AUTOMATED PROCESSING ‚Üí MERCHANT LEARNING ‚Üí ANALYTICS READY\n",
    "```\n",
    "\n",
    "###  What This Notebook Does:\n",
    "\n",
    "1. **Stage 1-5:** Automated processing (PDF ‚Üí Categorized CSV)\n",
    "2. **Stage 6A:** [OPTIONAL] Import manual labels\n",
    "3. **Stage 6B:** Hybrid merchant learning (interactive)\n",
    "4. **Stage 7:** Create unified category system\n",
    "5. **Final:** Analysis-ready CSV with all features\n",
    "\n",
    "###  Final Output:\n",
    "\n",
    "- **ONE clean CSV** with unified categories\n",
    "- **Temporal features** (weekday, hour, payday indicators)\n",
    "- **Financial features** (spending velocity, balance trends)\n",
    "- **Behavioral features** (recurring merchants, patterns)\n",
    "- **100% analysis-ready** for EDA, dashboards, ML\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SETUP & CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tabula\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Libraries loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Project Configuration\n",
    "\n",
    "**Update these settings for your project:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration complete\n",
      "   User: john\n",
      "   Output: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\processed\n",
      "   Database: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\processed\\merchant_databases\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PROJECT SETTINGS\n",
    "# ============================================================================\n",
    "\n",
    "# User ID (for personal merchant database)\n",
    "USER_ID = \"john\"  # Change per user\n",
    "\n",
    "# Input: M-Pesa PDF statement\n",
    "PDF_PATH = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_statement_john.pdf\"\n",
    "PDF_PASSWORD = \"335419\"\n",
    "\n",
    "# Optional: Manual labels (if you have pre-labeled data)\n",
    "MANUAL_LABELS_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\Statement3.csv\"  # Set path or None\n",
    "MANUAL_LABELS_COLUMN = \"Merchant_Subcategory\"  # Column with labels\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\processed\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Database directory (for merchant learning)\n",
    "DATABASE_DIR = os.path.join(OUTPUT_DIR, \"merchant_databases\")\n",
    "os.makedirs(DATABASE_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# STAGE OUTPUTS\n",
    "# ============================================================================\n",
    "\n",
    "STAGE1 = os.path.join(OUTPUT_DIR, \"stage1_raw.csv\")\n",
    "STAGE2 = os.path.join(OUTPUT_DIR, \"stage2_types.csv\")\n",
    "STAGE3 = os.path.join(OUTPUT_DIR, \"stage3_categories.csv\")\n",
    "STAGE4 = os.path.join(OUTPUT_DIR, \"stage4_smart_rules.csv\")\n",
    "STAGE5 = os.path.join(OUTPUT_DIR, \"stage5_clean.csv\")\n",
    "STAGE6 = os.path.join(OUTPUT_DIR, \"stage6_merchants_learned.csv\")\n",
    "FINAL = os.path.join(OUTPUT_DIR, \"FINAL_ANALYSIS_READY.csv\")\n",
    "\n",
    "print(\"‚úÖ Configuration complete\")\n",
    "print(f\"   User: {USER_ID}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print(f\"   Database: {DATABASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  AUTOMATED PROCESSING PIPELINE\n",
    "## Stages 1-5 (No User Input Required)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 1: PDF ‚Üí CSV\n",
    "\n",
    "Extract M-Pesa statement from password-protected PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 1: PDF ‚Üí CSV\n",
      "================================================================================\n",
      "\n",
      " Reading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\mpesa_statement_john.pdf\n",
      " Password: ******\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Got stderr: Feb 20, 2026 2:17:17 PM org.apache.pdfbox.pdmodel.font.PDTrueTypeFont <init>\n",
      "WARNING: Using fallback font 'ArialMT' for 'DejaVuSans'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Extracted 148 tables\n",
      "‚úì Combined: 2,869 rows, 14 columns\n",
      " Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\processed\\stage1_raw.csv\n",
      "\n",
      " STAGE 1 COMPLETE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 1: PDF TO CSV CONVERSION\n",
    "\"\"\"\n",
    "\n",
    "import tabula\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAGE 1: PDF ‚Üí CSV\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(f\" Reading: {PDF_PATH}\")\n",
    "print(f\" Password: {'*' * len(PDF_PASSWORD)}\")\n",
    "print()\n",
    "\n",
    "# Extract all tables from all pages\n",
    "tables = tabula.read_pdf(\n",
    "    PDF_PATH,\n",
    "    password=PDF_PASSWORD,\n",
    "    encoding='latin-1',\n",
    "    pages='all',\n",
    "    multiple_tables=True\n",
    ")\n",
    "\n",
    "print(f\"‚úì Extracted {len(tables)} tables\")\n",
    "\n",
    "# Combine tables\n",
    "df = pd.concat(tables, ignore_index=True)\n",
    "\n",
    "print(f\"‚úì Combined: {len(df):,} rows, {len(df.columns)} columns\")\n",
    "\n",
    "# Save\n",
    "df.to_csv(STAGE1, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\" Saved: {STAGE1}\")\n",
    "print()\n",
    "print(\" STAGE 1 COMPLETE\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 2: Transaction Type Identification\n",
    "\n",
    "Identify: Send Money, Till Payment, PayBill, Pochi, Airtime, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\n",
      "‚úì Loaded 2715 transactions\n",
      "\n",
      " Identifying transaction types...\n",
      " Extracting details...\n",
      "‚úì Identified 13 transaction types\n",
      "\n",
      "================================================================================\n",
      "TRANSACTION TYPE BREAKDOWN\n",
      "================================================================================\n",
      "M-Pesa Fee               :   779 ( 28.7%)\n",
      "Send Money               :   625 ( 23.0%)\n",
      "PayBill                  :   381 ( 14.0%)\n",
      "Cash Deposit             :   297 ( 10.9%)\n",
      "Income                   :   245 (  9.0%)\n",
      "Pochi la Biashara        :   139 (  5.1%)\n",
      "M-Shwari                 :    85 (  3.1%)\n",
      "Till Payment             :    79 (  2.9%)\n",
      "Airtime                  :    58 (  2.1%)\n",
      "Cash Withdrawal          :    21 (  0.8%)\n",
      "Reversal                 :     3 (  0.1%)\n",
      "Data Bundles             :     2 (  0.1%)\n",
      "Other                    :     1 (  0.0%)\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION - KEY TYPES\n",
      "================================================================================\n",
      "\n",
      "Data Bundles (2 transactions):\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "\n",
      "Airtime (58 transactions):\n",
      "  Airtime Purchase\n",
      "  Pay Bill Online to 4093275 - Direct Pay Limited 1 Acc. ATL1595883595\n",
      "\n",
      "Cash Deposit (297 transactions):\n",
      "  Deposit of Funds at Agent Till 158065 - Washindi Shop Dajos HotelBuild\n",
      "  Deposit of Funds at Agent Till 420487 - Kilwa Agencies LTDNyayo Stadiu\n",
      "\n",
      "Cash Withdrawal (21 transactions):\n",
      "  Customer Withdrawal At Agent Till 354039 - Enlight Comm Shanniz Enterp\n",
      "  Customer Withdrawal At Agent Till 171129 - Tosubeto Ent geneuine conn \n",
      "\n",
      "================================================================================\n",
      "FULIZA-POWERED TRANSACTIONS: 0 total\n",
      "================================================================================\n",
      "\n",
      "‚úì Fuliza LOAN (OverDraft) vs Fuliza PAYMENTS properly separated!\n",
      "\n",
      "‚úÖ Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\n",
      "\n",
      "‚úÖ Ready for Stage 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 2: TRANSACTION TYPE IDENTIFICATION (COMPLETE FIX)\n",
    "‚úÖ Separates Fuliza LOAN (OverDraft of Credit Party) from Fuliza PAYMENTS\n",
    "‚úÖ Loan Repayment as separate category\n",
    "‚úÖ All other fixes included\n",
    "\"\"\"\n",
    "class TransactionTypeIdentifier:\n",
    "    \"\"\"Enhanced transaction type identification with all fixes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Define patterns in strict priority order\"\"\"\n",
    "        # Format: (type_name, [patterns], priority)\n",
    "        self.type_patterns = [\n",
    "            # PRIORITY 1: Fees (check first - often confused with other types)\n",
    "            ('M-Pesa Fee', [\n",
    "                r'transfer\\s+of\\s+funds\\s+charge',\n",
    "                r'pay\\s+bill\\s+charge',\n",
    "                r'pay\\s+merchant\\s+charge',\n",
    "                r'withdraw(al)?\\s+charge',\n",
    "                r'\\bcharge\\b$',\n",
    "            ], 1),\n",
    "            \n",
    "            # PRIORITY 2: Fuliza/Overdraft LOAN (the credit itself - OverDraft of Credit Party)\n",
    "            ('Fuliza', [\n",
    "                r'overdraft\\s+of\\s+credit\\s+party',  # This is the LOAN\n",
    "            ], 2),\n",
    "            \n",
    "            # PRIORITY 3: Loan Repayment (paying back loans, including Fuliza payments)\n",
    "            ('Loan Repayment', [\n",
    "                r'od\\s+loan\\s+repayment',\n",
    "                r'loan\\s+repayment',\n",
    "                r'fuliza\\s+repayment',\n",
    "                r'overdraw',\n",
    "            ], 3),\n",
    "            \n",
    "            # PRIORITY 4: LOOP Payment (Income from LOOP)\n",
    "            ('LOOP Payment', [\n",
    "                r'promotion\\s+payment\\s+from.*loop\\s+b2c',\n",
    "                r'loop\\s+b2c',\n",
    "            ], 4),\n",
    "            \n",
    "            # PRIORITY 5: Received Money (Income)\n",
    "            ('Income', [\n",
    "                r'funds\\s+received\\s+from',\n",
    "                r'business\\s+payment\\s+from',\n",
    "                r'received\\s+from',\n",
    "                r'salary\\s+payment\\s+from',\n",
    "            ], 5),\n",
    "            \n",
    "            # PRIORITY 6: Cash Deposit (at agent)\n",
    "            ('Cash Deposit', [\n",
    "                r'deposit\\s+of\\s+funds\\s+at\\s+agent',\n",
    "            ], 6),\n",
    "            \n",
    "            # PRIORITY 7: Cash Withdrawal (at agent)\n",
    "            ('Cash Withdrawal', [\n",
    "                r'customer\\s+withdrawal\\s+at\\s+agent',\n",
    "                r'withdrawal\\s+at\\s+agent',\n",
    "            ], 7),\n",
    "            \n",
    "            # PRIORITY 8: Data Bundles (separated from Airtime)\n",
    "            # Including Fuliza-powered data bundles\n",
    "            ('Data Bundles', [\n",
    "                r'safaricom\\s+data',\n",
    "                r'safaricom\\s+data\\s+bundles',\n",
    "                r'customer\\s+bundle\\s+purchase\\s+with\\s+fuliza.*4093441',\n",
    "                r'(?i)buy\\s+bundle',\n",
    "                r'(?i)customer\\s+bundle\\s+purchase',\n",
    "                r'customer\\s+bundle\\s+purchase\\s+with\\s+fuliza',\n",
    "            \n",
    "            ], 8),\n",
    "            \n",
    "            # PRIORITY 9: Airtime (separated from Data, includes Direct Pay)\n",
    "            # Including Fuliza-powered airtime\n",
    "            ('Airtime', [\n",
    "                r'(?i)safaricom\\s+offers',  # Safaricom Offers = Airtime\n",
    "                r'airtime\\s+purchase',\n",
    "                r'pay\\s+bill.*direct\\s+pay.*atl\\d+',  # Direct Pay airtime\n",
    "                r'4187661.*direct\\s+pay',  # Direct Pay paybill\n",
    "                r'4093275.*direct\\s+pay',  # Another Direct Pay paybill\n",
    "                r'recharge\\s+for\\s+customer',\n",
    "                r'pay\\s+bill.*220220.*pesapal.*airt\\d+',\n",
    "                r'(?i).\\bpesapal\\b.',\n",
    "                r'(?i)merchant\\s+payment.to\\s+\\d+\\s-\\s*TINGG',# Catch TINGG via Merchant Payment\n",
    "                r'(?i)pay\\s+bill.to\\s+\\d+\\s-\\s*TINGG',   # Catch TINGG via Pay Bill (The one you just found)\n",
    "                r'TINGG',  # Catch any remaining TINGG transactions as Airtime\n",
    "            ], 9),\n",
    "            \n",
    "            # PRIORITY 10: Send Money (including Fuliza-powered transfers)\n",
    "            ('Send Money', [\n",
    "                r'(?i)customer\\s+transfer\\s+to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "                r'customer\\s+transfer\\s+to\\s+-\\s+',\n",
    "                r'(?i)customer\\stransfer',\n",
    "                r'customer\\s+send\\s+money.*fuliza.*to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "                r'(?i)customer\\s+transfer\\s+fuliza\\s+mpesa\\s*to\\s+-\\s+(2547|07|01)[\\d\\*]+',\n",
    "            ], 10),\n",
    "            \n",
    "            # PRIORITY 11: Pochi la Biashara\n",
    "            ('Pochi la Biashara', [\n",
    "                r'customer\\s+payment\\s+to\\s+small\\s+business',\n",
    "            ], 11),\n",
    "            \n",
    "            # PRIORITY 12: Till Payment (including Fuliza-powered)\n",
    "            ('Till Payment', [\n",
    "                r'merchant\\s+payment\\s+(online\\s+)?to\\s+\\d+',\n",
    "                r'merchant\\s+payment\\s+fuliza\\s+m-?pesa\\s*to\\s+\\d+',\n",
    "                r'till\\s+\\d+',\n",
    "            ], 12),\n",
    "            \n",
    "            # PRIORITY 13: PayBill (including Fuliza-powered)\n",
    "            ('PayBill', [\n",
    "                r'pay\\s+bill\\s+(online\\s+)?to\\s+\\d+',\n",
    "                r'pay\\s+bill\\s+fuliza\\s+m-?pesa\\s+to\\s+\\d+',\n",
    "                r'pay\\s+bill\\s+online\\s+fuliza\\s+m-pesa\\s+to\\s+(\\d+)\\s+-\\s+([\\w\\s]+?)\\s+acc\\.?\\s+([\\w\\s]+)',\n",
    "            ], 13),\n",
    "            \n",
    "            # PRIORITY 14: M-Shwari\n",
    "            ('M-Shwari', [\n",
    "                r'm-?\\s*shwari',\n",
    "            ], 14),\n",
    "            \n",
    "            # PRIORITY 15: Unit Trust\n",
    "            ('Unit Trust', [\n",
    "                r'unit\\s+trust',\n",
    "                r'ziidi',\n",
    "            ], 15),\n",
    "            \n",
    "            # PRIORITY 16: Reversal\n",
    "            ('Reversal', [\n",
    "                r'reversal',\n",
    "            ], 16),\n",
    "        ]\n",
    "    \n",
    "    def identify_type(self, description: str) -> str:\n",
    "        \"\"\"Identify transaction type\"\"\"\n",
    "        if pd.isna(description) or description == '':\n",
    "            return 'Other'\n",
    "        \n",
    "        desc_lower = str(description).lower().strip()\n",
    "        \n",
    "        # Check in priority order\n",
    "        for trans_type, patterns, _ in self.type_patterns:\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, desc_lower, re.IGNORECASE):\n",
    "                    return trans_type\n",
    "        \n",
    "        return 'Other'\n",
    "    \n",
    "    def extract_fields(self, description: str, txn_type: str) -> Dict:\n",
    "        \"\"\"Extract key fields from description\"\"\"\n",
    "        if pd.isna(description):\n",
    "            return {}\n",
    "        \n",
    "        fields = {}\n",
    "        desc = str(description)\n",
    "        \n",
    "        if txn_type == \"Send Money\":\n",
    "            # Regular transfer\n",
    "            match = re.search(\n",
    "                r'(?i)customer\\s+transfer\\s+(?:fuliza\\s+mpesa\\s*)?to\\s+-\\s+((2547|07|01)[\\d\\*]+)\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"recipient_number\"] = match.group(1)\n",
    "                fields[\"recipient_name\"] = match.group(3).strip()\n",
    "        \n",
    "        elif txn_type == \"Pochi la Biashara\":\n",
    "            match = re.search(\n",
    "                r'(?i)small\\s+business\\s+to\\s+-\\s+((2547|07|01)[\\d\\*]+)\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"recipient_number\"] = match.group(1)\n",
    "                fields[\"recipient_name\"] = match.group(3).strip()\n",
    "        \n",
    "        elif txn_type == \"Till Payment\":\n",
    "            # Regular or Fuliza merchant payment\n",
    "            match = re.search(\n",
    "                r'(?i)merchant\\s+payment\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+-\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"till_number\"] = match.group(1)\n",
    "                raw_merchant = match.group(2).strip()\n",
    "                raw_merchant = re.sub(\n",
    "                    r'(?i)\\s+via\\s+(coop|equity|kcb|ncba|family)\\s+bank\\.?$',\n",
    "                    '', raw_merchant\n",
    "                ).strip()\n",
    "                fields[\"merchant_name\"] = raw_merchant\n",
    "        \n",
    "        elif txn_type == \"PayBill\":\n",
    "            # Regular or Fuliza paybill\n",
    "            match = re.search(\n",
    "                r'(?i)pay\\s+bill\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+[-‚Äì]\\s+([\\w\\s]+?)\\s+[Aa]cc\\.?\\s+([\\w#]+)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"paybill_number\"] = match.group(1)\n",
    "                fields[\"merchant_name\"] = match.group(2).strip()\n",
    "                fields[\"account_number\"] = match.group(3).strip()\n",
    "            else:\n",
    "                match2 = re.search(\n",
    "                    r'(?i)pay\\s+bill\\s+(?:fuliza\\s+m-?pesa\\s*)?(?:online\\s+)?to\\s+(\\d+)\\s+[-‚Äì]?\\s+(.*)',\n",
    "                    desc\n",
    "                )\n",
    "                if match2:\n",
    "                    fields[\"paybill_number\"] = match2.group(1)\n",
    "                    fields[\"merchant_name\"] = match2.group(2).strip()\n",
    "        \n",
    "        elif txn_type in [\"Cash Withdrawal\", \"Cash Deposit\"]:\n",
    "            match = re.search(\n",
    "                r'(?i)agent\\s+till\\s+(\\d+)\\s+[-‚Äì]\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"agent_till\"] = match.group(1)\n",
    "                fields[\"agent_name\"] = match.group(2).strip()\n",
    "        \n",
    "        elif txn_type in [\"Received Money\", \"LOOP Payment\"]:\n",
    "            match = re.search(\n",
    "                r'(?i)(?:funds\\s+received|payment)\\s+from\\s+[-‚Äì]?\\s+(\\d+)\\s+[-‚Äì]\\s+(.*)',\n",
    "                desc\n",
    "            )\n",
    "            if match:\n",
    "                fields[\"sender_number\"] = match.group(1)\n",
    "                fields[\"sender_name\"] = match.group(2).strip()\n",
    "        \n",
    "        return fields\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add transaction_type and extracted_fields\"\"\"\n",
    "        print(\" Identifying transaction types...\")\n",
    "        \n",
    "        # Clean description\n",
    "        df['description_clean'] = df['Details'].apply(self._clean_text)\n",
    "        \n",
    "        # Identify types\n",
    "        df['transaction_type'] = df['description_clean'].apply(self.identify_type)\n",
    "        \n",
    "        # Extract fields\n",
    "        print(\" Extracting details...\")\n",
    "        df['extracted_fields'] = df.apply(\n",
    "            lambda row: self.extract_fields(row['description_clean'], row['transaction_type']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Identified {df['transaction_type'].nunique()} transaction types\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"Clean multiline PDF text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        text = str(text).replace('\\\\r', ' ').replace('\\\\n', ' ').replace('\\r', ' ').replace('\\n', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "\n",
    "def run_stage2(input_csv: str, output_csv: str):\n",
    "    \"\"\"Run Stage 2\"\"\"\n",
    "    \n",
    "\n",
    "    # Load\n",
    "    print(f\" Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    \n",
    "    # Filter to transactions\n",
    "    mask = df['Receipt No.'].notna() & (df['Receipt No.'] != '')\n",
    "    df = df[mask].copy()\n",
    "    \n",
    "    print(f\"‚úì Loaded {len(df)} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Process\n",
    "    identifier = TransactionTypeIdentifier()\n",
    "    df = identifier.process_dataframe(df)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"TRANSACTION TYPE BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    for trans_type, count in df['transaction_type'].value_counts().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{trans_type:25s}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERIFICATION - KEY TYPES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Verify critical fixes\n",
    "    key_types = ['Fuliza', 'Loan Repayment', 'LOOP Payment', 'Data Bundles', \n",
    "                 'Airtime', 'Cash Deposit', 'Cash Withdrawal']\n",
    "    \n",
    "    for trans_type in key_types:\n",
    "        type_df = df[df['transaction_type'] == trans_type]\n",
    "        if len(type_df) > 0:\n",
    "            print(f\"\\n{trans_type} ({len(type_df)} transactions):\")\n",
    "            for _, row in type_df.head(2).iterrows():\n",
    "                print(f\"  {row['description_clean'][:70]}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Show Fuliza-powered transactions\n",
    "    fuliza_powered = df[df['description_clean'].str.contains('fuliza', case=False, na=False)]\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"FULIZA-POWERED TRANSACTIONS: {len(fuliza_powered)} total\")\n",
    "    print(\"=\" * 80)\n",
    "    fuliza_breakdown = fuliza_powered['transaction_type'].value_counts()\n",
    "    for txn_type, count in fuliza_breakdown.items():\n",
    "        print(f\"  {txn_type:25s}: {count:5d}\")\n",
    "    print()\n",
    "    print(\"‚úì Fuliza LOAN (OverDraft) vs Fuliza PAYMENTS properly separated!\")\n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df['extracted_fields_str'] = df['extracted_fields'].apply(str)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage1_mpesa_raw.csv\"\n",
    "    OUTPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\"\n",
    "    \n",
    "    df = run_stage2(INPUT, OUTPUT)\n",
    "    print(\"‚úÖ Ready for Stage 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 3: Keyword Categorization\n",
    "\n",
    "Apply keyword rules: Income, Bills, Shopping, Airtime, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\n",
      "‚úì Loaded 2715 transactions\n",
      "\n",
      "  Categorizing...\n",
      "‚úì Categorized into 19 categories\n",
      "\n",
      "================================================================================\n",
      "CATEGORY BREAKDOWN\n",
      "================================================================================\n",
      "M-Pesa Fees                   :   779 ( 28.7%)\n",
      "Uncategorized                 :   626 ( 23.1%)\n",
      "Cash Deposit                  :   297 ( 10.9%)\n",
      "Income                        :   245 (  9.0%)\n",
      "Savings                       :   228 (  8.4%)\n",
      "Merchant                      :   220 (  8.1%)\n",
      "Bills                         :   104 (  3.8%)\n",
      "Cash Withdrawal               :    62 (  2.3%)\n",
      "Airtime                       :    58 (  2.1%)\n",
      "Government Bills              :    32 (  1.2%)\n",
      "Subscriptions                 :    26 (  1.0%)\n",
      "Betting                       :    20 (  0.7%)\n",
      "Shopping                      :     6 (  0.2%)\n",
      "Personal Care                 :     4 (  0.1%)\n",
      "Reversal                      :     3 (  0.1%)\n",
      "Data Bundles                  :     2 (  0.1%)\n",
      "Fast Foods                    :     1 (  0.0%)\n",
      "Transport                     :     1 (  0.0%)\n",
      "Health Care                   :     1 (  0.0%)\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION - KEY CATEGORIES\n",
      "================================================================================\n",
      "\n",
      "Data Bundles (2 transactions):\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "  Customer Bundle Purchase to 4093441SAFARICOM DATA BUNDLES by - 2547***\n",
      "\n",
      "Airtime (58 transactions):\n",
      "  Airtime Purchase\n",
      "  Pay Bill Online to 4093275 - Direct Pay Limited 1 Acc. ATL1595883595\n",
      "\n",
      "Income (245 transactions):\n",
      "  Funds received from - 2547******113 NDEGE KAUSI\n",
      "  Funds received from - 2547******067 Timothy Macharia\n",
      "\n",
      "Cash Deposit (297 transactions):\n",
      "  Deposit of Funds at Agent Till 158065 - Washindi Shop Dajos HotelBuild\n",
      "  Deposit of Funds at Agent Till 420487 - Kilwa Agencies LTDNyayo Stadiu\n",
      "\n",
      "Cash Withdrawal (62 transactions):\n",
      "  M-Shwari Withdraw\n",
      "  M-Shwari Withdraw\n",
      "\n",
      "‚úÖ Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\n",
      "\n",
      "‚úÖ Ready for Stage 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class KeywordCategorizer: \n",
    "    def __init__(self):\n",
    "        self.category_keywords = {\n",
    "            # HIGH PRIORITY\n",
    "            'Health Care': {\n",
    "                'keywords': [\n",
    "                    'hospital', 'clinic', 'pharmacy', 'medical',\n",
    "                    'chemist', 'doctor', 'laboratory', 'lab', 'diagnostic',\n",
    "                    'aga khan', 'nairobi hospital', 'mater', 'kenyatta hospital',\n",
    "                    'mp shah', 'gertrudes', 'lancet', 'dental', 'optical',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Government Bills': {\n",
    "                'keywords': [\n",
    "                    'government', 'tax', 'revenue', 'nssf', 'nhif', 'kra', 'SHIF', 'SHA',\n",
    "                    'pension', 'social security', 'national insurance', 'E-CITIZEN', 'E-Citizen','E- CITIZEN',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Betting': {\n",
    "                'keywords': [\n",
    "                    'sportpesa', 'sportybet', 'betika', '1xbet', 'stake', \n",
    "                    'bangbet', '22bet', 'mozzart bet', 'betway', 'odibets',\n",
    "                    'kareco holdings', 'melbet', 'betin', 'betpawa', 'shabiki',\n",
    "                    'bet', 'betting', 'lotto', 'lottery', 'casino', 'CHEZA WIN', \n",
    "                    'SHINDA SASA', 'DUMUKENYA', 'BETWIN', 'DUMU KENYA',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # Loans - REMOVED \"fuliza\" (now handled via transaction type)\n",
    "            'Loans': {\n",
    "                'keywords': [\n",
    "                    'm-shwari loan', 'kcb m-pesa loan', 'hustler fund',\n",
    "                    'okash', 'zenka', 'timiza', 'Overdraft',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "\n",
    "            'Loan Repayment': {\n",
    "                'keywords': ['repayment', 'overdraw'],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # Online Shopping - REMOVED \"online\" and \"online purchase\"\n",
    "            'Online Shopping': {\n",
    "                'keywords': [\n",
    "                    'jumia', 'kilimall', 'masoko', 'glovo', 'jiji',\n",
    "                    'aliexpress', 'amazon', 'alibaba', 'uber eats', 'bolt food',\n",
    "                    'sky garden', 'food delivery', 'home delivery',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Bills': {\n",
    "                'keywords': [\n",
    "                    'kplc', 'water', 'rent', 'insurance', 'gas refill',\n",
    "                    'internet', 'wifi', 'land rates', 'security',\n",
    "                    'parking', 'electricity', 'prepaid', 'postpaid',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Subscriptions': {\n",
    "                'keywords': [\n",
    "                    'netflix', 'spotify', 'youtube', 'prime', 'hbo',\n",
    "                    'GOTV', 'dstv', 'showmax', 'apple music', 'startimes',\n",
    "                    'zuku', 'subscription', 'microsoft 365', 'office 365', 'GO TV'\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Education': {\n",
    "                'keywords': [\n",
    "                    'university', 'school', 'college', 'helb', 'kuccps',\n",
    "                    'knec', 'tvet', 'kmtc', 'fees', 'tuition', 'catering',\n",
    "                    'kabarak', 'student', 'academy', 'exam fee', 'hostel',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            'Savings': {\n",
    "                'keywords': [\n",
    "                    'mshwari deposit', 'unit trust', 'mmf', 'fixed deposit',\n",
    "                    'investment', 'koala', 'ndovu', 'etica', 'chama',\n",
    "                    'ziidi', 'savings', 'sacco deposit', 'Sacco', 'co-op', \n",
    "                    'equity', 'kcb', 'ncba', 'family bank', 'absa', 'stanbic', \n",
    "                    'co-operative', 'self help group', 'mfb', 'mf', 'savings group', \n",
    "                    'savings account', 'savings deposit', 'retirement', \n",
    "                    'retirement fund', 'pension fund',\n",
    "                ],\n",
    "                'priority': 1,\n",
    "            },\n",
    "            \n",
    "            # MEDIUM PRIORITY\n",
    "            'Shopping': {\n",
    "                'keywords': [\n",
    "                    'supermarket', 'naivas', 'quickmart', 'quick mart',\n",
    "                    'carrefour', 'chandarana', 'foodplus', 'cleanshelf',\n",
    "                    'eastmatt', 'tuskys', 'kabsmart', 'nakumatt', 'Store', \n",
    "                    'majid al futtah', 'market',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Fast Foods': {\n",
    "                'keywords': [\n",
    "                    'kfc', 'chicken inn', 'java house', 'artcaffe',\n",
    "                    'pizza', 'burger king', 'dominos', 'debonairs',\n",
    "                    'pizza hut', 'pizza inn', 'subway', 'steers', 'inn', \n",
    "                    'cafe', 'chips', 'snack', 'chips and snacks',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Food & Dining': {\n",
    "                'keywords': [\n",
    "                    'restaurant', 'hotel', 'cafe', 'eatery', 'food court',\n",
    "                    'dining', 'meat', 'vegetables', 'fruits', 'milk', 'food',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Personal Care': {\n",
    "                'keywords': [\n",
    "                    'beauty', 'cosmetics', 'skincare', 'makeup', 'barber',\n",
    "                    'salon', 'spa', 'kinyozi', 'grooming', 'hair', 'nails',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Transport': {\n",
    "                'keywords': [\n",
    "                    'uber', 'bolt', 'taxi', 'little cab', 'transport',\n",
    "                    'fuel', 'petrol', 'diesel', 'shell', 'total', 'parking', 'rubis',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            'Entertainment': {\n",
    "                'keywords': [\n",
    "                    'liquor', 'bar', 'wine', 'beer', 'club', 'lounge',\n",
    "                    'pub', 'cinema', 'bowling', 'arcade', 'entertainment',\n",
    "                ],\n",
    "                'priority': 2,\n",
    "            },\n",
    "            \n",
    "            # LOW PRIORITY\n",
    "            'Bank Transfer': {\n",
    "                'keywords': [\n",
    "                    'equity', 'kcb', 'family bank', 'co-op', 'ncba',\n",
    "                    'stanbic', 'absa', 'bank transfer',\n",
    "                ],\n",
    "                'priority': 3,\n",
    "            },\n",
    "        }\n",
    "    \n",
    "    def categorize(self, description: str, transaction_type: str, extracted_fields: Dict = None) -> str:\n",
    "        \"\"\"Categorize transaction\"\"\"\n",
    "        if pd.isna(description):\n",
    "            return 'Uncategorized'\n",
    "        \n",
    "        desc_lower = str(description).lower()\n",
    "        \n",
    "        # Build search text\n",
    "        search_text = desc_lower\n",
    "        if extracted_fields:\n",
    "            for key in ['merchant_name', 'recipient_name', 'sender_name', 'agent_name']:\n",
    "                if key in extracted_fields:\n",
    "                    search_text += ' ' + str(extracted_fields[key]).lower()\n",
    "        \n",
    "        # PRIORITY 1: Transaction type based (FIXED)\n",
    "        \n",
    "        # Income\n",
    "        if transaction_type in ['Received Money', 'LOOP Payment', 'Income']:\n",
    "            return 'Income'\n",
    "        \n",
    "        # Cash operations\n",
    "        if transaction_type == 'Cash Deposit':\n",
    "            return 'Cash Deposit'\n",
    "        \n",
    "        if transaction_type == 'Cash Withdrawal':\n",
    "            return 'Cash Withdrawal'\n",
    "        \n",
    "        # Loans (including Fuliza/OverDraft from Stage 2)\n",
    "        if transaction_type == 'Overdraft':\n",
    "            return 'Loans'\n",
    "        \n",
    "        # Data vs Airtime (now separated in Stage 2)\n",
    "        if transaction_type == 'Data Bundles':\n",
    "            return 'Data Bundles'\n",
    "        \n",
    "        if transaction_type == 'Airtime':\n",
    "            return 'Airtime'\n",
    "        \n",
    "        # Fees\n",
    "        if transaction_type == 'M-Pesa Fee':\n",
    "            return 'M-Pesa Fees'\n",
    "        \n",
    "        # M-Shwari\n",
    "        if transaction_type == 'M-Shwari':\n",
    "            if 'withdraw' in desc_lower:\n",
    "                return 'Cash Withdrawal'\n",
    "            else:\n",
    "                return 'Savings'\n",
    "        \n",
    "        # Unit Trust\n",
    "        if transaction_type == 'Unit Trust':\n",
    "            return 'Savings'\n",
    "        \n",
    "        # Reversal\n",
    "        if transaction_type == 'Reversal':\n",
    "            return 'Reversal'\n",
    "        \n",
    "        # PRIORITY 2: Send Money - LEAVE UNCATEGORIZED for Stage 4\n",
    "        if transaction_type == 'Send Money':\n",
    "            return 'Uncategorized'\n",
    "        \n",
    "        # PRIORITY 3: Till/PayBill/Pochi - Try keywords, fallback to Merchant\n",
    "        if transaction_type in ['Till Payment', 'PayBill', 'Pochi la Biashara']:\n",
    "            matched = self._match_keywords(search_text)\n",
    "            return matched if matched else 'Merchant'\n",
    "        \n",
    "        # PRIORITY 4: Other - Try keywords\n",
    "        matched = self._match_keywords(search_text)\n",
    "        return matched if matched else 'Other'\n",
    "    \n",
    "    def _match_keywords(self, search_text: str) -> str:\n",
    "        \"\"\"Match keywords\"\"\"\n",
    "        sorted_categories = sorted(\n",
    "            self.category_keywords.items(),\n",
    "            key=lambda x: x[1].get('priority', 99)\n",
    "        )\n",
    "        \n",
    "        for category, rules in sorted_categories:\n",
    "            for keyword in rules.get('keywords', []):\n",
    "                pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "                if re.search(pattern, search_text, re.IGNORECASE):\n",
    "                    return category\n",
    "        \n",
    "        return ''\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add category column\"\"\"\n",
    "        print(\"  Categorizing...\")\n",
    "        \n",
    "        # Parse extracted_fields\n",
    "        if 'extracted_fields' in df.columns:\n",
    "            try:\n",
    "                import ast\n",
    "                df['extracted_fields_dict'] = df['extracted_fields'].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.strip() else {}\n",
    "                )\n",
    "            except:\n",
    "                df['extracted_fields_dict'] = df['extracted_fields']\n",
    "        else:\n",
    "            df['extracted_fields_dict'] = [{}] * len(df)\n",
    "        \n",
    "        # Categorize\n",
    "        df['category'] = df.apply(\n",
    "            lambda row: self.categorize(\n",
    "                row['description_clean'], \n",
    "                row['transaction_type'],\n",
    "                row.get('extracted_fields_dict', {})\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì Categorized into {df['category'].nunique()} categories\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def run_stage3(input_csv: str, output_csv: str):\n",
    "    \"\"\"Run Stage 3\"\"\"\n",
    "    \n",
    "    \n",
    "    # Load\n",
    "    print(f\" Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df)} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Categorize\n",
    "    categorizer = KeywordCategorizer()\n",
    "    df = categorizer.process_dataframe(df)\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CATEGORY BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    for category, count in df['category'].value_counts().items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{category:30s}: {count:5d} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Verify key categories\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERIFICATION - KEY CATEGORIES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    key_cats = ['Loans', 'Data Bundles', 'Airtime', 'Income', \n",
    "                'Cash Deposit', 'Cash Withdrawal', 'Loan Repayment']\n",
    "    \n",
    "    for cat in key_cats:\n",
    "        cat_df = df[df['category'] == cat]\n",
    "        if len(cat_df) > 0:\n",
    "            print(f\"\\n{cat} ({len(cat_df)} transactions):\")\n",
    "            for _, row in cat_df.head(2).iterrows():\n",
    "                print(f\"  {row['description_clean'][:70]}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage2_with_types.csv\"\n",
    "    OUTPUT = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\"\n",
    "    \n",
    "    df = run_stage3(INPUT, OUTPUT)\n",
    "    print(\"‚úÖ Ready for Stage 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 4: Send Money Smart Rules\n",
    "\n",
    "Apply customizable rules to categorize Send Money transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 4: SEND MONEY CATEGORIZATION (CUSTOMIZABLE)\n",
      "================================================================================\n",
      "\n",
      "‚úì Using default rules\n",
      "\n",
      "üìÇ Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\n",
      "‚úì Loaded 2,715 transactions\n",
      "\n",
      "ü§ñ Categorizing Send Money transactions with custom rules...\n",
      "\n",
      "================================================================================\n",
      "ACTIVE RULES\n",
      "================================================================================\n",
      "\n",
      "RULE1: Recurring + High Amount\n",
      "  Min occurrences: 2\n",
      "  Amount threshold: KES 500\n",
      "  Amount condition: > threshold\n",
      "  ‚Üí Categorize as: Friends & Family\n",
      "  (Recurring recipient + Amount > threshold)\n",
      "\n",
      "RULE2: Recurring + Low Amount\n",
      "  Min occurrences: 2\n",
      "  Amount threshold: KES 500\n",
      "  Amount condition: ‚â§ threshold\n",
      "  ‚Üí Categorize as: Merchant\n",
      "  (Recurring recipient + Amount ‚â§ threshold)\n",
      "\n",
      "RULE3: One-time Transactions\n",
      "  ‚Üí Categorize as: Merchant\n",
      "  (Non-recurring transactions)\n",
      "\n",
      "üîç Found 198 unique recipients\n",
      "‚úì 72 recurring recipients (‚â•2 transactions)\n",
      "\n",
      "Top 15 recurring recipients:\n",
      "  2547******463                                : 196 times\n",
      "  2547******402                                :  20 times\n",
      "  07******162                                  :  14 times\n",
      "  2547******857                                :  13 times\n",
      "  2547******633                                :  11 times\n",
      "  2547******831                                :  10 times\n",
      "  01******309                                  :   9 times\n",
      "  2547******317                                :   9 times\n",
      "  07******312                                  :   8 times\n",
      "  2547******795                                :   8 times\n",
      "  2547******488                                :   8 times\n",
      "  2547******743                                :   8 times\n",
      "  2547******638                                :   8 times\n",
      "  07******121                                  :   8 times\n",
      "  2547******596                                :   7 times\n",
      "\n",
      "================================================================================\n",
      "SEND MONEY CATEGORIZATION RESULTS\n",
      "================================================================================\n",
      "Processed: 625 Send Money transactions\n",
      "\n",
      "Results:\n",
      "  Merchant                      :   575 ( 92.0%)\n",
      "  Friends & Family              :    50 (  8.0%)\n",
      "\n",
      "================================================================================\n",
      "FINAL CATEGORY BREAKDOWN\n",
      "================================================================================\n",
      "Merchant                      :    795 ( 29.3%)\n",
      "M-Pesa Fees                   :    779 ( 28.7%)\n",
      "Cash Deposit                  :    297 ( 10.9%)\n",
      "Income                        :    245 (  9.0%)\n",
      "Savings                       :    228 (  8.4%)\n",
      "Bills                         :    104 (  3.8%)\n",
      "Cash Withdrawal               :     62 (  2.3%)\n",
      "Airtime                       :     58 (  2.1%)\n",
      "Friends & Family              :     50 (  1.8%)\n",
      "Government Bills              :     32 (  1.2%)\n",
      "Subscriptions                 :     26 (  1.0%)\n",
      "Betting                       :     20 (  0.7%)\n",
      "Shopping                      :      6 (  0.2%)\n",
      "Personal Care                 :      4 (  0.1%)\n",
      "Reversal                      :      3 (  0.1%)\n",
      "Data Bundles                  :      2 (  0.1%)\n",
      "Fast Foods                    :      1 (  0.0%)\n",
      "Transport                     :      1 (  0.0%)\n",
      "Health Care                   :      1 (  0.0%)\n",
      "Uncategorized                 :      1 (  0.0%)\n",
      "\n",
      "üíæ Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\n",
      "\n",
      "‚úì Rules saved to: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized_rules.json\n",
      "\n",
      "================================================================================\n",
      "STAGE 4 COMPLETE! üéâ\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 4: SEND MONEY CATEGORIZATION (CUSTOMIZABLE RULES)\n",
    "Now with customizable thresholds that can be set from UI or manually\n",
    "\n",
    "CUSTOMIZABLE RULES:\n",
    "1. Send Money + Recurring (‚â•X times) + Amount > Y ‚Üí Category A\n",
    "2. Send Money + Recurring (‚â•X times) + Amount ‚â§ Y ‚Üí Category B  \n",
    "3. Send Money + Non-recurring (any amount) ‚Üí Category C\n",
    "\n",
    "Where X, Y, A, B, C are user-defined\n",
    "\"\"\"\n",
    "\n",
    "class CustomizableSendMoneyCategorizer:\n",
    "    \"\"\"\n",
    "    Categorize Send Money transactions with customizable rules\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, rules_config: dict = None):\n",
    "        \"\"\"\n",
    "        Initialize with custom rules configuration\n",
    "        \n",
    "        Args:\n",
    "            rules_config: Dictionary with rule parameters\n",
    "                {\n",
    "                    'rule1': {\n",
    "                        'min_occurrences': 2,\n",
    "                        'amount_threshold': 500,\n",
    "                        'category': 'Friends & Family'\n",
    "                    },\n",
    "                    'rule2': {\n",
    "                        'min_occurrences': 2,\n",
    "                        'amount_threshold': 500,\n",
    "                        'category': 'Merchant'\n",
    "                    },\n",
    "                    'rule3': {\n",
    "                        'category': 'Merchant'\n",
    "                    }\n",
    "                }\n",
    "        \"\"\"\n",
    "        \n",
    "        # Default rules\n",
    "        self.default_rules = {\n",
    "            'rule1': {\n",
    "                'name': 'Recurring + High Amount',\n",
    "                'min_occurrences': 2,\n",
    "                'amount_threshold': 500.0,\n",
    "                'amount_comparison': 'greater',  # 'greater' or 'less_equal'\n",
    "                'category': 'Friends & Family',\n",
    "                'description': 'Recurring recipient + Amount > threshold'\n",
    "            },\n",
    "            'rule2': {\n",
    "                'name': 'Recurring + Low Amount',\n",
    "                'min_occurrences': 2,\n",
    "                'amount_threshold': 500.0,\n",
    "                'amount_comparison': 'less_equal',\n",
    "                'category': 'Merchant',\n",
    "                'description': 'Recurring recipient + Amount ‚â§ threshold'\n",
    "            },\n",
    "            'rule3': {\n",
    "                'name': 'One-time Transactions',\n",
    "                'category': 'Merchant',\n",
    "                'description': 'Non-recurring transactions'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Use provided config or default\n",
    "        if rules_config:\n",
    "            self.rules = {**self.default_rules, **rules_config}\n",
    "        else:\n",
    "            self.rules = self.default_rules\n",
    "    \n",
    "    def save_rules(self, filepath: str):\n",
    "        \"\"\"Save rules configuration to JSON file\"\"\"\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(self.rules, f, indent=2)\n",
    "        print(f\"‚úì Rules saved to: {filepath}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_rules(cls, filepath: str):\n",
    "        \"\"\"Load rules configuration from JSON file\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            rules = json.load(f)\n",
    "        return cls(rules)\n",
    "    \n",
    "    def extract_recipient_id(self, extracted_fields_str: str) -> str:\n",
    "        \"\"\"Extract recipient identifier from extracted_fields\"\"\"\n",
    "        if pd.isna(extracted_fields_str) or extracted_fields_str == '':\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            import ast\n",
    "            fields = ast.literal_eval(extracted_fields_str)\n",
    "            \n",
    "            # Use phone number as primary identifier\n",
    "            if 'recipient_number' in fields:\n",
    "                return fields['recipient_number']\n",
    "            elif 'recipient_name' in fields:\n",
    "                return fields['recipient_name']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def detect_recurring_recipients(self, df: pd.DataFrame) -> dict:\n",
    "        \"\"\"Detect recurring recipients in Send Money transactions\"\"\"\n",
    "        \n",
    "        # Filter to uncategorized Send Money\n",
    "        send_money_df = df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Uncategorized')\n",
    "        ].copy()\n",
    "        \n",
    "        if len(send_money_df) == 0:\n",
    "            return {}\n",
    "        \n",
    "        # Extract recipient IDs\n",
    "        send_money_df['recipient_id'] = send_money_df['extracted_fields_str'].apply(\n",
    "            self.extract_recipient_id\n",
    "        )\n",
    "        \n",
    "        # Count occurrences\n",
    "        recipient_counts = send_money_df['recipient_id'].value_counts().to_dict()\n",
    "        \n",
    "        # Remove None\n",
    "        recipient_counts = {k: v for k, v in recipient_counts.items() if k is not None}\n",
    "        \n",
    "        return recipient_counts\n",
    "    \n",
    "    def categorize_send_money(self, row: pd.Series, recipient_counts: dict) -> str:\n",
    "        \"\"\"Categorize a single Send Money transaction using custom rules\"\"\"\n",
    "        \n",
    "        # Extract recipient ID\n",
    "        recipient_id = self.extract_recipient_id(row['extracted_fields_str'])\n",
    "        \n",
    "        # Get recipient count\n",
    "        count = recipient_counts.get(recipient_id, 1) if recipient_id else 1\n",
    "        \n",
    "        # Get amount\n",
    "        amount = 0\n",
    "        if pd.notna(row.get('Withdrawn')):\n",
    "            try:\n",
    "                amount = abs(float(row['Withdrawn']))\n",
    "            except:\n",
    "                amount = 0\n",
    "        elif pd.notna(row.get('withdrawn')):\n",
    "            try:\n",
    "                amount = abs(float(row['withdrawn']))\n",
    "            except:\n",
    "                amount = 0\n",
    "        \n",
    "        # Check Rule 1: Recurring + High Amount\n",
    "        rule1 = self.rules.get('rule1', {})\n",
    "        if count >= rule1.get('min_occurrences', 2):\n",
    "            threshold = rule1.get('amount_threshold', 500.0)\n",
    "            comparison = rule1.get('amount_comparison', 'greater')\n",
    "            \n",
    "            if comparison == 'greater' and amount > threshold:\n",
    "                return rule1.get('category', 'Friends & Family')\n",
    "            \n",
    "            # Check Rule 2: Recurring + Low Amount\n",
    "            rule2 = self.rules.get('rule2', {})\n",
    "            if count >= rule2.get('min_occurrences', 2):\n",
    "                threshold2 = rule2.get('amount_threshold', 500.0)\n",
    "                comparison2 = rule2.get('amount_comparison', 'less_equal')\n",
    "                \n",
    "                if comparison2 == 'less_equal' and amount <= threshold2:\n",
    "                    return rule2.get('category', 'Merchant')\n",
    "        \n",
    "        # Rule 3: Non-recurring (default fallback)\n",
    "        rule3 = self.rules.get('rule3', {})\n",
    "        return rule3.get('category', 'Merchant')\n",
    "    \n",
    "    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Process entire dataframe with custom rules\"\"\"\n",
    "        \n",
    "        print(\"ü§ñ Categorizing Send Money transactions with custom rules...\")\n",
    "        print()\n",
    "        \n",
    "        # Show current rules\n",
    "        print(\"=\" * 80)\n",
    "        print(\"ACTIVE RULES\")\n",
    "        print(\"=\" * 80)\n",
    "        for rule_id, rule in self.rules.items():\n",
    "            print(f\"\\n{rule_id.upper()}: {rule.get('name', 'Unnamed')}\")\n",
    "            if 'min_occurrences' in rule:\n",
    "                print(f\"  Min occurrences: {rule['min_occurrences']}\")\n",
    "            if 'amount_threshold' in rule:\n",
    "                print(f\"  Amount threshold: KES {rule['amount_threshold']:,.0f}\")\n",
    "            if 'amount_comparison' in rule:\n",
    "                comp = '>' if rule['amount_comparison'] == 'greater' else '‚â§'\n",
    "                print(f\"  Amount condition: {comp} threshold\")\n",
    "            print(f\"  ‚Üí Categorize as: {rule['category']}\")\n",
    "            print(f\"  ({rule.get('description', '')})\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Detect recurring recipients\n",
    "        recipient_counts = self.detect_recurring_recipients(df)\n",
    "        \n",
    "        if recipient_counts:\n",
    "            print(f\"üîç Found {len(recipient_counts)} unique recipients\")\n",
    "            recurring = {k: v for k, v in recipient_counts.items() if v >= self.rules['rule1'].get('min_occurrences', 2)}\n",
    "            print(f\"‚úì {len(recurring)} recurring recipients (‚â•{self.rules['rule1'].get('min_occurrences', 2)} transactions)\")\n",
    "            \n",
    "            if recurring:\n",
    "                print()\n",
    "                print(\"Top 15 recurring recipients:\")\n",
    "                sorted_recipients = sorted(recurring.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "                for recipient, count in sorted_recipients:\n",
    "                    print(f\"  {recipient[:45]:45s}: {count:3d} times\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Count before\n",
    "        before_uncat = len(df[\n",
    "            (df['transaction_type'] == 'Send Money') & \n",
    "            (df['category'] == 'Uncategorized')\n",
    "        ])\n",
    "        \n",
    "        # Apply categorization\n",
    "        mask = (df['transaction_type'] == 'Send Money') & (df['category'] == 'Uncategorized')\n",
    "        \n",
    "        df.loc[mask, 'category'] = df[mask].apply(\n",
    "            lambda row: self.categorize_send_money(row, recipient_counts),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Show results\n",
    "        print(\"=\" * 80)\n",
    "        print(\"SEND MONEY CATEGORIZATION RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Count by resulting category\n",
    "        category_breakdown = df[\n",
    "            (df['transaction_type'] == 'Send Money')\n",
    "        ]['category'].value_counts()\n",
    "        \n",
    "        print(f\"Processed: {before_uncat:,} Send Money transactions\")\n",
    "        print()\n",
    "        print(\"Results:\")\n",
    "        for category, count in category_breakdown.items():\n",
    "            pct = count / before_uncat * 100 if before_uncat > 0 else 0\n",
    "            print(f\"  {category:30s}: {count:5,} ({pct:5.1f}%)\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "def run_stage4_customizable(input_csv: str, \n",
    "                            output_csv: str,\n",
    "                            rules_config: dict = None,\n",
    "                            rules_file: str = None):\n",
    "    \"\"\"\n",
    "    Run Stage 4 with customizable rules\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to Stage 3 output CSV\n",
    "        output_csv: Path to save final categorized CSV\n",
    "        rules_config: Dictionary with custom rules (optional)\n",
    "        rules_file: Path to JSON file with rules (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 4: SEND MONEY CATEGORIZATION (CUSTOMIZABLE)\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Load rules\n",
    "    if rules_file:\n",
    "        print(f\"üìÇ Loading rules from: {rules_file}\")\n",
    "        categorizer = CustomizableSendMoneyCategorizer.load_rules(rules_file)\n",
    "    elif rules_config:\n",
    "        print(\"‚úì Using provided rules configuration\")\n",
    "        categorizer = CustomizableSendMoneyCategorizer(rules_config)\n",
    "    else:\n",
    "        print(\"‚úì Using default rules\")\n",
    "        categorizer = CustomizableSendMoneyCategorizer()\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"üìÇ Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} transactions\")\n",
    "    print()\n",
    "    \n",
    "    # Process\n",
    "    df = categorizer.process_dataframe(df)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL CATEGORY BREAKDOWN\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    category_counts = df['category'].value_counts().sort_values(ascending=False)\n",
    "    for category, count in category_counts.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        print(f\"{category:30s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"üíæ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    # Optionally save rules\n",
    "    rules_output = output_csv.replace('.csv', '_rules.json')\n",
    "    categorizer.save_rules(rules_output)\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 4 COMPLETE! üéâ\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # EXAMPLE 1: Use default rules\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage3_with_categories.csv\"\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\"\n",
    "    \n",
    "    df = run_stage4_customizable(INPUT_CSV, OUTPUT_CSV)\n",
    "    \n",
    "    # EXAMPLE 2: Use custom rules (e.g., from UI)\n",
    "    \"\"\"\n",
    "    CUSTOM_RULES = {\n",
    "        'rule1': {\n",
    "            'name': 'Recurring + High Amount',\n",
    "            'min_occurrences': 3,  # More strict: need 3+ occurrences\n",
    "            'amount_threshold': 1000.0,  # Higher threshold: 1000 KES\n",
    "            'amount_comparison': 'greater',\n",
    "            'category': 'Family'  # Different category name\n",
    "        },\n",
    "        'rule2': {\n",
    "            'name': 'Recurring + Low Amount',\n",
    "            'min_occurrences': 3,\n",
    "            'amount_threshold': 1000.0,\n",
    "            'amount_comparison': 'less_equal',\n",
    "            'category': 'Food Vendor'  # More specific\n",
    "        },\n",
    "        'rule3': {\n",
    "            'name': 'One-time Transactions',\n",
    "            'category': 'Uncategorized'  # Flag for manual review\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    df = run_stage4_customizable(INPUT_CSV, OUTPUT_CSV, rules_config=CUSTOM_RULES)\n",
    "    \"\"\"\n",
    "    \n",
    "    # EXAMPLE 3: Load rules from UI-generated JSON\n",
    "    \"\"\"\n",
    "    df = run_stage4_customizable(\n",
    "        INPUT_CSV, \n",
    "        OUTPUT_CSV, \n",
    "        rules_file='ui_generated_rules.json'\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 5: CSV Cleanup\n",
    "\n",
    "Remove empty columns, standardize names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 5: CSV CLEANUP\n",
      "================================================================================\n",
      "\n",
      " Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\n",
      "‚úì Loaded 2,715 rows, 20 columns\n",
      "\n",
      "Original columns:\n",
      "   1. Unnamed: 0                               - 2,715 nulls (100.0%)\n",
      "   2. Unnamed: 1                               - 2,715 nulls (100.0%)\n",
      "   3. TRANSACTION TYPE                         - 2,715 nulls (100.0%)\n",
      "   4. PAID IN                                  - 2,715 nulls (100.0%)\n",
      "   5. PAID OUT                                 - 2,715 nulls (100.0%)\n",
      "   6. Receipt No.                              -     0 nulls (  0.0%)\n",
      "   7. Completion Time                          -     0 nulls (  0.0%)\n",
      "   8. Details                                  -     1 nulls (  0.0%)\n",
      "   9. Transaction Status                       -     0 nulls (  0.0%)\n",
      "  10. Paid In                                  - 2,129 nulls ( 78.4%)\n",
      "  11. Withdrawn                                -   586 nulls ( 21.6%)\n",
      "  12. Balance                                  -     0 nulls (  0.0%)\n",
      "  13. Statement Verification Code              - 2,715 nulls (100.0%)\n",
      "prompts to enter the code. - 2,715 nulls (100.0%)ment dial *334#, select My account and follow the\n",
      "  15. description_clean                        -     1 nulls (  0.0%)\n",
      "  16. transaction_type                         -     0 nulls (  0.0%)\n",
      "  17. extracted_fields                         -     0 nulls (  0.0%)\n",
      "  18. extracted_fields_str                     -     0 nulls (  0.0%)\n",
      "  19. extracted_fields_dict                    -     0 nulls (  0.0%)\n",
      "  20. category                                 -     0 nulls (  0.0%)\n",
      "\n",
      "üßπ Removing empty columns...\n",
      "  Removing 7 completely empty columns:\n",
      "    ‚Ä¢ Unnamed: 0\n",
      "    ‚Ä¢ Unnamed: 1\n",
      "    ‚Ä¢ TRANSACTION TYPE\n",
      "    ‚Ä¢ PAID IN\n",
      "    ‚Ä¢ PAID OUT\n",
      "    ‚Ä¢ Statement Verification Code\n",
      "prompts to enter the code.ty of this M-PESA statement dial *334#, select My account and follow the\n",
      "\n",
      " Checking for duplicate columns...\n",
      "  Removing 2 duplicate columns:\n",
      "    ‚Ä¢ extracted_fields_str\n",
      "    ‚Ä¢ extracted_fields_dict\n",
      "\n",
      " Standardizing column names...\n",
      "  Receipt No. ‚Üí receipt_no\n",
      "  Completion Time ‚Üí completion_time\n",
      "  Details ‚Üí details_original\n",
      "  Transaction Status ‚Üí status\n",
      "  Paid In ‚Üí paid_in\n",
      "  Withdrawn ‚Üí withdrawn\n",
      "  Balance ‚Üí balance\n",
      "  description_clean ‚Üí description\n",
      "  transaction_type ‚Üí type\n",
      "  category ‚Üí category\n",
      "\n",
      "‚úÖ Final columns:\n",
      "   1. receipt_no                -     0 nulls ( 0.0%)\n",
      "   2. completion_time           -     0 nulls ( 0.0%)\n",
      "   3. details_original          -     1 nulls ( 0.0%)\n",
      "   4. description               -     1 nulls ( 0.0%)\n",
      "   5. status                    -     0 nulls ( 0.0%)\n",
      "   6. paid_in                   - 2,129 nulls (78.4%)\n",
      "   7. withdrawn                 -   586 nulls (21.6%)\n",
      "   8. balance                   -     0 nulls ( 0.0%)\n",
      "   9. type                      -     0 nulls ( 0.0%)\n",
      "  10. extracted_fields          -     0 nulls ( 0.0%)\n",
      "  11. category                  -     0 nulls ( 0.0%)\n",
      "\n",
      "================================================================================\n",
      "CLEANUP SUMMARY\n",
      "================================================================================\n",
      "Original: 20 columns\n",
      "Removed:  9 columns\n",
      "Final:    11 columns\n",
      "Rows:     2,715 (unchanged)\n",
      "\n",
      " Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_clean.csv\n",
      "\n",
      "================================================================================\n",
      "STAGE 5 COMPLETE! ‚ú®\n",
      "================================================================================\n",
      "\n",
      "Ready for manual merchant labeling!\n",
      "Next: Open CSV and add 'merchant_subcategory' column\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 5: CSV CLEANUP\n",
    "Removes empty columns, duplicate columns, and standardizes column names\n",
    "\"\"\"\n",
    "\n",
    "def clean_csv(input_csv: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Clean the categorized CSV by removing empty/duplicate columns\n",
    "    and standardizing column names\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to Stage 4 output CSV\n",
    "        output_csv: Path to save cleaned CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 5: CSV CLEANUP\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    # Load data\n",
    "    print(f\" Loading: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv, low_memory=False)\n",
    "    print(f\"‚úì Loaded {len(df):,} rows, {len(df.columns)} columns\")\n",
    "    print()\n",
    "    \n",
    "    # Show original columns\n",
    "    print(\"Original columns:\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        null_count = df[col].isna().sum()\n",
    "        null_pct = (null_count / len(df)) * 100\n",
    "        print(f\"  {i:2d}. {col:40s} - {null_count:5,} nulls ({null_pct:5.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Remove columns with 100% null values\n",
    "    print(\"üßπ Removing empty columns...\")\n",
    "    before_cols = len(df.columns)\n",
    "    \n",
    "    empty_cols = [col for col in df.columns if df[col].isna().all()]\n",
    "    if empty_cols:\n",
    "        print(f\"  Removing {len(empty_cols)} completely empty columns:\")\n",
    "        for col in empty_cols:\n",
    "            print(f\"    ‚Ä¢ {col}\")\n",
    "        df = df.drop(columns=empty_cols)\n",
    "    else:\n",
    "        print(\"  No completely empty columns found\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    print(\" Checking for duplicate columns...\")\n",
    "    \n",
    "    # Check for columns with same content\n",
    "    duplicate_cols = []\n",
    "    checked = set()\n",
    "    \n",
    "    for col1 in df.columns:\n",
    "        if col1 in checked:\n",
    "            continue\n",
    "        for col2 in df.columns:\n",
    "            if col1 != col2 and col2 not in checked:\n",
    "                if df[col1].equals(df[col2]):\n",
    "                    duplicate_cols.append(col2)\n",
    "                    checked.add(col2)\n",
    "    \n",
    "    if duplicate_cols:\n",
    "        print(f\"  Removing {len(duplicate_cols)} duplicate columns:\")\n",
    "        for col in duplicate_cols:\n",
    "            print(f\"    ‚Ä¢ {col}\")\n",
    "        df = df.drop(columns=duplicate_cols)\n",
    "    else:\n",
    "        print(\"  No duplicate columns found\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Standardize essential column names\n",
    "    print(\" Standardizing column names...\")\n",
    "    \n",
    "    rename_map = {\n",
    "        'Receipt No.': 'receipt_no',\n",
    "        'Completion Time': 'completion_time',\n",
    "        'Details': 'details_original',\n",
    "        'Transaction Status': 'status',\n",
    "        'Paid In': 'paid_in',\n",
    "        'Withdrawn': 'withdrawn',\n",
    "        'Balance': 'balance',\n",
    "        'description_clean': 'description',\n",
    "        'transaction_type': 'type',\n",
    "        'extracted_fields_str': 'extracted_fields',\n",
    "        'category': 'category'\n",
    "    }\n",
    "    \n",
    "    # Only rename columns that exist\n",
    "    actual_rename = {old: new for old, new in rename_map.items() if old in df.columns}\n",
    "    df = df.rename(columns=actual_rename)\n",
    "    \n",
    "    for old, new in actual_rename.items():\n",
    "        print(f\"  {old} ‚Üí {new}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Keep only essential columns in specific order\n",
    "    essential_columns = [\n",
    "        'receipt_no',\n",
    "        'completion_time',\n",
    "        'description',\n",
    "        'status',\n",
    "        'paid_in',\n",
    "        'withdrawn',\n",
    "        'balance',\n",
    "        'type',\n",
    "        'extracted_fields',\n",
    "        'category'\n",
    "    ]\n",
    "    \n",
    "    # Add details_original if it exists\n",
    "    if 'details_original' in df.columns:\n",
    "        essential_columns.insert(2, 'details_original')\n",
    "    \n",
    "    # Filter to existing columns\n",
    "    available_columns = [col for col in essential_columns if col in df.columns]\n",
    "    df_clean = df[available_columns].copy()\n",
    "    \n",
    "    print(\"‚úÖ Final columns:\")\n",
    "    for i, col in enumerate(df_clean.columns, 1):\n",
    "        null_count = df_clean[col].isna().sum()\n",
    "        null_pct = (null_count / len(df_clean)) * 100\n",
    "        print(f\"  {i:2d}. {col:25s} - {null_count:5,} nulls ({null_pct:4.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Summary\n",
    "    print(\"=\" * 80)\n",
    "    print(\"CLEANUP SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Original: {before_cols} columns\")\n",
    "    print(f\"Removed:  {before_cols - len(df_clean.columns)} columns\")\n",
    "    print(f\"Final:    {len(df_clean.columns)} columns\")\n",
    "    print(f\"Rows:     {len(df_clean):,} (unchanged)\")\n",
    "    print()\n",
    "    \n",
    "    # Save\n",
    "    df_clean.to_csv(output_csv, index=False)\n",
    "    print(f\" Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"STAGE 5 COMPLETE! ‚ú®\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\stage4_final_categorized.csv\"\n",
    "    OUTPUT_CSV = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_clean.csv\"\n",
    "    \n",
    "    df = clean_csv(INPUT_CSV, OUTPUT_CSV)\n",
    "    \n",
    "    print(\"Ready for manual merchant labeling!\")\n",
    "    print(\"Next: Open CSV and add 'merchant_subcategory' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üéì MERCHANT LEARNING SYSTEM\n",
    "## Stage 6: Hybrid Personal Learning\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 6A: [OPTIONAL] Import Manual Labels\n",
    "\n",
    "**Run this ONLY if you have manually labeled data.**\n",
    "\n",
    "This pre-populates your merchant database, so you skip labeling those merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Importing manual labels...\n",
      "\n",
      "‚úÖ Imported 285 merchants from manual labels\n",
      "‚úÖ Database saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\processed\\merchant_databases\\user_john_merchants.json\n",
      "\n",
      "üéâ 285 merchants pre-loaded!\n",
      "   These will be auto-categorized in Stage 6B\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "OPTIONAL: IMPORT MANUAL LABELS\n",
    "Skip this cell if you don't have manual labels\n",
    "\"\"\"\n",
    "\n",
    "# Only run if MANUAL_LABELS_CSV is set and file exists\n",
    "if MANUAL_LABELS_CSV and os.path.exists(MANUAL_LABELS_CSV):\n",
    "    print(\" Importing manual labels...\")\n",
    "    print()\n",
    "    \n",
    "    # Import function (embedded)\n",
    "    class ManualLabelImporter:\n",
    "        def __init__(self, user_id, database_dir):\n",
    "            self.user_id = user_id\n",
    "            self.db_path = os.path.join(database_dir, f\"user_{user_id}_merchants.json\")\n",
    "            self.merchant_db = {}\n",
    "            if os.path.exists(self.db_path):\n",
    "                with open(self.db_path, 'r') as f:\n",
    "                    self.merchant_db = json.load(f)\n",
    "        \n",
    "        def _extract_merchant_id(self, row):\n",
    "            # Try extracted_fields\n",
    "            extracted = row.get('extracted_fields_str', '') or row.get('extracted_fields', '')\n",
    "            if pd.notna(extracted) and str(extracted) not in ['', '{}', 'nan']:\n",
    "                try:\n",
    "                    import ast\n",
    "                    fields = ast.literal_eval(str(extracted))\n",
    "                    if fields.get('till_number'):\n",
    "                        return f\"TILL_{fields['till_number']}\"\n",
    "                    elif fields.get('paybill_number'):\n",
    "                        return f\"PAYBILL_{fields['paybill_number']}\"\n",
    "                    elif fields.get('recipient_number'):\n",
    "                        return f\"PHONE_{fields['recipient_number']}\"\n",
    "                    elif fields.get('merchant_name'):\n",
    "                        return f\"NAME_{fields['merchant_name'][:50].upper()}\"\n",
    "                except:\n",
    "                    pass\n",
    "            return None\n",
    "        \n",
    "        def import_csv(self, csv_path, category_col):\n",
    "            df = pd.read_csv(csv_path, low_memory=False)\n",
    "            \n",
    "            if 'category' in df.columns:\n",
    "                df = df[df['category'] == 'Merchant']\n",
    "            \n",
    "            labeled = df[df[category_col].notna()].copy()\n",
    "            labeled['merchant_id'] = labeled.apply(self._extract_merchant_id, axis=1)\n",
    "            labeled = labeled[labeled['merchant_id'].notna()]\n",
    "            \n",
    "            imported = 0\n",
    "            for merchant_id, group in labeled.groupby('merchant_id'):\n",
    "                category = group[category_col].value_counts().index[0]\n",
    "                sample = str(group.iloc[0].get('description', ''))[:70]\n",
    "                \n",
    "                self.merchant_db[merchant_id] = {\n",
    "                    'category': category,\n",
    "                    'sample_description': sample,\n",
    "                    'first_seen': datetime.now().isoformat(),\n",
    "                    'transaction_count': len(group),\n",
    "                    'imported_from': csv_path\n",
    "                }\n",
    "                imported += 1\n",
    "            \n",
    "            # Save\n",
    "            with open(self.db_path, 'w') as f:\n",
    "                json.dump(self.merchant_db, f, indent=2)\n",
    "            \n",
    "            print(f\"‚úÖ Imported {imported} merchants from manual labels\")\n",
    "            print(f\"‚úÖ Database saved: {self.db_path}\")\n",
    "            return imported\n",
    "    \n",
    "    # Run import\n",
    "    importer = ManualLabelImporter(USER_ID, DATABASE_DIR)\n",
    "    count = importer.import_csv(MANUAL_LABELS_CSV, MANUAL_LABELS_COLUMN)\n",
    "    \n",
    "    print()\n",
    "    print(f\"üéâ {count} merchants pre-loaded!\")\n",
    "    print(f\"   These will be auto-categorized in Stage 6B\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"‚Ñπ  No manual labels to import - will learn interactively in Stage 6B\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 6B: Hybrid Merchant Learning (Interactive)\n",
    "\n",
    "**This is where the UI integration happens!**\n",
    "\n",
    "### How It Works:\n",
    "1. Checks database first (from manual import or previous months)\n",
    "2. Auto-labels known merchants\n",
    "3. Shows interactive prompts for unknown merchants\n",
    "4. Saves learnings to personal database\n",
    "\n",
    "### In Production UI:\n",
    "- Replace `input()` with React/HTML form\n",
    "- Show progress bar\n",
    "- Display merchant info visually\n",
    "- Save to backend API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 6B: MERCHANT LEARNING\n",
      "================================================================================\n",
      "\n",
      " Loading: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_clean.csv\n",
      "‚úì 2,715 transactions\n",
      "\n",
      "‚úì Database loaded: 333 known merchants\n",
      "‚úÖ Auto-labeled: 795\n",
      "‚ùì Need input: 0\n",
      "\n",
      " Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_with_merchants.csv\n",
      "\n",
      "‚úÖ STAGE 6 COMPLETE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 6B: HYBRID MERCHANT LEARNING\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAGE 6B: MERCHANT LEARNING\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Load Stage 5 output\n",
    "STAGE5 = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_clean.csv\"\n",
    "print(f\" Loading: {STAGE5}\")\n",
    "df = pd.read_csv(STAGE5, low_memory=False)\n",
    "print(f\"‚úì {len(df):,} transactions\")\n",
    "print()\n",
    "\n",
    "# Simple merchant learner\n",
    "class MerchantLearner:\n",
    "    def __init__(self, user_id, db_dir):\n",
    "        self.db_path = os.path.join(db_dir, f\"user_{user_id}_merchants.json\")\n",
    "        if os.path.exists(self.db_path):\n",
    "            with open(self.db_path, 'r') as f:\n",
    "                self.db = json.load(f)\n",
    "        else:\n",
    "            self.db = {}\n",
    "        print(f\"‚úì Database loaded: {len(self.db)} known merchants\")\n",
    "    \n",
    "    def extract_id(self, row):\n",
    "        # Try to get merchant ID from extracted_fields\n",
    "        extracted = str(row.get('extracted_fields_str', '') or row.get('extracted_fields', ''))\n",
    "        if extracted and extracted not in ['', '{}', 'nan']:\n",
    "            try:\n",
    "                import ast\n",
    "                fields = ast.literal_eval(extracted)\n",
    "                if fields.get('till_number'):\n",
    "                    return f\"TILL_{fields['till_number']}\"\n",
    "                elif fields.get('recipient_number'):\n",
    "                    return f\"PHONE_{fields['recipient_number']}\"\n",
    "                elif fields.get('merchant_name'):\n",
    "                    return f\"NAME_{fields['merchant_name'][:30]}\"\n",
    "            except:\n",
    "                pass\n",
    "        return None\n",
    "    \n",
    "    def categorize(self, df, interactive=True):\n",
    "        df = df.copy()\n",
    "        df['merchant_subcategory'] = None\n",
    "        df['merchant_id'] = None\n",
    "        \n",
    "        # Extract IDs\n",
    "        merchant_mask = df['category'] == 'Merchant'\n",
    "        for idx in df[merchant_mask].index:\n",
    "            df.at[idx, 'merchant_id'] = self.extract_id(df.loc[idx])\n",
    "        \n",
    "        # Auto-label from database\n",
    "        from_db = 0\n",
    "        for idx in df[merchant_mask].index:\n",
    "            mid = df.at[idx, 'merchant_id']\n",
    "            if mid and mid in self.db:\n",
    "                df.at[idx, 'merchant_subcategory'] = self.db[mid]['category']\n",
    "                from_db += 1\n",
    "        \n",
    "        need_input = merchant_mask.sum() - from_db\n",
    "        \n",
    "        print(f\"‚úÖ Auto-labeled: {from_db:,}\")\n",
    "        print(f\"‚ùì Need input: {need_input:,}\")\n",
    "        print()\n",
    "        \n",
    "        # Interactive learning\n",
    "        if interactive and need_input > 0:\n",
    "            unknown = df[(merchant_mask) & (df['merchant_subcategory'].isna())]\n",
    "            unique = unknown.groupby('merchant_id').first().reset_index()\n",
    "            \n",
    "            print(\"üéì Learning new merchants...\")\n",
    "            print()\n",
    "            \n",
    "            learned = 0\n",
    "            for _, row in unique.iterrows():\n",
    "                mid = row['merchant_id']\n",
    "                if not mid or mid == 'None':\n",
    "                    continue\n",
    "                \n",
    "                desc = str(row.get('description', ''))[:65]\n",
    "                count = len(df[df['merchant_id'] == mid])\n",
    "                \n",
    "                print(\"-\" * 80)\n",
    "                print(f\"Merchant: {desc}\")\n",
    "                print(f\"Appears: {count} times\")\n",
    "                print()\n",
    "                print(\"Category?\")\n",
    "                print(\"1=Transport 2=Groceries 3=Shopping 4=Food&Dining\")\n",
    "                print(\"5=Construction 6=Family 7=Investment 8=Other S=Skip\")\n",
    "                \n",
    "                choice = input(\"‚Üí \").strip().upper()\n",
    "                \n",
    "                cats = {'1':'Transport','2':'Groceries','3':'Shopping',\n",
    "                       '4':'Food & Dining','5':'Construction','6':'Friends & Family', '7': 'Investment', \n",
    "                        '8':'Personal Care', '9':'Business','10': 'Contribution', '11': 'Health Care','12': 'Other', '13':'Skip'}\n",
    "                \n",
    "                if choice == 'S':\n",
    "                    continue\n",
    "                elif choice in cats:\n",
    "                    cat = cats[choice]\n",
    "                elif choice == '7':\n",
    "                    cat = input(\"Enter category: \").strip()\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                df.loc[df['merchant_id']==mid, 'merchant_subcategory'] = cat\n",
    "                self.db[mid] = {'category': cat, 'learned': datetime.now().isoformat()}\n",
    "                learned += 1\n",
    "                print(f\"‚úì {cat}\")\n",
    "                print()\n",
    "            \n",
    "            # Save database\n",
    "            with open(self.db_path, 'w') as f:\n",
    "                json.dump(self.db, f, indent=2)\n",
    "            \n",
    "            print(\"=\" * 80)\n",
    "            print(f\"üéâ Learned {learned} merchants!\")\n",
    "            print(f\"‚úì Total known: {len(self.db)}\")\n",
    "            print(\"=\" * 80)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Run learning\n",
    "learner = MerchantLearner(USER_ID, DATABASE_DIR)\n",
    "df = learner.categorize(df, interactive=True)\n",
    "\n",
    "# Save\n",
    "STAGE6 = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_categorized_with_merchants.csv\"\n",
    "df.to_csv(STAGE6, index=False)\n",
    "print(f\" Saved: {STAGE6}\")\n",
    "print()\n",
    "print(\"‚úÖ STAGE 6 COMPLETE\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚ú® FINAL PREPARATION\n",
    "## Stage 7: Unified Categories + Analysis Features\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAGE 7: Create Unified Category System\n",
    "\n",
    "**What This Does:**\n",
    "1. Merges keyword-caught merchants (Shopping, Transport, etc.) into Merchant category\n",
    "2. Creates `final_category` - ONE category for all analysis\n",
    "3. Creates category hierarchy (high-level ‚Üî detailed)\n",
    "4. Adds temporal, financial, and behavioral features\n",
    "5. Standardizes all labels (Transport not transport)\n",
    "\n",
    "**Output:** 100% analysis-ready CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STAGE 7: CREATING ANALYSIS-READY DATA\n",
      "================================================================================\n",
      "\n",
      "‚úì Merged 12 keyword merchants\n",
      "‚úì Created final_category\n",
      "‚úì Created category hierarchy\n",
      "üìÖ Creating temporal features...\n",
      "üè∑Ô∏è  Creating categorical features...\n",
      "‚úì Added analysis features\n",
      "\n",
      "================================================================================\n",
      "‚úÖ ANALYSIS-READY DATA CREATED!\n",
      "================================================================================\n",
      "\n",
      " Saved: C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_analysis_ready.csv\n",
      "\n",
      "Rows: 2,715\n",
      "Columns: 33\n",
      "Date range: 2024-02-17 18:31:52 to 2026-02-10 10:30:15\n",
      "\n",
      "High-Level Categories:\n",
      "  Finance & Fees                :    779 ( 28.7%)\n",
      "  Spending                      :    685 ( 25.2%)\n",
      "  Transfers & Savings           :    587 ( 21.6%)\n",
      "  Income                        :    245 (  9.0%)\n",
      "  Bills & Obligations           :    163 (  6.0%)\n",
      "  Social & Leisure              :    157 (  5.8%)\n",
      "  Other                         :     99 (  3.6%)\n",
      "\n",
      "Top 15 Detailed Categories:\n",
      "  M-Pesa Fees                   :    779 ( 28.7%)\n",
      "  Cash Deposit                  :    297 ( 10.9%)\n",
      "  Income                        :    245 (  9.0%)\n",
      "  Savings                       :    228 (  8.4%)\n",
      "  Food & Dining                 :    221 (  8.1%)\n",
      "  Transport                     :    190 (  7.0%)\n",
      "  Bills                         :    104 (  3.8%)\n",
      "  Friends & Family              :     91 (  3.4%)\n",
      "  Groceries                     :     90 (  3.3%)\n",
      "  Construction                  :     66 (  2.4%)\n",
      "  Cash Withdrawal               :     62 (  2.3%)\n",
      "  Airtime                       :     58 (  2.1%)\n",
      "  Shopping                      :     56 (  2.1%)\n",
      "  Contribution                  :     46 (  1.7%)\n",
      "  Business                      :     34 (  1.3%)\n",
      "\n",
      "‚úÖ STAGE 7 COMPLETE\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STAGE 7: UNIFIED CATEGORY SYSTEM + FEATURES\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STAGE 7: CREATING ANALYSIS-READY DATA\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Load Stage 6\n",
    "df = pd.read_csv(STAGE6, low_memory=False)\n",
    "\n",
    "# Remove empty duplicate if exists\n",
    "if 'Merchant_Subcategory' in df.columns:\n",
    "    df = df.drop(columns=['Merchant_Subcategory'])\n",
    "\n",
    "# Standardize merchant subcategory labels\n",
    "label_map = {\n",
    "    'transport': 'Transport', 'Transport': 'Transport',\n",
    "    'groceries': 'Groceries', 'Groceries': 'Groceries',\n",
    "    'shopping': 'Shopping', 'Shopping': 'Shopping',\n",
    "    'construction': 'Construction',\n",
    "    'business': 'Business',\n",
    "    'contribution': 'Contribution',\n",
    "    'food & dining': 'Food & Dining',\n",
    "    'Friends & Family': 'Friends & Family',\n",
    "    'Personal Care': 'Personal Care',\n",
    "}\n",
    "\n",
    "if 'merchant_subcategory' in df.columns:\n",
    "    df['merchant_subcategory'] = df['merchant_subcategory'].map(\n",
    "        lambda x: label_map.get(x, x) if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "# Merge keyword-caught merchants\n",
    "keyword_merchants = ['Shopping', 'Groceries', 'Transport', 'Food & Dining', \n",
    "                    'Personal Care', 'Health Care', 'Entertainment']\n",
    "\n",
    "merge_mask = (\n",
    "    df['category'].isin(keyword_merchants) &\n",
    "    df['type'].isin(['Till Payment', 'PayBill', 'Pochi la Biashara'])\n",
    ")\n",
    "\n",
    "df.loc[merge_mask & df['merchant_subcategory'].isna(), 'merchant_subcategory'] = df.loc[merge_mask & df['merchant_subcategory'].isna(), 'category']\n",
    "df.loc[merge_mask, 'category'] = 'Merchant'\n",
    "\n",
    "print(f\"‚úì Merged {merge_mask.sum()} keyword merchants\")\n",
    "\n",
    "# Create final_category\n",
    "df['final_category'] = df.apply(\n",
    "    lambda r: r['merchant_subcategory'] if r['category']=='Merchant' and pd.notna(r['merchant_subcategory']) else r['category'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"‚úì Created final_category\")\n",
    "\n",
    "# Create hierarchy\n",
    "def get_level1(cat):\n",
    "    if pd.isna(cat): return 'Other'\n",
    "    if cat in ['Income']: return 'Income'\n",
    "    if cat in ['Transport','Groceries','Shopping','Food & Dining','Construction','Personal Care','Entertainment','Clothing','Business','Labor']:\n",
    "        return 'Spending'\n",
    "    if cat in ['Bills','Government Bills','Subscriptions','Health Care','Education']:\n",
    "        return 'Bills & Obligations'\n",
    "    if cat in ['Friends & Family','Contribution','Betting']:\n",
    "        return 'Social & Leisure'\n",
    "    if cat in ['M-Pesa Fees','Loan Repayment','Loans','Fuliza']:\n",
    "        return 'Finance & Fees'\n",
    "    if cat in ['Cash Deposit','Cash Withdrawal','Savings','Bank Transfer']:\n",
    "        return 'Transfers & Savings'\n",
    "    return 'Other'\n",
    "\n",
    "df['category_level1'] = df['final_category'].apply(get_level1)\n",
    "df['category_level2'] = df['final_category']\n",
    "\n",
    "print(\"‚úì Created category hierarchy\")\n",
    "\n",
    "# 1. Parse datetime\n",
    "date_col = 'completion_time' if 'completion_time' in df.columns else 'Completion Time'\n",
    "df['datetime'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "\n",
    "# 2. Create temporal features\n",
    "print(\"üìÖ Creating temporal features...\")\n",
    "df['date'] = df['datetime'].dt.date\n",
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['month_name'] = df['datetime'].dt.strftime('%B')\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['weekday'] = df['datetime'].dt.day_name()\n",
    "df['weekday_num'] = df['datetime'].dt.dayofweek\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['is_weekend'] = df['weekday_num'].isin([5,6]).astype(int)\n",
    "\n",
    "def time_of_day(hour):\n",
    "    if pd.isna(hour): return 'Unknown'\n",
    "    if 5 <= hour < 12: return 'Morning'\n",
    "    elif 12 <= hour < 17: return 'Afternoon'\n",
    "    elif 17 <= hour < 21: return 'Evening'\n",
    "    else: return 'Night'\n",
    "\n",
    "df['time_of_day'] = df['hour'].apply(time_of_day)\n",
    "\n",
    "\n",
    "# Add features\n",
    "# Clean amounts\n",
    "if 'withdrawn' in df.columns:\n",
    "    df['amount_spent'] = pd.to_numeric(df['withdrawn'].astype(str).str.replace(',',''), errors='coerce').abs().fillna(0)\n",
    "elif 'Withdrawn' in df.columns:\n",
    "    df['amount_spent'] = pd.to_numeric(df['Withdrawn'].astype(str).str.replace(',',''), errors='coerce').abs().fillna(0)\n",
    "else:\n",
    "    df['amount_spent'] = 0\n",
    "\n",
    "if 'paid_in' in df.columns:\n",
    "    df['amount_received'] = pd.to_numeric(df['paid_in'].astype(str).str.replace(',',''), errors='coerce').abs().fillna(0)\n",
    "elif 'Paid In' in df.columns:\n",
    "    df['amount_received'] = pd.to_numeric(df['Paid In'].astype(str).str.replace(',',''), errors='coerce').abs().fillna(0)\n",
    "else:\n",
    "    df['amount_received'] = 0\n",
    "\n",
    "if 'balance' in df.columns:\n",
    "    df['balance'] = pd.to_numeric(df['balance'].astype(str).str.replace(',',''), errors='coerce')\n",
    "elif 'Balance' in df.columns:\n",
    "    df['balance'] = pd.to_numeric(df['Balance'].astype(str).str.replace(',',''), errors='coerce')\n",
    "\n",
    "# Sort by time\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# Net flow\n",
    "df['net_flow'] = df['amount_received'] - df['amount_spent']\n",
    "\n",
    "# Running totals\n",
    "df['cumulative_spent'] = df['amount_spent'].cumsum()\n",
    "df['cumulative_received'] = df['amount_received'].cumsum()\n",
    "\n",
    "# Balance change\n",
    "if 'balance' in df.columns:\n",
    "    df['balance_change'] = df['balance'].diff()\n",
    "\n",
    "# 4. Categorical features\n",
    "print(\"üè∑Ô∏è  Creating categorical features...\")\n",
    "\n",
    "print(\"‚úì Added analysis features\")\n",
    "print()\n",
    "\n",
    "# Save\n",
    "FINAL = r\"C:\\Users\\setla\\Documents\\Flatiron\\PHASE5\\Capstone\\final_analysis_ready.csv\"\n",
    "df.to_csv(FINAL, index=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ ANALYSIS-READY DATA CREATED!\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\" Saved: {FINAL}\")\n",
    "print()\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "print()\n",
    "\n",
    "print(\"High-Level Categories:\")\n",
    "for cat, cnt in df['category_level1'].value_counts().items():\n",
    "    pct = cnt/len(df)*100\n",
    "    print(f\"  {cat:30s}: {cnt:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "print()\n",
    "print(\"Top 15 Detailed Categories:\")\n",
    "for cat, cnt in df['final_category'].value_counts().head(15).items():\n",
    "    pct = cnt/len(df)*100\n",
    "    print(f\"  {cat:30s}: {cnt:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ STAGE 7 COMPLETE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESSENTIAL AND DISCRETIONARY CLASSIFICATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Classification applied\n",
      "\n",
      "================================================================================\n",
      "NEW CLASSIFICATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ESSENTIAL:         475 ( 17.5%)\n",
      "DISCRETIONARY:     398 ( 14.7%)\n",
      "NEITHER:         1,842 ( 67.8%)\n",
      "\n",
      "ESSENTIAL Categories:\n",
      "  Transport                :   190 txns | KES   111,570.00\n",
      "  Groceries                :    90 txns | KES   103,264.00\n",
      "  Bills                    :   104 txns | KES   115,656.00\n",
      "  Government Bills         :    32 txns | KES    32,536.00\n",
      "  Health Care              :     1 txns | KES        90.00\n",
      "  Airtime                  :    58 txns | KES    44,400.00\n",
      "\n",
      "DISCRETIONARY Categories:\n",
      "  Betting                  :    20 txns | KES     1,005.00\n",
      "  Fast Foods               :     1 txns | KES       310.00\n",
      "  Food & Dining            :   221 txns | KES    31,575.00\n",
      "  Shopping                 :    56 txns | KES    45,444.00\n",
      "  Personal Care            :    28 txns | KES     2,240.00\n",
      "  Contribution             :    46 txns | KES    80,117.00\n",
      "  Subscriptions            :    26 txns | KES    45,231.00\n",
      "\n",
      "================================================================================\n",
      "SPENDING ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Essential Spending:     KES     407,516.00 ( 12.7%)\n",
      "Discretionary Spending: KES     205,922.00 (  6.4%)\n",
      "Other (Neither):        KES   2,597,146.00\n",
      "Total Spending:         KES   3,210,584.00\n",
      "\n",
      "üí° INSIGHTS:\n",
      "   ‚Ä¢ If you reduce discretionary spending by 25%: Save KES 51,480.50/month\n",
      "   ‚Ä¢ If you reduce discretionary spending by 50%: Save KES 102,961.00/month\n",
      "\n",
      "üíæ Saved: final_analysis.csv\n",
      "\n",
      "‚úÖ Ready for analysis with correct classification!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "ESSENTIAL (True needs - can't avoid for basic living):\n",
    "‚úì Transport - Getting to work/school\n",
    "‚úì Groceries - Food for home\n",
    "‚úì Bills - Utilities (KPLC, Water)\n",
    "‚úì Government Bills - NHIF, NSSF, taxes\n",
    "‚úì Health Care - Medical expenses\n",
    "‚úì Education - School fees\n",
    "‚úì Airtime - Communication (basic need in modern life)\n",
    "\n",
    "DISCRETIONARY (Wants - can reduce/avoid):\n",
    "‚úì Betting - Gambling\n",
    "‚úì Fast Foods - Eating out (non-essential)\n",
    "‚úì Food & Dining - Restaurants (non-essential)\n",
    "‚úì Entertainment - Leisure activities\n",
    "‚úì Shopping - Non-grocery shopping\n",
    "‚úì Personal Care - Salons, spas (beyond basic)\n",
    "‚úì Contribution - Donations, offerings (generous but optional)\n",
    "\n",
    "NEITHER (Not spending or social obligations):\n",
    "‚Ä¢ Income\n",
    "‚Ä¢ Cash Deposit/Withdrawal  \n",
    "‚Ä¢ Savings\n",
    "‚Ä¢ M-Pesa Fees\n",
    "‚Ä¢ Friends & Family - Social obligations (different from discretionary)\n",
    "‚Ä¢ Construction - Business/investment\n",
    "‚Ä¢ Business - Business expenses\n",
    "‚Ä¢ All other transfers\n",
    "\"\"\"\n",
    "def fix_essential_discretionary_classification(input_csv: str, output_csv: str):\n",
    "    \"\"\"\n",
    "    Fix essential vs discretionary classification with correct logic\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # ESSENTIAL - True basic needs\n",
    "    essential_categories = [\n",
    "        'Transport',        # Getting to work/school\n",
    "        'Groceries',        # Food for home\n",
    "        'Bills',           # Utilities\n",
    "        'Government Bills', # Taxes, NHIF, NSSF\n",
    "        'Health Care',     # Medical\n",
    "        'Education',       # School fees\n",
    "        'Airtime',         # Basic communication\n",
    "    ]\n",
    "    \n",
    "    # DISCRETIONARY - Wants, can reduce/avoid\n",
    "    discretionary_categories = [\n",
    "        'Betting',         # Gambling\n",
    "        'Fast Foods',      # Eating out\n",
    "        'Food & Dining',   # Restaurants (NOT groceries)\n",
    "        'Entertainment',   # Leisure\n",
    "        'Shopping',        # Non-grocery shopping\n",
    "        'Personal Care',   # Salons, spas\n",
    "        'Contribution',    # Donations, offerings\n",
    "        'Subscriptions',   # Entertainment subscriptions (Netflix, GOTV, etc.)\n",
    "    ]\n",
    "    \n",
    "    # Apply classification\n",
    "    df['is_essential'] = df['final_category'].isin(essential_categories).astype(int)\n",
    "    df['is_discretionary'] = df['final_category'].isin(discretionary_categories).astype(int)\n",
    "    \n",
    "    print(\"‚úì Classification applied\")\n",
    "    print()\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VALIDATION & SUMMARY\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"NEW CLASSIFICATION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    essential = df[df['is_essential'] == 1]\n",
    "    discretionary = df[df['is_discretionary'] == 1]\n",
    "    neither = df[(df['is_essential'] == 0) & (df['is_discretionary'] == 0)]\n",
    "    \n",
    "    print(f\"ESSENTIAL:      {len(essential):6,} ({len(essential)/len(df)*100:5.1f}%)\")\n",
    "    print(f\"DISCRETIONARY:  {len(discretionary):6,} ({len(discretionary)/len(df)*100:5.1f}%)\")\n",
    "    print(f\"NEITHER:        {len(neither):6,} ({len(neither)/len(df)*100:5.1f}%)\")\n",
    "    print()\n",
    "    \n",
    "    # Essential breakdown\n",
    "    print(\"ESSENTIAL Categories:\")\n",
    "    for cat in essential_categories:\n",
    "        count = len(df[(df['final_category'] == cat) & (df['is_essential'] == 1)])\n",
    "        if count > 0:\n",
    "            amount = df[(df['final_category'] == cat) & (df['is_essential'] == 1)]['amount_spent'].sum()\n",
    "            print(f\"  {cat:25s}: {count:5,} txns | KES {amount:12,.2f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Discretionary breakdown\n",
    "    print(\"DISCRETIONARY Categories:\")\n",
    "    for cat in discretionary_categories:\n",
    "        count = len(df[(df['final_category'] == cat) & (df['is_discretionary'] == 1)])\n",
    "        if count > 0:\n",
    "            amount = df[(df['final_category'] == cat) & (df['is_discretionary'] == 1)]['amount_spent'].sum()\n",
    "            print(f\"  {cat:25s}: {count:5,} txns | KES {amount:12,.2f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Financial summary\n",
    "    essential_spending = essential['amount_spent'].sum()\n",
    "    discretionary_spending = discretionary['amount_spent'].sum()\n",
    "    total_spending = df['amount_spent'].sum()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPENDING ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(f\"Essential Spending:     KES {essential_spending:14,.2f} ({essential_spending/total_spending*100:5.1f}%)\")\n",
    "    print(f\"Discretionary Spending: KES {discretionary_spending:14,.2f} ({discretionary_spending/total_spending*100:5.1f}%)\")\n",
    "    print(f\"Other (Neither):        KES {total_spending - essential_spending - discretionary_spending:14,.2f}\")\n",
    "    print(f\"Total Spending:         KES {total_spending:14,.2f}\")\n",
    "    print()\n",
    "    \n",
    "    # Savings potential\n",
    "    if discretionary_spending > 0:\n",
    "        print(\"üí° INSIGHTS:\")\n",
    "        print(f\"   ‚Ä¢ If you reduce discretionary spending by 25%: Save KES {discretionary_spending * 0.25:,.2f}/month\")\n",
    "        print(f\"   ‚Ä¢ If you reduce discretionary spending by 50%: Save KES {discretionary_spending * 0.50:,.2f}/month\")\n",
    "        print()\n",
    "    \n",
    "    # Save\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"üíæ Saved: {output_csv}\")\n",
    "    print()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT = \"final_analysis_ready.csv\"\n",
    "    OUTPUT = \"final_analysis.csv\"\n",
    "    \n",
    "    df = fix_essential_discretionary_classification(INPUT, OUTPUT)\n",
    "    \n",
    "    print(\"‚úÖ Ready for analysis with correct classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚úÖ WORKFLOW COMPLETE!\n",
    "---\n",
    "\n",
    "## üéâ Success!\n",
    "\n",
    "Your M-Pesa data is now **100% analysis-ready**!\n",
    "\n",
    "### üìÅ Output Files:\n",
    "\n",
    "1. **`FINAL_ANALYSIS_READY.csv`** ‚Üê Use this for analytics!\n",
    "2. **`user_{id}_merchants.json`** ‚Üê Personal database (persistent)\n",
    "3. Intermediate files (stage1-6) for debugging\n",
    "\n",
    "### ‚ú® What's in the Final CSV:\n",
    "\n",
    "- ‚úÖ **Unified categories** (no duplicates)\n",
    "- ‚úÖ **Category hierarchy** (high-level ‚Üî detailed)\n",
    "- ‚úÖ **Temporal features** (weekday, hour, payday indicators)\n",
    "- ‚úÖ **Financial features** (amounts, balance, trends)\n",
    "- ‚úÖ **Behavioral features** (recurring, essential/discretionary)\n",
    "- ‚úÖ **Standardized labels** (Transport not transport)\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "1. **Exploratory Data Analysis (EDA)**\n",
    "   - Spending patterns by time\n",
    "   - Category breakdowns\n",
    "   - Trend analysis\n",
    "\n",
    "2. **Recommendations Engine**\n",
    "   - Budget optimization\n",
    "   - Savings opportunities\n",
    "   - Spending predictions\n",
    "\n",
    "3. **Interactive Dashboard**\n",
    "   - Real-time visualizations\n",
    "   - Drill-down capabilities\n",
    "   - Comparative analysis\n",
    "\n",
    "### üí° For Future Statements:\n",
    "\n",
    "Run this notebook again with a new PDF:\n",
    "- Stages 1-5: Automated (no input)\n",
    "- Stage 6: Fewer merchants to label (database grows!)\n",
    "- After 3-6 months: 95%+ auto-categorized üéØ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
